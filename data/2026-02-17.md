<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 39]
- [cs.IT](#cs.IT) [Total: 14]
- [eess.SP](#eess.SP) [Total: 26]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Simulation-Based Study of AI-Assisted Channel Adaptation in UAV-Enabled Cellular Networks](https://arxiv.org/abs/2602.13199)
*Andrii Grekhov,Volodymyr Kharchenko,Vasyl Kondratiuk*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents a simulation based study of Artificial Intelligence assisted communication channel adaptation in Unmanned Aerial Vehicle enabled cellular networks. The considered system model includes communication channel Ground Base Station Aerial Repeater UAV Base Station Cluster of Cellular Network Users. The primary objective of the study is to investigate the impact of adaptive channel parameter control on communication performance under dynamically changing interference conditions. A lightweight supervised machine learning approach based on linear regression is employed to implement cognitive channel adaptation. The AI model operates on packet level performance indicators and enables real time adjustment of Transaction Size in response to variations in Bit Error Rate and effective Data Rate. A custom simulation environment is developed to generate training and testing datasets and to evaluate system behavior under both static and adaptive channel configurations.

</details>


### [2] [Traffic Simulation in Ad Hoc Network of Flying UAVs with Generative AI Adaptation](https://arxiv.org/abs/2602.13200)
*Andrii Grekhov,Volodymyr Kharchenko,Vasyl Kondratiuk*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The purpose of this paper is to model traffic in Ad Hoc network of Unmanned Aerial Vehicles and demonstrate a way for adapting communication channel using Artificial Intelligence. The modeling was based on the original model of Ad Hoc network including 20 Unmanned Aerial Vehicles. The dependences of packet loss on the packet size for different transmission powers, on the packet size for different frequencies, on Unmanned Aerial Vehicles flight area and on the number of Unmanned Aerial Vehicles were obtained and analyzed. The implementation of adaptive data transmission is presented in the program code. The dependences of packet loss, power and transaction size on time during Artificial Intelligence adaptation are shown.

</details>


### [3] [CLF-ULP: Cross-Layer Fusion-Based Link Prediction in Dynamic Multiplex UAV Networks](https://arxiv.org/abs/2602.13201)
*Cunlai Pu,Fangrui Wu,Zhe Wang,Xiangbo Shu*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In complex Unmanned Aerial Vehicle (UAV) networks, UAVs can establish dynamic and heterogeneous links with one another for various purposes, such as communication coverage, collective sensing, and task collaboration. These interactions give rise to dynamic multiplex UAV networks, where each layer represents a distinct type of interaction among UAVs. Understanding how such links form and evolve is both of theoretical interest and of practical importance for the control and maintenance of networked UAV systems. In this paper, we first develop a dynamic multiplex network model for UAV networks to characterize their dynamic and heterogeneous link properties. We then propose a cross-layer fusion-based deep learning model, termed CLF-ULP, to predict future inter-UAV links based on historical topology data. CLF-ULP incorporates graph attention networks to extract topological features within each layer and perform a cross-layer attention fusion to capture inter-layer dependencies. Furthermore, a shared-parameter long short-term memory network is employed to model the temporal evolution of each layer. To improve embedding quality and link prediction performance, we develop a joint loss function that considers both intra-layer and inter-layer UAV adjacency. Extensive experiments on simulated UAV datasets under diverse mobility patterns demonstrate that CLF-ULP achieves state-of-the-art performance in predicting links within dynamic multiplex UAV networks.

</details>


### [4] [Enhancing NOMA Handover Performance Using Hybrid AI-Driven Modulated Deterministic Sequences](https://arxiv.org/abs/2602.13202)
*Sumita Majhi,G Vasantha Reddy,Pinaki Mitra*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Non-Orthogonal Multiple Access (NOMA) is an information-theoretical approach used in 5G networks to improve spectral efficiency, but it is prone to interference during handovers. In this work, we propose a hybrid method that combines Gold-Walsh modulated sequences with Deep Q-Networks (DQN) to intelligently manage interference during NOMA handovers. This method optimizes sequence selection and power allocation dynamically. As a result, it achieves a 95.2\% handover success rate, which is an improvement of up to 23.1 percentage points. It also delivers up to 28\% throughput gain and reduces interference by up to 41\% in various mobility scenarios. All improvements are statistically significant (\(p < 0.001\)). The DQN trains in \(4{,}200 \pm 400\) episodes with a complexity of \(O(N \log N + d \cdot h + \log B)\) and can be deployed in real-time.

</details>


### [5] [Adversarial Network Imagination: Causal LLMs and Digital Twins for Proactive Telecom Mitigation](https://arxiv.org/abs/2602.13203)
*Vignesh Sriram,Yuqiao Meng,Luoxi Tang,Zhaohan Xi*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Telecommunication networks experience complex failures such as fiber cuts, traffic overloads, and cascading outages. Existing monitoring and digital twin systems are largely reactive, detecting failures only after service degradation occurs. We propose Adversarial Network Imagination, a closed-loop framework that integrates a Causal Large Language Model (LLM), a Knowledge Graph, and a Digital Twin to proactively generate, simulate, and evaluate adversarial network failures. The Causal LLM produces structured failure scenarios grounded in network dependencies encoded in the Knowledge Graph. These scenarios are executed within a Digital Twin to measure performance degradation and evaluate mitigation strategies. By iteratively refining scenarios based on simulation feedback, the framework shifts network operations from reactive troubleshooting toward anticipatory resilience analysis.

</details>


### [6] [Hybrid Secure Routing in Mobile Ad-hoc Networks (MANETSs)](https://arxiv.org/abs/2602.13204)
*Soundes Oumaima Boufaida,Abdemadjid Benmachiche,Majda Maatallah,Chaouki Chemam*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Because wireless communication is dynamic and has inherent defects, routing algorithms are crucial in the quickly evolving field of mobile ad hoc networks, or MANETs This study looks at the many security problems that MANETs encounter. These problems, which pose major risks to network performance, include flooding, sinkholes, and black hole assaults to address these challenges. We introduce the Hybrid Secure Routing Protocol (HSRP), which enhances the security and robustness of routing operations by fusing trust-based tactics with cryptographic approaches. HSRP combines the strengths of both proactive and reactive routing strategies, enabling it to adapt dynamically to evolving network conditions while protecting against malicious activities. We use extensive simulations with Network Simulator (NS-2) and a thorough review of the literature to assess HSRP's performance under different attack scenarios. The results show that, in comparison to traditional protocols, HSRP increases throughput and decreases latency, hence improving routing efficiency while simultaneously bolstering data transfer security. With uses in vital domains including military operations and disaster response, this study provides a scalable and workable approach for safe routing in MANETs. The findings highlight how crucial it is to include cutting-edge security features in routing protocol design to guarantee the dependability and integrity of MANETs in practical situations.

</details>


### [7] [Reinforcement Learning-Enabled Dynamic Code Assignment for Ultra-Dense IoT Networks: A NOMA-Based Approach to Massive Device Connectivity](https://arxiv.org/abs/2602.13205)
*Sumita Majhi,Kishan Thakkar,Pinaki Mitra*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Ultra-dense IoT networks require an effective non-orthogonal multiple access (NOMA) scheme, yet they experience intense interference because of fixed code assignment. We suggest a reinforcement learning (RL) model of dynamic Gold code assignment in IoT-NOMA networks. Our Markov Decision Process which is IoT aware is a joint optimization of throughput, energy efficiency, and fairness. Two RL algorithms are created, including Natural Policy Gradient (NPG) to learn stable discrete actions and Deep Deterministic Policy Gradient (DDPG) with continuous code embedding. Under smart city conditions, NPG can attain throughput of 11.6% and energy efficiency of 15.8 likewise superior to its performance with a static allocation. Nonetheless, the performance is worse in organized industrial settings, and the reliability is minimal (0-2%), which points to the fact that dynamic code assignment is not a sufficient measure of ultra-reliable IoT and needs to be supplemented by power control or retransmission schemes. The work offers a basis to the RL-based resource allocation in massive IoT network.

</details>


### [8] [Toward Resource-Efficient Collaboration of Large AI Models in Mobile Edge Networks](https://arxiv.org/abs/2602.13206)
*Peichun Li,Liping Qian,Dusit Niyato,Shiwen Mao,Yuan Wu*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The collaboration of large artificial intelligence (AI) models in mobile edge networks has emerged as a promising paradigm to meet the growing demand for intelligent services at the network edge. By enabling multiple devices to cooperatively execute submodels or subtasks, collaborative AI enhances inference efficiency and service quality with constrained resources. However, deploying large AI models in such environments remains challenging due to the intrinsic mismatch between model complexity and the limited computation, memory, and communication resources in edge networks. This article provides a comprehensive overview of the system architecture for collaborative AI in mobile edge networks, along with representative application scenarios in transportation and healthcare. We further present recent advances in resource-efficient collaboration techniques, categorized into spatial and temporal approaches. The major spatial approaches include federated tuning, mixture of experts, patch-based diffusion, and hierarchical diffusion. Meanwhile, the important temporal approaches encompass split learning, cascading inference, speculative decoding, and routing inference. Building upon these foundations, we propose a multi-stage diffusion framework that enables elastic distribution of large generative models across heterogeneous edge resources. Experimental results demonstrate that our framework achieves performance improvement in both efficiency and adaptability for data generation.

</details>


### [9] [A Safety-Constrained Reinforcement Learning Framework for Reliable Wireless Autonomy](https://arxiv.org/abs/2602.13207)
*Abdikarim Mohamed Ibrahim,Rosdiadee Nordin*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Artificial intelligence (AI) and reinforcement learning (RL) have shown significant promise in wireless systems, enabling dynamic spectrum allocation, traffic management, and large-scale Internet of Things (IoT) coordination. However, their deployment in mission-critical applications introduces the risk of unsafe emergent behaviors, such as UAV collisions, denial-of-service events, or instability in vehicular networks. Existing safety mechanisms are predominantly reactive, relying on anomaly detection or fallback controllers that intervene only after unsafe actions occur, which cannot guarantee reliability in ultra-reliable low-latency communication (URLLC) settings. In this work, we propose a proactive safety-constrained RL framework that integrates proof-carrying control (PCC) with empowerment-budgeted (EB) enforcement. Each agent action is verified through lightweight mathematical certificates to ensure compliance with interference constraints, while empowerment budgets regulate the frequency of safety overrides to balance safety and autonomy. We implement this framework on a wireless uplink scheduling task using Proximal Policy Optimization (PPO). Simulation results demonstrate that the proposed PCC+EB controller eliminates unsafe transmissions while preserving system throughput and predictable autonomy. Compared with unconstrained and reactive baselines, our method achieves provable safety guarantees with minimal performance degradation. These results highlight the potential of proactive safety constrained RL to enable trustworthy wireless autonomy in future 6G networks.

</details>


### [10] [Large Language Model (LLM)-enabled Reinforcement Learning for Wireless Network Optimization](https://arxiv.org/abs/2602.13210)
*Jie Zheng,Ruichen Zhang,Dusit Niyato,Haijun Zhang,Jiacheng Wang,Hongyang Du,Jiawen Kang,Zehui Xiong*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Enhancing future wireless networks presents a significant challenge for networking systems due to diverse user demands and the emergence of 6G technology. While reinforcement learning (RL) is a powerful framework, it often encounters difficulties with high-dimensional state spaces and complex environments, leading to substantial computational demands, distributed intelligence, and potentially inconsistent outcomes. Large language models (LLMs), with their extensive pretrained knowledge and advanced reasoning capabilities, offer promising tools to enhance RL in optimizing 6G wireless networks. We explore RL models augmented by LLMs, emphasizing their roles and the potential benefits of their synergy in wireless network optimization. We then examine LLM-enabled RL across various protocol layers: physical, data link, network, transport, and application layers. Additionally, we propose an LLM-assisted state representation and semantic extraction to enhance the multi-agent reinforcement learning (MARL) framework. This approach is applied to service migration and request routing, as well as topology graph generation in unmanned aerial vehicle (UAV)-satellite networks. Through case studies, we demonstrate that our framework effectively performs optimization of wireless network. Finally, we outline prospective research directions for LLM-enabled RL in wireless network optimization.

</details>


### [11] [An Overlay Multicast Routing Method Based on Network Situational Aware-ness and Hierarchical Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.13211)
*Miao Ye,Yanye Chen,Yong Wang,Cheng Zhu,Qiuxiang Jiang,Gai Huang,Feng Ding*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Compared with IP multicast, Overlay Multicast (OM) offers better compatibility and flexible deployment in heterogeneous, cross-domain networks. However, traditional OM struggles to adapt to dynamic traffic due to unawareness of physical resource states, and existing reinforcement learning methods fail to decouple OM's tightly coupled multi-objective nature, leading to high complexity, slow convergence, and instability. To address this, we propose MA-DHRL-OM, a multi-agent deep hierarchical reinforcement learning approach. Using SDN's global view, it builds a traffic-aware model for OM path planning. The method decomposes OM tree construction into two stages via hierarchical agents, reducing action space and improving convergence stability. Multi-agent collaboration balances multi-objective optimization while enhancing scalability and adaptability. Experiments show MA-DHRL-OM outperforms existing methods in delay, bandwidth utilization, and packet loss, with more stable convergence and flexible routing.

</details>


### [12] [Network-Adaptive Cloud Preprocessing for Visual Neuroprostheses](https://arxiv.org/abs/2602.13216)
*Jiayi Liu,Yilin Wang,Michael Beyeler*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cloud-based machine learning is increasingly explored as a preprocessing strategy for next-generation visual neuroprostheses, where advanced scene understanding may exceed the computational and energy constraints of battery-powered visual processing units (VPUs). Offloading computation to remote servers enables the use of state-of-the-art vision models, but also introduces sensitivity to network latency, jitter, and packet loss, which can disrupt the temporal consistency of the delivered neural stimulus. In this work, we examine the feasibility of cloud-assisted visual preprocessing for artificial vision by framing remote inference as a perceptually constrained systems problem. We present a network-adaptive cloud-assisted pipeline in which real-time round-trip-time (RTT) feedback is used to dynamically modulate image resolution, compression, and transmission rate, explicitly prioritizing temporal continuity under adverse network conditions. Using a Raspberry Pi 4 as a simulated VPU and a client-server architecture, we evaluate system performance across a range of realistic wireless network regimes. Results show that adaptive visual encoding substantially reduces end-to-end latency during network congestion, with only modest degradation of global scene structure, while boundary precision degrades more sharply. Together, these findings delineate operating regimes in which cloud-assisted preprocessing may remain viable for future visual neuroprostheses and underscore the importance of network-aware adaptation for maintaining perceptual stability.

</details>


### [13] [An Agentic AI Control Plane for 6G Network Slice Orchestration, Monitoring, and Trading](https://arxiv.org/abs/2602.13227)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Tharaka Hewa,Abdul Rahman,Xueping Liang,Safdar H. Bouk,Amin Hass,Peter Foytik,Ng Wee Keong,Kasun De Zoysa*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: 6G networks are expected to be AI-native, intent-driven, and economically programmable, requiring fundamentally new approaches to network slice orchestration. Existing slicing frameworks, largely designed for 5G, rely on static policies and manual workflows and are ill-suited for the dynamic, multi-domain, and service-centric nature of emerging 6G environments. In this paper, we propose an agentic AI control plane architecture for 6G network slice orchestration, monitoring, and trading that treats orchestration as a holistic control function encompassing slice planning, deployment, continuous monitoring, and economically informed decision-making. The proposed control plane is realized as a layered architecture in which multiple cooperating AI agents. To support flexible and on-demand slice utilization, the control plane incorporates market-aware orchestration capabilities, allowing slice requirements, pricing, and availability to be jointly considered during orchestration decisions. A natural language interface, implemented using the Model Context Protocol (MCP), enables users and applications to interact with control-plane functions through intent-based queries while enforcing safety and policy constraints. To ensure responsible and explainable autonomy, the control plane integrates fine-tuned large language models organized as a multi-model consortium, governed by a dedicated reasoning model. The proposed approach is evaluated using a real-world testbed with multiple mobile core instances (e.g Open5GS) integrated with Ericsson's RAN infrastructure. The results demonstrate that combining agentic autonomy, closed-loop SLA assurance, market-aware orchestration, and natural language control enables a scalable and adaptive 6G-native control plane for network slice management, highlighting the potential of agentic AI as a foundational mechanism for future 6G networks.

</details>


### [14] [Pocket RAG: On-Device RAG for First Aid Guidance in Offline Mobile Environment](https://arxiv.org/abs/2602.13229)
*Dong Ho Kang,Hyunjoon Lee,Hyeonjeong Cha,Minkyu Choi,Sungsoo Lim*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In disaster scenarios or remote areas, first responders often lose network connectivity when providing first aid. In such situations, server-based AI systems fail to provide critical guidance. To address this issue, we present a lightweight, mobile-based retrieval-augmented generation system for small language models (SLMs) that can run directly on Android devices. Our system integrates a mobile-friendly optimized pipeline featuring Hybrid RAG, selective compression, batched prompt decoding, and quantization caching. Despite the model's small size, our RAG-based system achieves 94.5\% accuracy for physical first aid and 97.0\% for psychological first aid. Additionally, we reduce response time from 14.2s to 3.7s, achieving a nearly 4x speedup. These results prove that our system is practical and can deliver reliable first aid guidance even without internet connectivity.

</details>


### [15] [An Explainable Failure Prediction Framework for Neural Networks in Radio Access Networks](https://arxiv.org/abs/2602.13231)
*Khaleda Papry,Francesco Spinnato,Marco Fiore,Mirco Nanni,Israat Haque*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As 5G networks continue to evolve to deliver high speed, low latency, and reliable communications, ensuring uninterrupted service has become increasingly critical. While millimeter wave (mmWave) frequencies enable gigabit data rates, they are highly susceptible to environmental factors, often leading to radio link failures (RLF). Predictive models leveraging radio and weather data have been proposed to address this issue; however, many operate as black boxes, offering limited transparency for operational deployment. This work bridges that gap by introducing a framework that combines explainability based feature pruning with model refinement. Our framework can be integrated into state of the art predictors such as GNN Transformer and LSTM based architectures for RLF prediction, enabling the development of accurate and explainability guided models in 5G networks. It provides insights into the contribution of input features and the decision making logic of neural networks, leading to lighter and more scalable models. When applied to RLF prediction, our framework unveils that weather data contributes minimally to the forecast in extensive real world datasets, which informs the design of a leaner model with 50 percent fewer parameters and improved F1 scores with respect to the state of the art solution. Ultimately, this work empowers network providers to evaluate and refine their neural network based prediction models for better interpretability, scalability, and performance.

</details>


### [16] [Securing SIM-Assisted Wireless Networks via Quantum Reinforcement Learning](https://arxiv.org/abs/2602.13238)
*Le-Hung Hoang,Quang-Trung Luu,Dinh Thai Hoang,Diep N. Nguyen,Van-Dinh Nguyen*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stacked intelligent metasurfaces (SIMs) have recently emerged as a powerful wave-domain technology that enables multi-stage manipulation of electromagnetic signals through multilayer programmable architectures. While SIMs offer unprecedented degrees of freedom for enhancing physical-layer security, their extremely large number of meta-atoms leads to a high-dimensional and strongly coupled optimization space, making conventional design approaches inefficient and difficult to scale. Moreover, existing deep reinforcement learning (DRL) techniques suffer from slow convergence and performance degradation in dynamic wireless environments with imperfect knowledge of passive eavesdroppers. To overcome these challenges, we propose a hybrid quantum proximal policy optimization (Q-PPO) framework for SIM-assisted secure communications, which jointly optimizes transmit power allocation and SIM phase shifts to maximize the average secrecy rate under power and quality-of-service constraints. Specifically, a parameterized quantum circuit is embedded into the actor network, forming a hybrid classical-quantum policy architecture that enhances policy representation capability and exploration efficiency in high-dimensional continuous action spaces. Extensive simulations demonstrate that the proposed Q-PPO scheme consistently outperforms DRL baselines, achieving approximately 15% higher secrecy rates and 30% faster convergence under imperfect eavesdropper channel state information. These results establish Q-PPO as a powerful optimization paradigm for SIM-enabled secure wireless networks.

</details>


### [17] [Intent-driven Diffusion-based Path for Mobile Data Collector in IoT-enabled Dense WSNs](https://arxiv.org/abs/2602.13277)
*Uma Mahesh Boda,Mallikharjuna Rao Nuka*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mobile data collection using controllable sinks is an effective approach to improve energy efficiency and data freshness in densely deployed wireless sensor networks (WSNs). However, existing path-planning methods are often heuristic-driven and lack the flexibility to adapt to high-level operational objectives under dynamic network conditions. In this paper, we propose ID2P2, a intent-driven diffusion-based path planning framework for jointly addresses rendezvous point selection and mobile data collector (MDC) tour construction in IoT-enabled dense WSNs. High-level intents, such as latency minimization, energy balancing, or coverage prioritization, are explicitly modeled and incorporated into a generative diffusion planning process that produces feasible and adaptive data collection trajectories. The proposed approach learns a trajectory prior that captures spatial node distribution and network characteristics, enabling the MDC to generate paths that align with specified intents while maintaining collision-free and energy-aware operation. Extensive simulations are conducted to evaluate the effectiveness of the proposed framework against conventional path-planning baselines. The results demonstrate that ID2P2 consistently outperforms representative baselines, achieving up to 25-30% reduction in tour completion time and travel overhead, approximately 10-30% improvement in data freshness, and 15-30% gains in energy efficiency and packet delivery performance, while maintaining higher throughput and fairness as network density increases, confirming its robustness and scalability for WSNs.

</details>


### [18] [Parametric-Sensitivity Aware Retransmission for Efficient AI Downloading](https://arxiv.org/abs/2602.13607)
*You Zhou,Qunsong Zeng,Kaibin Huang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The edge artificial intelligence (AI) applications in next-generation mobile networks demand efficient AI-model downloading techniques to support real-time, on-device inference. However, transmitting high-dimensional AI models over wireless channels remains challenging due to limited communication resources. To address this issue, we propose a parametric-sensitivity-aware retransmission (PASAR) framework that manages radio-resource usage of different parameter packets according to their importance on model inference accuracy, known as parametric sensitivity. Empirical analysis reveals a highly right-skewed sensitivity distribution, indicating that only a small fraction of parameters significantly affect model performance. Leveraging this insight, we design a novel online retransmission protocol, i.e., the PASAR protocol, that adaptively terminates packet transmission based on real-time bit error rate (BER) measurements and the associated parametric sensitivity. The protocol employs an adaptive, round-wise stopping criterion, enabling heterogeneous, packet-level retransmissions that preserve overall model functionality but reduce overall latency. Extensive experiments across diverse deep neural network architectures and real-world datasets demonstrate that PASAR substantially outperforms classical hybrid automatic repeat request (HARQ) schemes in terms of communication efficiency and latency.

</details>


### [19] [GraFSTNet: Graph-based Frequency SpatioTemporal Network for Cellular Traffic Prediction](https://arxiv.org/abs/2602.13282)
*Ziyi Li,Hui Ma,Fei Xing,Chunjiong Zhang,Ming Yan*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With rapid expansion of cellular networks and the proliferation of mobile devices, cellular traffic data exhibits complex temporal dynamics and spatial correlations, posing challenges to accurate traffic prediction. Previous methods often focus predominantly on temporal modeling or depend on predefined spatial topologies, which limits their ability to jointly model spatio-temporal dependencies and effectively capture periodic patterns in cellular traffic. To address these issues, we propose a cellular traffic prediction framework that integrates spatio-temporal modeling with time-frequency analysis. First, we construct a spatial modeling branch to capture inter-cell dependencies through an attention mechanism, minimizing the reliance on predefined topological structures. Second, we build a time-frequency modeling branch to enhance the representation of periodic patterns. Furthermore, we introduce an adaptive-scale LogCosh loss function, which adjusts the error penalty based on traffic magnitude, preventing large errors from dominating the training process and helping the model maintain relatively stable prediction accuracy across different traffic intensities. Experiments on three open-sourced datasets demonstrate that the proposed method achieves prediction performance superior to state-of-the-art approaches.

</details>


### [20] [AGORA: Agentic Green Orchestration Architecture for Beyond 5G Networks](https://arxiv.org/abs/2602.13290)
*Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,Maycon Peixoto,Flavio De Oliveira Silva*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Effective management and operational decision-making for complex mobile network systems present significant challenges, particularly when addressing conflicting requirements such as efficiency, user satisfaction, and energy-efficient traffic steering. The literature presents various approaches aimed at enhancing network management, including the Zero-Touch Network (ZTN) and Self-Organizing Network (SON); however, these approaches often lack a practical and scalable mechanism to consider human sustainability goals as input, translate them into energy-aware operational policies, and enforce them at runtime. In this study, we address this gap by proposing the AGORA: Agentic Green Orchestration Architecture for Beyond 5G Networks. AGORA embeds a local tool-augmented Large Language Model (LLM) agent in the mobile network control loop to translate natural-language sustainability goals into telemetry-grounded actions, actuating the User Plane Function (UPF) to perform energy-aware traffic steering. The findings indicate a strong latency-energy coupling in tool-driven control loops and demonstrate that compact models can achieve a low energy footprint while still facilitating correct policy execution, including non-zero migration behavior under stressed Multi-access Edge Computing (MEC) conditions. Our approach paves the way for sustainability-first, intent-driven network operations that align human objectives with executable orchestration in Beyond-5G infrastructures.

</details>


### [21] [Cooperative Edge Caching with Large Language Model in Wireless Networks](https://arxiv.org/abs/2602.13307)
*Ning Yang,Wentao Wang,Lingtao Ouyang,Haijun Zhang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cooperative edge caching in overlapping zones creates intricate coupling among Base Station (BS) decisions, making content replacement highly sensitive to topology and temporal reuse. While heuristics are often myopic and Deep Reinforcement Learning lacks robustness under dynamics, this paper proposes a Large Language Model (LLM)-based multi-BS orchestrator. The LLM acts as the sole autonomous engine, interacting with the environment via a validated text-to-action interface. Each time slot, the system renders environmental states -- including cache inventories and frequency statistics -- into prompts, parsing LLM-generated decisions against strict feasibility constraints. We align the model through a two-stage paradigm: Supervised Fine-Tuning on oracle trajectories for syntax and initialization, followed by Group Relative Policy Optimization. The latter employs an ``opportunity-aware'' reward that prioritizes multi-step cooperative gains relative to a No-Operation baseline. Evaluated on identical request traces, the orchestrator approaches exhaustive-search performance (0.610 vs.\ 0.617 in a 5-BS scenario), outperforms classical baselines (e.g., +4.1\% over least-frequently used), and demonstrates robust zero-shot transfer across varying cache capacities, library sizes, and user densities.

</details>


### [22] [Resilient and Freshness-Aware Scheduling for Industrial Multi-Hop IAB Networks: A Packet Duplication Approach](https://arxiv.org/abs/2602.13311)
*Shuo Zhu,Siyu Lin,Zijing Wang,Qiao Ren,Xiaoheng Deng,Bo Ai*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In industrial millimeter-wave (mmWave) multi-hop Integrated Access and Backhaul (IAB) networks, dynamic blockages caused by moving obstacles pose a severe threat to robust and continuous networks. While Packet Duplication (PD) enhances reliability by path diversity, it inevitably doubles the traffic load, leading to severe congestion and degraded Age of Information (AoI). To navigate this reliability-congestion trade-off, we formulated an optimization problem in a multi-hop IAB scenario that minimizes the average AOI while satisfying strict queue stability constraints. We utilize Lyapunov optimization to transform the long-term stochastic optimization problem into tractable deterministic sub-problems. To solve these sub-problems efficiently, we propose a Resilient and Freshness-Aware Scheduling (RFAS) algorithm. Simulation results show that in blockage-prone environments, RFAS significantly outperforms baselines by maintaining a Packet Delivery Ratio (PDR) above 95\%. Crucially, it strictly guarantees queue stability under hard buffer constraints, whereas baselines suffer from buffer overflows. Furthermore, RFAS reduces the network load imbalance by 19\% compared to the baseline in high-frequency traffic scenarios. This confirms RFAS as a robust and sustainable solution for real-time industrial control loops.

</details>


### [23] [Semantic Waveforms for AI-Native 6G Networks](https://arxiv.org/abs/2602.13316)
*Nour Hello,Mohamed Amine Hamoura,Francois Rivet,Emilio Calvanese Strinati*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we propose a semantic-aware waveform design framework for AI-native 6G networks that jointly optimizes physical layer resource usage and semantic communication efficiency and robustness, while explicitly accounting for the hardware constraints of RF chains. Our approach, called Orthogonal Semantic Sequency Division Multiplexing (OSSDM), introduces a parametrizable, orthogonal-base waveform design that enables controlled degradation of the wireless transmitted signal to preserve semantically significant content while minimizing resource consumption. We demonstrate that OSSDM not only reinforces semantic robustness against channel impairments but also improves semantic spectral efficiency by encoding meaningful information directly at the waveform level. Extensive numerical evaluations show that OSSDM outperforms conventional OFDM waveforms in spectral efficiency and semantic fidelity. The proposed semantic waveform co-design opens new research frontiers for AI-native, intelligent communication systems by enabling meaning-aware physical signal construction through the direct encoding of semantics at the waveform level.

</details>


### [24] [3D Wi-Fi Signal Measurement in Realistic Digital Twin Testbed Environments Using Ray Tracing](https://arxiv.org/abs/2602.13340)
*Mengyuan Wang,Haopeng Wang,Haiwei Dong,Abdulmotaleb El Saddik*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate and efficient modeling of indoor wireless signal propagation is crucial for the deployment of next-generation Wi-Fi. This paper presents a digital twin-based measurement system that integrates real-world 3D environment reconstruction with deterministic ray tracing for physically grounded electromagnetic modeling. Building geometry is obtained through LiDAR scanning, followed by object segmentation and assignment of ITU-R standard material parameters. The propagation process is simulated with a GPU-accelerated ray-tracing engine that generates path-level channel attributes, including delay, power, angular dispersion, and Ricean K-factor. Under identical runtime constraints, the proposed system is evaluated against a commercial measurement simulator, demonstrating up to 21 dB higher path gain and consistently improved signal-to-interference-plus-noise ratio in line-of-sight conditions. Additionally, experiments against onsite RSSI measurements confirm a high spatial correlation of 0.98 after calibration, proving the system's fidelity in real-world settings. Furthermore, coverage analysis across 2.4 GHz, 5 GHz, and 6 GHz bands demonstrates the capability of system to model frequency-dependent material attenuation for Wi-Fi 6E/7 networks. Finally, the system offers interactive 3D visualization and on-demand data extraction, highlighting its potential for digital twin-driven wireless system design and optimization.

</details>


### [25] [Location as a service with a MEC architecture](https://arxiv.org/abs/2602.13358)
*Christopher Schahn,Jorin Kouril,Bernd Schaeufele,Ilja Radusch*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In recent years, automated driving has become viable, and advanced driver assistance systems (ADAS) are now part of modern cars. These systems require highly precise positioning. In this paper, a cooperative approach to localization is presented. The GPS information from several road users is collected in a Mobile Edge Computing cloud, and the characteristics of GNSS positioning are used to provide lane-precise positioning for all participants by applying probabilistic filters and HD maps.

</details>


### [26] [Parametric Traversal for Multi-Dimensional Cost-Aware Graph Reasoning](https://arxiv.org/abs/2602.13369)
*Nicolas Tacheny*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Classical path search assumes complete graphs and scalar optimization metrics, yet real infrastructure networks are incomplete and require multi-dimensional evaluation. We introduce the concept of traversal: a generalization of paths that combines existing edges with gap transitions, missing but acceptable connections representing links that can be built. This abstraction captures how engineers actually reason about infrastructure: not just what exists, but what can be realized.
  We present a parametric framework that treats planned connections as first-class transitions, scales to large graphs through efficient candidate filtering, and uses multi-dimensional criteria to decide whether a traversal should continue to be explored or be abandoned. We evaluate the framework through representative scenarios in datacenter circuit design and optical route construction in telecommunication networks, demonstrating conditional feasibility, non-scalarizable trade-offs, and policy calibration capabilities beyond the reach of classical formulations.

</details>


### [27] [Spatiotemporal Feature Alignment and Weighted Fusion in Collaborative Perception Enabled by Network Synchronization and Age of Information](https://arxiv.org/abs/2602.13439)
*Qiaomei Han,Xianbin Wang,Minghui Liwang,Dusit Niyato*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Collaborative perception in Internet of Vehicles (IoV) aggregates multi-vehicle observations for broader scene coverage and improved decision-making. However, fusion quality degrades under spatiotemporal heterogeneity from unsynchronized clocks, communication delays, and motion variations across vehicles. Prior work mitigates these through spatial transformations or fixed time-offset corrections, overlooking time-varying clock drifts and delays that cause persistent feature misalignment. To overcome these, we propose a spatiotemporal feature alignment and weighted fusion framework. Specifically, network synchronization is designed to continuously compensate for clock state differences between vehicles and establish a common time reference, onto which all feature timestamps can be mapped. After synchronization, to align the freshness of received features since their generation, their Age of Information (AoI) is determined by estimating network delay with given feature size and link quality. Our spatiotemporal feature alignment then projects vehicles' features into one spatial coordinate and corrects them to a synchronized fusion instant using AoIs, enabling all features to describe the scene coherently. Furthermore, due to varying synchronization and alignment quality, we estimate their uncertainties and integrate with AoI to generate feature weights for efficient fusion, prioritizing fresh, reliable feature regions. Simulations show consistent perception accuracy improvements over strong baselines under clock drifts and link delays.

</details>


### [28] [SIDSense: Database-Free TV White Space Sensing for Disaster-Resilient Connectivity](https://arxiv.org/abs/2602.13542)
*George M. Gichuru,Zoe Aiyanna M. Cayetano*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Small Island Developing States (SIDS) are disproportionately exposed to climate-driven disasters, yet often rely on fragile terrestrial networks that fail when they are most needed. TV White Space (TVWS) links offer long-range, low-power coverage; however, current deployments depend on Protocol to Access White Spaces (PAWS) database connectivity for channel authorization, creating a single point of failure during outages.
  We present SIDSense, an edge AI framework for database-free TVWS operation that preserves regulatory intent through a compliance-gated controller, audit logging, and graceful degradation. SIDSense couples CNN-based spectrum classification with a hybrid sensing-first, authorization-as-soon-as-possible workflow and co-locates sensing and video enhancement with a private 5G stack on a maritime vessel to sustain situational-awareness video backhaul.
  Field experiments in Barbados demonstrate sustained connectivity during simulated PAWS outages, achieving 94.2% sensing accuracy over 470-698 MHz with 23 ms mean decision latency, while maintaining zero missed 5G Layer-1 (L1) deadlines under GPU-aware scheduling. We release an empirical Caribbean TVWS propagation and occupancy dataset and look to contribute some of the components of the SIDSense pipeline to the open source community to accelerate resilient connectivity deployments in climate-vulnerable regions.

</details>


### [29] [Multi-Modal Sensing and Fusion in mmWave Beamforming for Connected Vehicles: A Transformer Based Framework](https://arxiv.org/abs/2602.13606)
*Muhammad Baqer Mollah,Honggang Wang,Mohammad Ataul Karim,Hua Fang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Millimeter wave (mmWave) communication, utilizing beamforming techniques to address the inherent path loss limitation, is considered as one of the key technologies to support ever increasing high throughput and low latency demands of connected vehicles. However, adopting standard defined beamforming approach in highly dynamic vehicular environments often incurs high beam training overheads and reduction in the available airtime for communications, which is mainly due to exchanging pilot signals and exhaustive beam measurements. To this end, we present a multi-modal sensing and fusion learning framework as a potential alternative solution to reduce such overheads. In this framework, we first extract the representative features from the sensing modalities by modality specific encoders, then, utilize multi-head cross-modal attention to learn dependencies and correlations between different modalities, and subsequently fuse the multimodal features to obtain predicted top-k beams so that the best line-of-sight links can be proactively established. To show the generalizability of the proposed framework, we perform a comprehensive experiment in four different vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) scenarios from real world multimodal and 60 GHz mmWave wireless sensing data. The experiment reveals that the proposed framework (i) achieves up to 96.72% accuracy on predicting top-15 beams correctly, (ii) incurs roughly 0.77 dB average power loss, and (iii) improves the overall latency and beam searching space overheads by 86.81% and 76.56% respectively for top-15 beams compared to standard defined approach.

</details>


### [30] [Compact LLM Deployment and World Model Assisted Offloading in Mobile Edge Computing](https://arxiv.org/abs/2602.13628)
*Ruichen Zhang,Xiaofeng Luo,Jiayi He,Dusit Niyato,Jiawen Kang,Zehui Xiong,Yonghui Li*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates compact large language model (LLM) deployment and world-model-assisted inference offloading in mobile edge computing (MEC) networks. We first propose an edge compact LLM deployment (ECLD) framework that jointly applies structured pruning, low-bit quantization, and knowledge distillation to construct edge-deployable LLM variants, and we evaluate these models using four complementary metrics: accessibility, energy consumption, hallucination rate, and generalization accuracy. Building on the resulting compact models, we formulate an MEC offloading optimization problem that minimizes the long-term average inference latency subject to per-device energy budgets and LLM-specific quality-of-service constraints on effective accuracy and hallucination. To solve this problem under unknown and time-varying network dynamics, we develop a world model-proximal policy optimization (PPO) algorithm, which augments an on-policy PPO algorithm with a learned recurrent world model that provides improved value targets and short imagination rollouts. Extensive experiments on Llama-3.1-8B, Qwen3-8B, and Mistral-12B show that ECLD compresses base models by about 70-80% in storage (i.e., from 15.3 GB to 3.3 GB for Llama-3.1-8B) and reduces per-query energy consumption by up to 50%, while largely preserving accuracy and often lowering hallucination compared with quantization-only or pruning-only baselines. Moreover, they also show that world model-PPO speeds up convergence by about 50%, improves the final reward by 15.8% over vanilla PPO, and reduces average inference latency by 12-30% across different user populations, while satisfying the accuracy and hallucination constraints and approaching the generation quality of always-offloading with much of the efficiency of local execution.

</details>


### [31] [LEAD-Drift: Real-time and Explainable Intent Drift Detection by Learning a Data-Driven Risk Score](https://arxiv.org/abs/2602.13672)
*Md. Kamrul Hossain,Walid Aljoby*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Intent-Based Networking (IBN) simplifies network management, but its reliability is challenged by "intent drift", where the network's state gradually deviates from its intended goal, often leading to silent failures. Conventional approaches struggle to detect the subtle, early stages of intent drift, raising alarms only when degradation is significant and failure is imminent, which limits their effectiveness for proactive assurance. To address this, we propose LEAD-Drift, a framework that detects intent drift in real time to enable proactive failure prevention. LEAD-Drift's core contribution is reformulating intent failure detection as a supervised learning problem by training a lightweight neural network on fixed-horizon labels to predict a future risk score. The model's raw output is then smoothed with an Exponential Moving Average (EMA) and passed through a statistically tuned threshold to generate robust, real-time alerts. Furthermore, we enhance the framework with two key features for operational intelligence: a multi-horizon modeling technique for dynamic time-to-failure estimation, and per-alert explainability using SHAP to identify root-cause KPIs. Our evaluation on a time-series dataset shows LEAD-Drift provides significantly earlier warnings, improving the average lead time by 7.3 minutes (+17.8\%) compared to a distance-based baseline. It also reduces alert noise by 80.2\% compared to a weighted-KPI heuristic, with only a minor trade-off in lead time. These results demonstrate that LEAD-Drift as a highly effective, interpretable, and operationally efficient solution for proactive network assurance in IBN.

</details>


### [32] [Agent-OSI: A Layered Protocol Stack Toward a Decentralized Internet of Agents](https://arxiv.org/abs/2602.13795)
*Wenxin Xu,Taotao Wang,Yihan Xia,Shengli Zhang,Soung Chang Liew*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) are accelerating the shift from an Internet of information to an Internet of Agents (IoA), where autonomous entities discover services, negotiate, execute tasks, and exchange value. Yet today's agents are still confined to platform silos and proprietary interfaces, lacking a common stack for interoperability, trust, and pay-per-use settlement. This article proposes \textit{Agent-OSI}, a six-layer reference stack for decentralized agent networking built on top of the existing Internet. Agent-OSI combines secure connectivity and A2A messaging, decentralized identity and authorization, settlement and metering, verifiable execution and provenance, and semantic interoperability for orchestration. In particular, we treat HTTP 402 (Payment Required) as an application-level payment challenge (analogous to HTTP 401 for authentication) that triggers escrow-based settlement and verifiable receipts (instantiated via a blockchain escrow in our prototype), rather than introducing a new network-layer protocol. We implement a prototype and evaluate cost and latency. Results show that keeping negotiation and delivery off-chain while preserving verifiable settlement reduces on-chain session costs by approximately 51\% compared with a standard Web3 baseline in our prototype setting, and that blockchain confirmation latency is often not the dominant factor for generative workloads.

</details>


### [33] [Agentic Assistant for 6G: Turn-based Conversations for AI-RAN Hierarchical Co-Management](https://arxiv.org/abs/2602.13868)
*Udhaya Srinivasan,Weisi Guo*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: New generations of radio access networks (RAN), especially with native AI services are increasingly difficult for human engineers to manage in real-time. Enterprise networks are often managed locally, where expertise is scarce. Existing research has focused on creating Retrieval-Augmented Generation (RAG) LLMs that can help to plan and configure RAN and core aspects only. Co-management of RAN and edge AI is the gap, which creates hierarchical and dynamic problems that require turn-based human interactions. Here, we create an agentic network manager and turn-based conversation assistant that can understand human intent-based queries that match hierarchical problems in AI-RAN. The framework constructed consists of: (a) a user interface and evaluation dashboard, (b) an intelligence layer that interfaces with the AI-RAN, and (c) a knowledge layer for providing the basis for evaluations and recommendations. These form 3 layers of capability with the following validation performances (average response time 13s): (1) design and planning a service (78\% accuracy), (2) operating specific AI-RAN tools (89\% accuracy), and (3) tuning AI-RAN performance (67\%). These initial results indicate the universal challenges of hallucination but also fast response performance success that can really reduce OPEX costs for small scale enterprise users.

</details>


### [34] [Toward Autonomous O-RAN: A Multi-Scale Agentic AI Framework for Real-Time Network Control and Management](https://arxiv.org/abs/2602.14117)
*Hojjat Navidan,Mohammad Cheraghinia,Jaron Fontaine,Mohamed Seif,Eli De Poorter,H. Vincent Poor,Ingrid Moerman,Adnan Shahid*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Open Radio Access Networks (O-RAN) promise flexible 6G network access through disaggregated, software-driven components and open interfaces, but this programmability also increases operational complexity. Multiple control loops coexist across the service management layer and RAN Intelligent Controller (RIC), while independently developed control applications can interact in unintended ways. In parallel, recent advances in generative Artificial Intelligence (AI) are enabling a shift from isolated AI models toward agentic AI systems that can interpret goals, coordinate multiple models and control functions, and adapt their behavior over time. This article proposes a multi-scale agentic AI framework for O-RAN that organizes RAN intelligence as a coordinated hierarchy across the Non-Real-Time (Non-RT), Near-Real-Time (Near-RT), and Real-Time (RT) control loops: (i) A Large Language Model (LLM) agent in the Non-RT RIC translates operator intent into policies and governs model lifecycles. (ii) Small Language Model (SLM) agents in the Near-RT RIC execute low-latency optimization and can activate, tune, or disable existing control applications; and (iii) Wireless Physical-layer Foundation Model (WPFM) agents near the distributed unit provide fast inference close to the air interface. We describe how these agents cooperate through standardized O-RAN interfaces and telemetry. Using a proof-of-concept implementation built on open-source models, software, and datasets, we demonstrate the proposed agentic approach in two representative scenarios: robust operation under non-stationary conditions and intent-driven slice resource control.

</details>


### [35] [MILD: Multi-Intent Learning and Disambiguation for Proactive Failure Prediction in Intent-based Networking](https://arxiv.org/abs/2602.14283)
*Md. Kamrul Hossain,Walid Aljoby*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In multi-intent intent-based networks, a single fault can trigger co-drift where multiple intents exhibit symptomatic KPI degradation, creating ambiguity about the true root-cause intent. We present MILD, a proactive framework that reformulates intent assurance from reactive drift detection to fixed-horizon failure prediction with intent-level disambiguation. MILD uses a teacher-augmented Mixture-of-Experts where a gated disambiguation module identifies the root-cause intent while per-intent heads output calibrated risk scores. On a benchmark with non-linear failures and co-drifts, MILD provides 3.8\%--92.5\% longer remediation lead time and improves intent-level root-cause disambiguation accuracy by 9.4\%--45.8\% over baselines. MILD also provides per-alert KPI explanations, enabling actionable diagnosis.

</details>


### [36] [LiSFC-Search: Lifelong Search for Network SFC Optimization under Non-stationary Drifts](https://arxiv.org/abs/2602.14360)
*Zuyuan Zhang,Vaneet Aggarwal,Tian Lan*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Edge-cloud convergence is reshaping service provisioning across 5G/6G and computing power networks (CPNs). Service function chaining (SFC) requires continuously placing and scheduling virtual network functions (VNFs) chains under compute/bandwidth and end-to-end QoS constraints. Most SFC optimizers assume static or stationary networks, and degrade under long-term topology/resource changes (failures, upgrades, expansions) that induce non-stationary graph drifts. We propose LiSFC, a Lipschitz lifelong planner that transfers MCTS statistics across drifting network configurations using an MDP-distance bound. More precisely, we formulate the problem as a sequence of MDPs indexed by the underlying network graph and constraints, and we define a \emph{graph drift} metric that upper-bounds the LiZero MDP distance. This allows LiSFC to import theoretical guarantees on bias and sample efficiency from the LiZero framework while being tailored to cloud-network convergence. We then design \emph{LiSFC-Search}, an SFC-aware unified MCTS (UMCTS) procedure that uses transferable adaptive UCT (aUCT) bonuses to reuse search statistics from prior CPN configurations. Preliminary results on synthetic CPN topologies and SFC workloads show that LiSFC consistently reduces SFC blocking probability and improves tail delay compared to non-transfer MCTS and purely learning-based baselines, highlighting its potential as an AI/ML building block for cloud-network convergence.

</details>


### [37] [Bitcoin Under Stress: Measuring Infrastructure Resilience 2014-2025](https://arxiv.org/abs/2602.14372)
*Wenbin Wu,Alexander Neumueller*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Bitcoin's design promises resilience through decentralization, yet physical infrastructure creates hidden dependencies. We present the first longitudinal study of Bitcoin's resilience to infrastructure failures using 11 years of P2P network data (2014-2025), 658 submarine cables, and 68 verified cable fault events. Using a Buldyrev-style cascade model with a country-level physical layer (225 countries, 354 submarine cable edges, 325 land border edges), we find that Bitcoin's clearnet percolation threshold $p_c \approx 0.72$-$0.92$ for random cable failures, declining 22% from $p_c \approx 0.92$ (2014-2017) to a minimum of $p_c = 0.72$ in 2021 during peak mining concentration. Targeted attacks reduce $p_c$ to 0.05-0.20. To address the 64% of nodes using Tor with unobservable locations, we develop a 4-layer multiplex model incorporating Tor relay infrastructure. Tor relay bandwidth concentrates in well-connected European countries, increasing resilience by $p_c \approx +0.02$-$+0.10$ rather than introducing fragility. Empirical validation shows 87% of cable faults caused less than 5% node impact. We contribute: (1) a multiplex percolation framework for overlay-underlay coupling with a 4-layer Tor relay model; (2) the first empirical measurement of Bitcoin's physical-layer resilience over a decade; and (3) evidence that Tor adoption amplifies resilience with distributional bounds under partial observability.

</details>


### [38] [A Q-Learning Approach for Dynamic Resource Management in Three-Tier Vehicular Fog Computing](https://arxiv.org/abs/2602.14390)
*Bahar Mojtabaei Ranani,Mahmood Ahmadi,Sajad Ahmadian*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, a method for predicting the resources required for an intelligent vehicle client using a three-layer vehicular computing architecture is proposed. This method leverages Q-Learning to optimize resource allocation and enhance overall system performance. This approach employs reinforcement learning capabilities to provide a dynamic and adaptive strategy for resource management in a fog computing environment. The key findings of this study indicate that Q-learning can effectively predict the appropriate allocation of resources by learning from past experiences and making informed decisions. Through continuous training and updating of the Q-learning agent, the system can adapt to changing conditions and make resource allocation decisions based on real-time information. The experimental results demonstrate the effectiveness of the proposed method in optimizing resource allocation. The Q-learning agent predicts the optimal values for memory, bandwidth, and processor. These predictions not only minimize resource consumption but also meet the performance requirements of the fog system. Implementations show that this method improves the average task processing time in compared to other methods evaluated in this study

</details>


### [39] [ASA: Adaptive Smart Agent Federated Learning via Device-Aware Clustering for Heterogeneous IoT](https://arxiv.org/abs/2602.14391)
*Ali Salimi,Saadat Izadi,Mahmood Ahmadi,Hadi Tabatabaee Malazi*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Federated learning (FL) has become a promising answer to facilitating privacy-preserving collaborative learning in distributed IoT devices. However, device heterogeneity is a key challenge because IoT networks include devices with very different computational powers, memory availability, and network environments. To this end, we introduce ASA (Adaptive Smart Agent). This new framework clusters devices adaptively based on real-time resource profiles and adapts customized models suited to every cluster's capability. ASA capitalizes on an intelligent agent layer that examines CPU power, available memory, and network environment to categorize devices into three levels: high-performance, mid-tier, and low-capability. Each level is provided with a model tuned to its computational power to ensure inclusive engagement across the network. Experimental evaluation on two benchmark datasets, MNIST and CIFAR-10, proves that ASA decreases communication burden by 43% to 50%, improves resource utilization by 43%, and achieves final model accuracies of 98.89% on MNIST and 85.30% on CIFAR-10. These results highlight ASA's efficacy in enhancing efficiency, scalability, and fairness in heterogeneous FL environments, rendering it a suitable answer for real-world IoT apps.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [40] [Sequential BP-based Decoding of QLDPC Codes](https://arxiv.org/abs/2602.13420)
*Mohsen Moradi,Salman Habib,Vahid Nourozi,David G. M. Mitchell*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum low-density parity-check (QLDPC) codes are a leading approach to quantum error correction, yet conventional belief propagation (BP) decoders often perform poorly, primarily due to non-convergence exacerbated by stabilizer constraints, which induce short cycles and degeneracy. We propose two scheduling variants, sequential check node scheduling (SCNS) and sequential variable node scheduling (SVNS), that improve BP's error-correction ability by processing check nodes (CNs) or variable nodes (VNs), respectively, in a fixed order, stabilizing message updates and reducing stalls. We also employ this technique to an improved BP-variant called BP guided decimation (BPGD), where symbols are progressively fixed during decoding iterations. Here, we demonstrate that the sequential BPGD (SBPGD) decoder can further improve the convergence properties and performance of the decoder. On standard QLDPC benchmarks under a Pauli-X noise model, our sequential schedules are shown to lower the block error rate relative to conventional BP, and SBPGD outperforms BPGD while using significantly fewer decimation rounds, translating to lower computational cost. These results demonstrate that changing the update schedule, without altering the code, can improve both the reliability and efficiency of BP-based decoding for QLDPC codes. For the [[1922,50,16]] C2 hypergraph-product code with independent X errors, SVNS-BP surpasses BP-OSD-0 in error correction at roughly the same complexity as standard BP.

</details>


### [41] [End-to-End NOMA with Perfect and Quantized CSI Over Rayleigh Fading Channels](https://arxiv.org/abs/2602.13446)
*Selma Benouadah,Mojtaba Vaezi,Ruizhan Shen,Hamid Jafarkhani*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: An end-to-end autoencoder (AE) framework is developed for downlink non-orthogonal multiple access (NOMA) over Rayleigh fading channels, which learns interference-aware and channel-adaptive super-constellations. While existing works either assume additive white Gaussian noise channels or treat fading channels without a fully end-to-end learning approach, our framework directly embeds the wireless channel into both training and inference. To account for practical channel state information (CSI), we further incorporate limited feedback via both uniform and Lloyd-Max quantization of channel gains and analyze their impact on AE training and bit error rate (BER) performance. Simulation results show that, with perfect CSI, the proposed AE outperforms the existing analytical NOMA schemes. In addition, Lloyd-Max quantization achieves superior BER performance compared to uniform quantization. These results demonstrate that end-to-end AEs trained directly over Rayleigh fading can effectively learn robust, interference-aware signaling strategies, paving the way for NOMA deployment in fading environments with realistic CSI constraints.

</details>


### [42] [An Algebraic Invariant for Free Convolutional Codes over Finite Local Rings](https://arxiv.org/abs/2602.13468)
*Mohammed El Oued*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates the algebraic structure of free convolutional codes over the finite local ring Z_{p^r}. We introduce a new structural invariant, the Residual Structural Polynomial, denoted by Delta_p(C) in F_p[D]. We construct this invariant via encoders which are reduced internal degree matrices (RIDM). We formally demonstrate that Delta_p(C) is an intrinsic characteristic of the code, invariant under equivalent RIDMs. A central result of this work is the establishment that Delta_p(C) serves as an algebraic criterion for intrinsic catastrophicity: we prove that a free code C admits a non-catastrophic realization if and only if Delta_p(C) is a monomial of the form D^s. Furthermore, we establish a fundamental duality theorem, proving that Delta_p(C) = Delta_p(C^perp). This result reveals a deep structural symmetry, showing that the "catastrophicity" of a free code is preserved under orthogonality.

</details>


### [43] [Convergence of Differential Entropies -- II](https://arxiv.org/abs/2602.13493)
*Mahesh Godavarti*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We show that under convergence in measure of probability density functions, differential entropy converges whenever the entropy integrands $f_n |\log f_n|$ are uniformly integrable and tight -- a direct consequence of Vitali's convergence theorem. We give an entropy-weighted Orlicz condition: $\sup_n \int f_n\, (|\log f_n|) < \infty$ for a single superlinear $$, strictly weaker than the fixed-$$ condition of Godavarti and Hero (2004). We also disprove the Godavarti-Hero conjecture that $> 1$ could be replaced by $_n \downarrow 1$. We recover the sufficient conditions of Godavarti-Hero, Piera-Parada, and Ghourchian-Gohari-Amini as corollaries, and we show the condition is also necessary on bounded domains.

</details>


### [44] [Constructing Quantum Convolutional Codes via Difference Triangle Sets](https://arxiv.org/abs/2602.13505)
*Vahid Nourozi,David Mitchell*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we introduce a construction of quantum convolutional codes (QCCs) based on difference triangle sets (DTSs). To construct QCCs, one must determine polynomial stabilizers $X(D)$ and $Z(D)$ that commute (symplectic orthogonality), while keeping the stabilizers sparse and encoding memory small. To construct Z(D), we show that one can use a reflection of the DTS indices of X(D), where X(D) corresponds to a classical convolutional self-orthogonal code (CSOC) constructed from strong DTS supports. The motivation of this approach is to provide a constructive design that guarantees a prescribed minimum distance. We provide numerical results demonstrating the construction for a variety of code rates.

</details>


### [45] [Redundancy-Optimal Constructions of $(1,1)$-Criss-Cross Deletion Correcting Codes with Efficient Encoding/Decoding Algorithms](https://arxiv.org/abs/2602.13548)
*Wenhao Liu,Zhengyi Jiang,Zhongyi Huang,Hanxu Hou*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Two-dimensional error-correcting codes, where codewords are represented as $n \times n$ arrays over a $q$-ary alphabet, find important applications in areas such as QR codes, DNA-based storage, and racetrack memories. Among the possible error patterns, $(t_r,t_c)$-criss-cross deletions-where $t_r$ rows and $t_c$ columns are simultaneously deleted-are of particular significance. In this paper, we focus on $q$-ary $(1,1)$-criss-cross deletion correcting codes. We present a novel code construction and develop complete encoding, decoding, and data recovery algorithms for parameters $n \ge 11$ and $q \ge 3$. The complexity of the proposed encoding, decoding, and data recovery algorithms is $\mathcal{O}(n^2)$. Furthermore, we show that for $n \ge 11$ and $q = (n)$ (i.e., there exists a constant $c>0$ such that $q \ge cn$), both the code redundancy and the encoder redundancy of the constructed codes are $2n + 2\log_q n + \mathcal{O}(1)$, which attain the lower bound ($2n + 2\log_q n - 3$) within an $\mathcal{O}(1)$ gap. To the best of our knowledge, this is the first construction that can achieve the optimal redundancy with only an $\mathcal{O}(1)$ gap, while simultaneously featuring explicit encoding and decoding algorithms.

</details>


### [46] [Discrete-Space Generative AI Pipeline for Semantic Transmission of Signals](https://arxiv.org/abs/2602.13556)
*Silvija Kokalj-Filipovic,Yagna Kaasaragadda*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce Discernment, a semantic communication system that transmits the meaning of physical signals (baseband radio and audio) over a technical channel using GenAI models operating in discrete spaces. Discernment dynamically adapts to channel impairments - modeled as erasure channels - by switching between an autoregressive or a diffusion-based generative algorithm, depending on the erasure pattern. Our results show that Discernment maintains semantic integrity even as channel capacity severely degrades, exhibiting very small and graceful performance decline in both classification accuracy and statistical fidelity of the reconstructed meaning. These findings demonstrate Discernment's ability to adjust to diverse physical channel conditions while maintaining spectral efficiency and low model complexity, making it well suited for IoT deployments and strongly motivating further research on this semantic channel paradigm.

</details>


### [47] [UAV Swarm Enabled Aerial Movable Antenna System for Low-Altitude Economy: From Far-Field to Near-Field Communication](https://arxiv.org/abs/2602.13687)
*Haiquan Lu,Chao Feng,Yong Zeng,Shaodan Ma,Long Shi,Shi Jin,Rui Zhang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Unmanned aerial vehicle (UAV) with the intrinsic three-dimensional (3D) mobility provides an ideal platform for implementing aerial movable antenna (AMA) system enabled by UAV swarm cooperation. Besides, AMA system is readily to achieve an extremely large-scale array aperture, rendering the conventional far-field uniform plane wave (UPW) model no longer valid for aerial-to-ground links. This paper studies the UAV swarm enabled near-field AMA communication, by taking into account the non-uniform spherical wave (NUSW) model, where UAV swarm trajectory simultaneously influences the channel amplitude and phase. We formulate a general optimization problem to maximize the minimum average communication rate over user equipments (UEs), by jointly optimizing the 3D UAV swarm trajectory and receive beamforming for all UEs. To draw useful insights, the special case of single UE is first studied, and successive convex approximation (SCA) technique is proposed to efficiently optimize the UAV swarm trajectory. For the special case of placement optimization, the optimal placement positions of UAVs for cases of single UAV and two UAVs are derived in closed-form. Then, for the special case of two UEs, we show that an inter-UE interference (IUI)-free communication can be achieved by symmetrically placing an even number of UAVs along a hyperbola, with its foci corresponding to the locations of the two UEs. Furthermore, for arbitrary number of UEs, an alternating optimization algorithm is proposed to efficiently tackle the non-convex optimization problem. Numerical results validate the significant performance gains over the benchmark schemes.

</details>


### [48] [BRAIN: Bayesian Reasoning via Active Inference for Agentic and Embodied Intelligence in Mobile Networks](https://arxiv.org/abs/2602.14033)
*Osman Tugay Basaran,Martin Maier,Falko Dressler*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Future sixth-generation (6G) mobile networks will demand artificial intelligence (AI) agents that are not only autonomous and efficient, but also capable of real-time adaptation in dynamic environments and transparent in their decisionmaking. However, prevailing agentic AI approaches in networking, exhibit significant shortcomings in this regard. Conventional deep reinforcement learning (DRL)-based agents lack explainability and often suffer from brittle adaptation, including catastrophic forgetting of past knowledge under non-stationary conditions. In this paper, we propose an alternative solution for these challenges: Bayesian reasoning via Active Inference (BRAIN) agent. BRAIN harnesses a deep generative model of the network environment and minimizes variational free energy to unify perception and action in a single closed-loop paradigm. We implement BRAIN as O-RAN eXtended application (xApp) on GPU-accelerated testbed and demonstrate its advantages over standard DRL baselines. In our experiments, BRAIN exhibits (i) robust causal reasoning for dynamic radio resource allocation, maintaining slice-specific quality of service (QoS) targets (throughput, latency, reliability) under varying traffic loads, (ii) superior adaptability with up to 28.3% higher robustness to sudden traffic shifts versus benchmarks (achieved without any retraining), and (iii) real-time interpretability of its decisions through human-interpretable belief state diagnostics.

</details>


### [49] [Energy-Efficient Over-the-Air Federated Learning via Pinching Antenna Systems](https://arxiv.org/abs/2602.14250)
*Saba Asaad,Ali Bereyhi*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Pinching antennas systems (PASSs) have recently been proposed as a novel flexible-antenna technology. These systems are implemented by attaching low-cost pinching elements to dielectric waveguides. As the direct link is bypassed through waveguides, PASSs can effectively compensate large-scale effects of the wireless channel. This work explores the potential gains of employing PASSs for over-the-air federated learning (OTA-FL). For a PASS-assisted server, we develop a low-complexity algorithmic approach, which jointly tunes the PASS parameters and schedules the mobile devices for minimal energy consumption in OTA-FL. We study the efficiency of the proposed design and compare it against the conventional OTA-FL setting with MIMO server. Numerical experiments demonstrate that using a single-waveguide PASS at the server within a moderately sized area, the required energy for model aggregation is drastically reduced as compared to the case with fully-digital MIMO server. This introduces PASS as a potential technology for energy-efficient distributed learning in next generations of wireless systems.

</details>


### [50] [Diversity vs Degrees of Freedom in Gaussian Fading Channels](https://arxiv.org/abs/2602.14371)
*Mahesh Godavarti*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The standard definitions of degrees of freedom (DOF) and diversity both normalize by $\log$. When this ruler is wrong, both measurements give zero or become undefined, yet intuitively DOF and diversity ought to be channel properties, not artifacts of a normalization choice. We formalize this for Gaussian fading channels. For fixed-$H$ MIMO, DOF and diversity are both ranks of the bilinear map~$HX$ with different variables free: $\varepsilon$-covering the image of~$X\!\mapsto\!HX$ gives DOF on the $\log$ gauge; expanding across all dimensions of the fading map gives diversity on the linear~$$ gauge. Covering produces logs; expansion produces linear growth; so in every model studied here the two gauges differ. These geometric definitions do not yield tradeoff curves. We bridge the gap with Bhattacharyya packing, obtaining gauge-DOF and B-diversity as workable proxies -- finite and informative on every gauge, including those where the classical diversity order is zero. Three gauge classes emerge: $\log$, $\log\log$, and $(\log)^$, $\in(0,1)$. The main result is a cross-gauge tradeoff for noncoherent fast fading: capacity lives on $\log\log$, but B-diversity lives on $\log$, exponentially larger, with matching upper and lower bounds. For coherent MIMO, block fading, and irregular-spectrum channels, the same approach recovers or extends known scaling laws.

</details>


### [51] [On the Rate-Distortion-Complexity Tradeoff for Semantic Communication](https://arxiv.org/abs/2602.14481)
*Jingxuan Chai,Yong Xiao,Guangming Shi*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Semantic communication is a novel communication paradigm that focuses on conveying the user's intended meaning rather than the bit-wise transmission of source signals. One of the key challenges is to effectively represent and extract the semantic meaning of any given source signals. While deep learning (DL)-based solutions have shown promising results in extracting implicit semantic information from a wide range of sources, existing work often overlooks the high computational complexity inherent in both model training and inference for the DL-based encoder and decoder. To bridge this gap, this paper proposes a rate-distortion-complexity (RDC) framework which extends the classical rate-distortion theory by incorporating the constraints on semantic distance, including both the traditional bit-wise distortion metric and statistical difference-based divergence metric, and complexity measure, adopted from the theory of minimum description length and information bottleneck. We derive the closed-form theoretical results of the minimum achievable rate under given constraints on semantic distance and complexity for both Gaussian and binary semantic sources. Our theoretical results show a fundamental three-way tradeoff among achievable rate, semantic distance, and model complexity. Extensive experiments on real-world image and video datasets validate this tradeoff and further demonstrate that our information-theoretic complexity measure effectively correlates with practical computational costs, guiding efficient system design in resource-constrained scenarios.

</details>


### [52] [Center-Fed Pinching Antenna System (C-PASS): Modeling, Analysis, and Beamforming Design](https://arxiv.org/abs/2602.14805)
*Xu Gan,Yuanwei Liu*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A generalized framework for the novel center-fed pinching antenna system (C-PASS) is proposed. Within this framework, closed-form expressions for the degree of freedom (DoF) and power scaling law of the proposed C-PASS are first derived. These theoretical results reveal that the achievable DoF scales linearly with the number of input ports, $M$, and the number of receive antennas, $K$. Furthermore, the derived power scaling laws demonstrate that the C-PASS achieves a power gain of order $\mathcal{O}(P_T M)$, where $P_T$ denotes the transmit power. Based on the proposed C-PASS modeling, a sum-rate maximization problem for the joint optimization of transmit and pinching beamforming is then formulated. To solve this highly coupled non-convex problem, an efficient alternating optimization algorithm is developed. More particularly, the transmit precoding and power splitting ratios are updated via derived closed-form solutions, while the pinching antenna positions and radiation coefficients are optimized using block coordinate descent (BCD) methods. Finally, our numerical results reveal that the single-waveguide C-PASS: 1) achieves superior DoF and power scaling laws compared to the single-waveguide PASS; and 2) outperforms the multi-waveguide PASS in high-attenuation regimes, yielding a substantial gain exceeding $10$ dB.

</details>


### [53] [Constructions of linear codes from vectorial plateaued functions and their subfield codes with applications to quantum CSS codes](https://arxiv.org/abs/2602.14832)
*Virginio Fratianni,Sihem Mesnager*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Linear codes over finite fields parameterized by functions have proven to be a powerful tool in coding theory, yielding optimal and few-weight codes with significant applications in secret sharing, authentication codes, and association schemes. In 2023, Xu et al. introduced a construction framework for 3-dimensional linear codes parameterized by two functions, which has demonstrated considerable success in generating infinite families of optimal linear codes. Motivated by this approach, we propose a construction that extends the framework to three functions, thereby enhancing the flexibility of the parameters. Additionally, we introduce a vectorial setting by allowing vector-valued functions, expanding the construction space and the set of achievable structural properties. We analyze both scalar and vectorial frameworks, employing Bent and s-Plateaued functions, including Almost Bent, to define the code generators. By exploiting the properties of the Walsh transform, we determine the explicit parameters and weight distributions of these codes and their punctured versions. A key result of this study is that the constructed codes have few weights, and their duals are distance and dimensionally optimal with respect to both the Sphere Packing and Griesmer bounds. Furthermore, we establish a theoretical connection between our vectorial approach and the classical first generic construction of linear codes, providing sufficient conditions for the resulting codes to be minimal and self-orthogonal. Finally, we investigate applications to quantum coding theory within the Calderbank-Shor-Steane framework.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [54] [SIM-assisted Secure Mobile Communications via Enhanced Proximal Policy Optimization Algorithm](https://arxiv.org/abs/2602.13265)
*Wenxuan Ma,Bin Lin,Hongyang Pan,Geng Sun,Enyu Shi,Jiancheng An,Chau Yuen*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With the development of sixth-generation (6G) wireless communication networks, the security challenges are becoming increasingly prominent, especially for mobile users (MUs). As a promising solution, physical layer security (PLS) technology leverages the inherent characteristics of wireless channels to provide security assurance. Particularly, stacked intelligent metasurface (SIM) directly manipulates electromagnetic waves through their multilayer structures, offering significant potential for enhancing PLS performance in an energy efficient manner. Thus, in this work, we investigate an SIM-assisted secure communication system for MUs under the threat of an eavesdropper, addressing practical challenges such as channel uncertainty in mobile environments, multiple MU interference, and residual hardware impairments. Consequently, we formulate a joint power and phase shift optimization problem (JPPSOP), aiming at maximizing the achievable secrecy rate (ASR) of all MUs. Given the non-convexity and dynamic nature of this optimization problem, we propose an enhanced proximal policy optimization algorithm with a bidirectional long short-term memory mechanism, an off-policy data utilization mechanism, and a policy feedback mechanism (PPO-BOP). Through these mechanisms, the proposed algorithm can effectively capture short-term channel fading and long-term MU mobility, improve sample utilization efficiency, and enhance exploration capabilities. Extensive simulation results demonstrate that PPO-BOP significantly outperforms benchmark strategies and other deep reinforcement learning algorithms in terms of ASR.10.1109/TWC.2026.3658332

</details>


### [55] [Towards Causality-Aware Modeling for Multimodal Brain-Muscle Interactions](https://arxiv.org/abs/2602.13459)
*Farwa Abbas,Wei Dai,Zoran Cvetkovic,Verity McClelland*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Robust characterization of dynamic causal interactions in multivariate biomedical signals is essential for advancing computational and algorithmic methods in biomedical imaging. Conventional approaches, such as Dynamic Bayesian Networks (DBNs), often assume linear or simple statistical dependencies, while manifold based techniques like Convergent Cross Mapping (CCM) capture nonlinear, lagged interactions but lack probabilistic quantification and interventional modeling. We introduce a DBN informed CCM framework that integrates geometric manifold reconstruction with probabilistic temporal modeling. Applied to multimodal EEG-EMG recordings from dystonic and neurotypical children, the method quantifies uncertainty, supports interventional simulation, and reveals distinct frequency specific reorganization of corticomuscular pathways in dystonia. Experimental results show marked improvements in predictive consistency and causal stability as compared to baseline approaches, demonstrating the potential of causality aware multimodal modeling for developing quantitative biomarkers and guiding targeted neuromodulatory interventions.

</details>


### [56] [Blind Deconvolution Demixing using Modulated Inputs](https://arxiv.org/abs/2602.13481)
*Humera Hameed,Ali Ahmed*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper focuses on solving a challenging problem of blind deconvolution demixing involving modulated inputs. Specifically, multiple input signals $s_n(t)$, each bandlimited to $B$ Hz, are modulated with known random sequences $r_n(t)$ that alter at rate $Q$. Each modulated signal is convolved with a different M tap channel of impulse response $h_n(t)$, and the outputs of each channel are added at a common receiver to give the observed signal $y(t)=\sum_{n=1}^N (r_n(t)\odot s_n(t))\circledast h_n(t)$, where $\odot$ is the point wise multiplication, and $\circledast$ is circular convolution. Given this observed signal $y(t)$, we are concerned with recovering $s_n(t)$ and $h_n(t)$. We employ deterministic subspace assumption for the input signal $s_n(t)$ and keep the channel impulse response $h_n(t)$ arbitrary. We show that if modulating sequence is altered at a rate $Q \geq N^2 (B+M)$ and sample complexity bound is obeyed then all the signals and the channels, $\{s_n(t),h_n(t)\}_{n=1}^N$, can be estimated from the observed mixture $y(t)$ using gradient descent algorithm. We have performed extensive simulations that show the robustness of our algorithm and used phase transitions to numerically investigate the theoretical guarantees provided by our algorithm.

</details>


### [57] [Feasibility of simultaneous EEG-fMRI at 0.55 T: Recording, Denoising, and Functional Mapping](https://arxiv.org/abs/2602.13489)
*Parsa Razmara,Takfarinas Medani,Majid Abbasi Sisara,Anand A. Joshi,Rui Chen,Woojae Jeong,Ye Tian,Krishna S. Nayak,Richard M. Leahy*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Simultaneous recording of electroencephalography (EEG) and functional MRI (fMRI) can provide a more complete view of brain function by merging high temporal and spatial resolutions. High-field ($\geq$3T) systems are standard, and require technical trade-offs, including artifacts in the EEG signal, reduced compatibility with metallic implants, high acoustic noise, and artifacts around high-susceptibility areas such as the optic nerve and nasal sinus. This proof-of-concept study demonstrates the feasibility of simultaneous EEG-fMRI at 0.55T in a visual task. We characterize the gradient and ballistocardiogram (BCG) artifacts inherent to this environment and observe reduced BCG magnitude consistent with the expected scaling of pulse-related artifacts with static magnetic field strength. This reduction shows promise for facilitating effective denoising while preserving the alpha rhythm and signal integrity. Furthermore, we tested a multimodal integration pipeline and demonstrated that the EEG power envelope corresponds with the hemodynamic BOLD response, supporting the potential to measure neurovascular coupling in this environment. We demonstrate that combined EEG-fMRI at 0.55T is feasible and represents a promising environment for multimodal neuroimaging.

</details>


### [58] [Sub Specie Aeternitatis: Fourier Transforms from the Theory of Heat to Musical Signals](https://arxiv.org/abs/2602.13520)
*Victor Lazzarini*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: J. B. Fourier in his \emph{Thorie Analytique de la Chaleur} of 1822 introduced, amongst other things, two ideas that have made a fundamental impact in fields as diverse as Mathematical Physics, Electrical Engineering, Computer Science, and Music. The first one of these, a method to find the coefficients for a trigonometric series describing an arbitrary function, was very early on picked up by G. Ohm and H. Helmholtz as the foundation for a theory of \emph{musical tones}. The second one, which is described by Fourier's double integral, became the basis for treating certain kinds of infinity in discontinuous functions, as shown by A. De Morgan in his 1842 \emph{The Differential and Integral Calculus}. Both make up the fundamental basis for what is now commonly known as the \emph{Fourier theorem}. With the help of P. A. M. Dirac's insights into the nature of these infinities, we can have a compact description of the frequency spectrum of a function of time, or conversely of a waveform corresponding to a given function of frequency. This paper, using solely primary sources, takes us from the physics of heat propagation to the modern theory of musical signals. It concludes with some considerations on the inherent duality of time and frequency emerging from Fourier's theorem.

</details>


### [59] [DopplerGLRTNet for Radar Off-Grid Detection](https://arxiv.org/abs/2602.13546)
*Yadang Alexis Rouzoumka,Jean Pinsolle,Eugnie Terreaux,Christle Morisseau,Jean-Philippe Ovarlez,Chengfang Ren*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Off-grid targets whose Doppler (or angle) does not lie on the discrete processing grid can severely degrade classical normalized matched-filter (NMF) detectors: even at high SNR, the detection probability may saturate at operationally relevant low false-alarm rates. A principled remedy is the continuous-parameter GLRT, which maximizes a normalized correlation over the parameter domain; however, dense scanning increases test-time cost and remains sensitive to covariance mismatch through whitening. We propose DopplerGLRTNet, an amortized off-grid GLRT: a lightweight regressor predicts the continuous Doppler within a resolution cell from the whitened observation, and the detector outputs a single GLRT/NMF-like score given by the normalized matched-filter energy at the predicted Doppler. Monte Carlo simulations in Gaussian and compound-Gaussian clutter show that DopplerGLRTNet mitigates off-grid saturation, approaches dense-scan performance at a fraction of its cost, and improves robustness to covariance estimation at the same empirically calibrated Pfa.

</details>


### [60] [Twenty-five years of J-DSP Online Labs for Signal Processing Classes and Workforce Development Programs](https://arxiv.org/abs/2602.13863)
*Andreas Spanias*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents the history of the online simulation program Java-DSP (J-DSP) and the most recent function development and deployment. J-DSP was created to support online laboratories in DSP classes and was first deployed in our ASU DSP class in 2000. The development of the program and its extensions was supported by several NSF grants including CCLI and IUSE. The web-based software was developed by our team in Java and later transitioned to the more secure HTML5 environment. J-DSP supports laboratory exercises on: digital filters and their design, the FFT and its utility in spectral analysis, machine learning for signal classification, and more recently online simulations with the Quantum Fourier Transform. Throughout the J-DSP development and deployment of this tool and its associated laboratory exercises, we documented evaluations. Mobile versions of the program for iOS and Android were also developed. J-DSP is used to this day in several universities, and specific functions of the program have been used in NSF REU, IRES and RET workforce development and high school outreach.

</details>


### [61] [Efficient Off-Grid Near-Field Cascade Channel Estimation for XL-IRS Systems via Tucker Decomposition](https://arxiv.org/abs/2602.13988)
*Wenzhou Cao,Yashuai Cao,Tiejun Lv,Mugen Peng*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate cascaded channel state information is pivotal for extremely large-scale intelligent reflecting surfaces (XL-IRS) in next-generation wireless networks. However, the large XL-IRS aperture induces spherical wavefront propagation due to near-field (NF) effects, complicating cascaded channel estimation. Conventional dictionary-based methods suffer from cumulative quantization errors and high complexity, especially in uniform planar array (UPA) systems. To address these issues, we first propose a tensor modelization method for NF cascaded channels by exploiting the tensor product among the horizontal and vertical response vectors of the UPA-structured base station (BS) and the incident-reflective array response vector of the IRS. This structure leverages spatial characteristics, enabling independent estimation of factor matrices to improve efficiency. Meanwhile, to avoid quantization errors, we propose an off-grid cascaded channel estimation framework based on sparse Tucker decomposition. Specifically, we model the received signal as a Tucker tensor, where the sparse core tensor captures path gain-delay terms and three factor matrices are spanned by BS and NF IRS array responses. We then formulate a sparse core tensor minimization problem with tri-modal log-sum sparsity constraints to tackle the NP-hard challenge. Finally, the method is accelerated via higher-order singular value decomposition preprocessing, combined with majorization-minimization and a tailored tensor over-relaxation fast iterative shrinkage-thresholding technique. We derive the Cramr-Rao lower bound and conduct convergence analysis. Simulations show the proposed scheme achieves a 13.6 dB improvement in normalized mean square error over benchmarks with significantly reduced runtime.

</details>


### [62] [Lightweight Range-Angle Imaging Based Algorithm for Quasi-Static Human Detection on Low-Cost FMCW Radar](https://arxiv.org/abs/2602.14001)
*Huy Trinh,George Shaker*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quasi-static human activities such as lying, standing or sitting produce very low Doppler shifts and highly spread radar signatures, making them difficult to detect with conventional constant-false-alarm rate (CFAR) detectors tuned for point targets. Moreover, privacy concerns and low lighting conditions limit the use of cameras in long-term care (LTC) facilities. This paper proposes a lightweight, non-visual image-based method for robust quasi-static human presence detection using a low-cost 60 GHz FMCW radar. On a dataset covering five semi-static activities, the proposed method improves average detection accuracy from 68.3% for Cell-Averaging CFAR (CA-CFAR) and 78.8% for Order-Statistics CFAR (OS-CFAR) to 93.24% for Subject 1, from 51.3%, 68.3% to 92.3% for Subject 2, and 57.72%, 69.94% to 94.82% for Subject 3, respectively. Finally, we benchmarked all three detectors across all activities on a Raspberry Pi 4B using a shared Range-Angle (RA) preprocessing pipeline. The proposed algorithm obtains an average 8.2 ms per frame, resulting in over 120 frames per second (FPS) and a 74 times speed-up over OS-CFAR. These results demonstrate that simple image-based processing can provide robust and deployable quasi-static human sensing in cluttered indoor environments.

</details>


### [63] [Rethinking RSSI for WiFi Sensing](https://arxiv.org/abs/2602.14004)
*Zhongqin Wang,J. Andrew Zhang,Kai Wu,Y. Jay Guo*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Received Signal Strength Indicator (RSSI) is widely available on commodity WiFi devices but is commonly regarded as too coarse for fine-grained sensing. This paper revisits its sensing potential and presents WiRSSI, a bistatic WiFi sensing framework for passive human tracking using only RSSI measurements. WiRSSI adopts a 1Tx-3Rx configuration and is readily extensible to Multiple-Input Multiple-Output (MIMO) deployments. We first reveal how CSI power implicitly encodes phase-related information and how this relationship carries over to RSSI, showing that RSSI preserves exploitable Doppler, Angle-of-Arrival (AoA), and delay cues associated with human motion. WiRSSI then extracts Doppler-AoA features via a 2D Fast Fourier Transform and infers delay from amplitude-only information in the absence of subcarrier-level phase. The estimated AoA and delay are then mapped to Cartesian coordinates and denoised to recover motion trajectories. Experiments in practical environments show that WiRSSI achieves median XY localization errors of 0.905 m, 0.784 m, and 0.785 m for elliptical, linear, and rectangular trajectories, respectively. In comparison, a representative CSI-based method attains median errors of 0.574 m, 0.599 m, and 0.514 m, corresponding to an average accuracy gap of 0.26 m. These results demonstrate that, despite its lower resolution, RSSI can support practical passive sensing and offers a low-cost alternative to CSI-based WiFi sensing.

</details>


### [64] [Convexity Meets Curvature: Lifted Near-Field Super-Resolution](https://arxiv.org/abs/2602.14063)
*Sajad Daei,Gbor Fodor,Mikael Skoglund*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Extra-large apertures, high carrier frequencies, and integrated sensing and communications (ISAC) are pushing array processing into the Fresnel region, where spherical wavefronts induce a range-dependent phase across the aperture. This curvature breaks the Fourier/Vandermonde structure behind classical subspace methods, and it is especially limiting with hybrid front-ends that provide only a small number of pilot measurements. Consequently, practical systems need continuous angle resolution and joint angle-range inference where many near-field approaches still rely on costly 2D gridding. We show that convexity can meet curvature via a lifted, gridless superresolution framework for near-field measurements. The key is a Bessel-Vandermonde factorization of the Fresnel-phase manifold that exposes a hidden Vandermonde structure in angle while isolating the range dependence into a compact coefficient map. Building on this, we introduce a lifting that maps each range bin and continuous angle to a structured rank-one atom, converting the nonlinear near-field model into a linear inverse problem over a row-sparse matrix. Recovery is posed as atomic-norm minimization and an explicit dual characterization via bounded trigonometric polynomials yields certificate-based localization that super-resolves off-grid angles and identifies active range bins. Simulations with strongly undersampled hybrid observations validate reliable joint angle-range recovery for next-generation wireless and ISAC systems.

</details>


### [65] [Wireless Physical Neural Networks (WPNNs): Opportunities and Challenges](https://arxiv.org/abs/2602.14094)
*Meng Hua,Itsik Bergel,Tolga Girici,Marco Di Renzo,Deniz Gunduz*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Wireless communication systems exhibit structural and functional similarities to neural networks: signals propagate through cascaded elements, interact with the environment, and undergo transformations. Building upon this perspective, we introduce a unified paradigm, termed \textit{wireless physical neural networks (WPNNs)}, in which components of a wireless network, such as transceivers, relays, backscatter, and intelligent surfaces, are interpreted as computational layers within a learning architecture. By treating the wireless propagation environment and network elements as differentiable operators, new opportunities arise for joint communication-computation designs, where system optimization can be achieved through learning-based methods applied directly to the physical network. This approach may operate independently of, or in conjunction with, conventional digital neural layers, enabling hybrid communication learning pipelines. In the article, we outline representative architectures that embody this viewpoint and discuss the algorithmic and training considerations required to leverage the wireless medium as a computational resource. Through numerical examples, we highlight the potential performance gains in processing, adaptability, efficiency, and end-to-end optimization, demonstrating the promise of reconfiguring wireless systems as learning networks in next-generation communication frameworks.

</details>


### [66] [Electromagnetic Bounds on Realizing Targeted MIMO Transfer Functions in Real-World Systems with Wave-Domain Programmability](https://arxiv.org/abs/2602.14152)
*Philipp del Hougne*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A key question for most applications involving reconfigurable linear wave systems is how accurately a desired linear operator can be realized by configuring the system's tunable elements. The relevance of this question spans from hybrid-MIMO analog combiners via computational meta-imagers to programmable wave-domain signal processing. Yet, no electromagnetically consistent bounds have been derived for the fidelity with which a desired operator can be realized in a real-world reconfigurable wave system. Here, we derive such bounds based on an electromagnetically consistent multiport-network model (capturing mutual coupling between tunable elements) and accounting for real-world hardware constraints (lossy, 1-bit-programmable elements). Specifically, we formulate the operator-synthesis task as a quadratically constrained fractional-quadratic problem and compute rigorous fidelity upper bounds based on semidefinite relaxation. We apply our technique to three distinct experimental setups. The first two setups are, respectively, a free-space and a rich-scattering $4\times 4$ MIMO channel at 2.45 GHz parameterized by a reconfigurable intelligent surface (RIS) comprising 100 1-bit-programmable elements. The third setup is a $4\times 4$ MIMO channel at 19 GHz from four feeds of a dynamic metasurface antenna (DMA) to four users. We systematically study how the achievable fidelity scales with the number of tunable elements, and we probe the tightness of our bounds by trying to find optimized configurations approaching the bounds with standard discrete-optimization techniques. We observe a strong influence of the coupling strength between tunable elements on our fidelity bound. For the two RIS-based setups, our bound attests to insufficient wave-domain flexibility for the considered operator synthesis.

</details>


### [67] [Explainable Interictal Epileptiform Discharge Detection Method Based on Scalp EEG and Retrieval-Augmented Generation](https://arxiv.org/abs/2602.14170)
*Yu Zhu,Jiayang Guo,Jun Jiang,Peipei Gu,Xin Shu,Duo Chen*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The detection of interictal epileptiform discharge (IED) is crucial for the diagnosis of epilepsy, but automated methods often lack interpretability. This study proposes IED-RAG, an explainable multimodal framework for joint IED detection and report generation. Our approach employs a dual-encoder to extract electrophysiological and semantic features, aligned via contrastive learning in a shared EEG-text embedding space. During inference, clinically relevant EEG-text pairs are retrieved from a vector database as explicit evidence to condition a large language model (LLM) for the generation of evidence-based reports. Evaluated on a private dataset from Wuhan Children's Hospital and the public TUH EEG Events Corpus (TUEV), the framework achieved balanced accuracies of 89.17\% and 71.38\%, with BLEU scores of 89.61\% and 64.14\%, respectively. The results demonstrate that retrieval of explicit evidence enhances both diagnostic performance and clinical interpretability compared to standard black-box methods.

</details>


### [68] [Localization Exploiting Spatial Variations in the Magnetic Field: Principles and Challenges](https://arxiv.org/abs/2602.14181)
*Isaac Skog,Manon Kok,Christophe Prieur,Gustaf Hendeby*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Signal processing has played, and continues to play, a fundamental role in the evolution of modern localization technologies. Localization using spatial variations in the Earth's magnetic field is no exception. It relies on signal-processing methods for statistical state inference, magnetic-field modeling, and sensor calibration. Contemporary localization techniques based on spatial variations in the magnetic field can provide decimeter-level indoor localization accuracy and outdoor localization accuracy on par with strategic-grade inertial navigation systems. This article provides a broad, high-level overview of current signal-processing principles and open research challenges in localization using spatial variations in the Earth's magnetic field. The aim is to provide the reader with an understanding of the similarities and differences among existing key technologies from a statistical signal-processing perspective. To that end, existing key technologies will be presented within a common parametric signal-model framework compatible with well-established statistical inference methods.

</details>


### [69] [Robust SAC-Enabled UAV-RIS Assisted Secure MISO Systems With Untrusted EH Receivers](https://arxiv.org/abs/2602.14191)
*Hamid Reza Hashempour,Le-Nam Tran,Duy H. N. Nguyen,Hien Quoc Ngo*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates secure downlink transmission in a UAV-assisted reconfigurable intelligent surface (RIS)-enabled multiuser multiple-input single-output network, where legitimate information-harvesting receivers coexist with untrusted energy-harvesting receivers (UEHRs) capable of eavesdropping. A UAV-mounted RIS provides blockage mitigation and passive beamforming, while the base station employs zero-forcing precoding for multiuser interference suppression. Due to limited feedback from UEHRs, their channel state information (CSI) is imperfect, leading to a worst-case secrecy energy efficiency (WCSEE) maximization problem. We jointly optimize the UAV horizontal position, RIS phase shifts, and transmit power allocation under both perfect and imperfect CSI, considering discrete RIS phases, UAV mobility, and energy-harvesting constraints. The resulting problem is highly nonconvex due to coupled channel geometry, robustness requirements, and discrete variables. To address this challenge, we propose a soft actor-critic (SAC)-based deep reinforcement learning framework that learns WCSEE-maximizing policies through interaction with the wireless environment. As a structured benchmark, a successive convex approximation (SCA) approach is developed for the perfect CSI case with continuous RIS phases. Simulation results show that the proposed SAC method achieves up to 28% and 16% secrecy energy efficiency gains over SCA and deep deterministic policy gradient baselines, respectively, while demonstrating superior robustness to CSI uncertainty and stable performance across varying transmit power levels and RIS sizes.

</details>


### [70] [Reconfigurable Intelligent Surfaces-assisted Positioning in Integrated Sensing and Communication Systems](https://arxiv.org/abs/2602.14415)
*Huyen-Trang Ta,Ngoc-Son Duong,Trung-Hieu Nguyen,Van-Linh Nguyen,Thai-Mai Dinh*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates the problem of high-precision target localization in integrated sensing and communication (ISAC) systems, where the target is sensed via both a direct path and a reconfigurable intelligent surface (RIS)-assisted reflection path. We first develop a sequential matched-filter estimator to acquire coarse angular parameters, followed by a range recovery process based on subcarrier phase differences. Subsequently, we formulate the target localization problem as a non-linear least squares optimization, using the coarse estimates to initialize the target's position coordinates. To solve this efficiently, we introduce a fast iterative refinement algorithm tailored for RIS-aided ISAC environments. Recognizing that the signal model involves both linear path gains and non-linear geometric dependencies, we exploit the separable least-squares structure to decouple these parameters. Furthermore, we propose a modified Levenberg algorithm with an approximation strategy, which enables low-cost parameter updates without necessitating repeated evaluations of the full non-linear model. Simulation results show that the proposed refinement method achieves accuracy comparable to conventional approaches, while significantly reducing algorithmic complexity.

</details>


### [71] [Low-Cost Physical-Layer Security Design for IRS-Assisted mMIMO Systems with One-Bit DACs](https://arxiv.org/abs/2602.14292)
*Weijie Xiong,Jian Yang,Jingran Lin,Hongli Liu,Zhiling Xiao,Qiang Li*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Integrating massive multiple-input multiple-output (mMIMO) systems with intelligent reflecting surfaces (IRS) presents a promising paradigm for enhancing physical-layer security (PLS) in wireless communications. However, deploying high-resolution quantizers in large-scale mMIMO arrays, along with numerous IRS elements, leads to substantial hardware complexity. To address these challenges, this paper proposes a cost-effective PLS design for IRS-assisted mMIMO systems by employing one-bit digital-to-analog converters (DACs). The focus is on jointly optimizing one-bit quantized precoding at the transmitter and constant-modulus phase shifts at the IRS to maximize the secrecy rate. This leads to a highly non-convex fractional secrecy rate maximization (SRM) problem. To efficiently solve this problem, two algorithms are proposed: (1) the WMMSE-PDD algorithm, which reformulates the SRM problem into a sequence of non-fractional programs with auxiliary variables using the weighted minimum mean-square error (WMMSE) method and solves them via the penalty dual decomposition (PDD) approach, achieving superior secrecy performance; and (2) the exact penalty product Riemannian gradient descent (EPPRGD) algorithm, which transforms the SRM problem into an unconstrained optimization over a product Riemannian manifold, eliminating auxiliary variables and enabling faster convergence with a slight trade-off in secrecy performance. Both algorithms provide analytical solutions at each iteration and are proven to converge to Karush-Kuhn-Tucker (KKT) points. Simulation results confirm the effectiveness of the proposed methods and highlight their respective advantages.

</details>


### [72] [Online Architecture Search for Compressed Sensing based on Hypergradient Descent](https://arxiv.org/abs/2602.14411)
*Ayano Nakai-Kasai,Yusuke Nakane,Tadashi Wadayama*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: AS-ISTA (Architecture Searched-Iterative Shrinkage Thresholding Algorithm) and AS-FISTA (AS-Fast ISTA) are compressed sensing algorithms introducing structural parameters to ISTA and FISTA to enable architecture search within the iterative process. The structural parameters are determined using deep unfolding, but this approach requires training data and the large overhead of training time. In this paper, we propose HGD-AS-ISTA (Hypergradient Descent-AS-ISTA) and HGD-AS-FISTA that use hypergradient descent, which is an online hyperparameter optimization method, to determine the structural parameters. Experimental results show that the proposed method improves performance of the conventional ISTA/FISTA while avoiding the need for re-training when the environment changes.

</details>


### [73] [Cramer--Rao Bounds for Magneto-Inductive Integrated Sensing and Communications](https://arxiv.org/abs/2602.14453)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Magnetic induction (MI) enables communication in RF-denied environments (underground, underwater, in-body), where the medium conductivity imprints a deterministic signature on the channel. This letter derives a closed-form Cramr--Rao bound (CRB) for the joint estimation of range and medium conductivity from MI pilot observations in an integrated sensing and communication (ISAC) framework. The Fisher information matrix reveals that the joint estimation penalty converges to 3\,dB in the near-field regime, meaning conductivity sensing adds at most a factor-of-two loss in ranging precision. Monte Carlo maximum-likelihood simulations confirm that the CRB is achievable under practical operating conditions.

</details>


### [74] [All-pole centroids in the Wasserstein metric with applications to clustering of spectral densities](https://arxiv.org/abs/2602.14583)
*Rumeshika Pallewela,Filip Elvander*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we propose a method for computing centroids, or barycenters, in the spectral Wasserstein-2 metric for sets of power spectral densities, where the barycenters are restricted to belong to the set of all-pole spectra with a certain model order. This may be interpreted as finding an autoregressive representative for sets of second-order stationary Gaussian processes. While Wasserstein, or optimal transport, barycenters have been successfully used earlier in problems of spectral estimation and clustering, the resulting barycenters are non-parametric and the complexity of representing and storing them depends on, e.g., the choice of discretization grid. In contrast, the herein proposed method yields compact, low-dimensional, and interpretable spectral centroids that can be used in downstream tasks. Computing the all-pole centroids corresponds to solving a non-convex optimization problem in the model parameters, and we present a gradient descent scheme for addressing this. Although convergence to a globally optimal point cannot be guaranteed, the sub-optimality of the obtained centroids can be quantified. The proposed method is illustrated on a problem of phoneme classification.

</details>


### [75] [Learning Dirac Spectral Transforms for Topological Signals](https://arxiv.org/abs/2602.14590)
*Leonardo Di Nino,Tiziana Cattai,Sergio Barbarossa,Ginestra Bianconi,Paolo Di Lorenzo*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Dirac operator provides a unified framework for processing signals defined over different order topological domains, such as node and edge signals. Its eigenmodes define a spectral representation that inherently captures cross-domain interactions, in contrast to conventional Hodge-Laplacian eigenmodes that operate within a single topological dimension. In this paper, we compare the two alternatives in terms of the distortion/sparsity trade-off and we show how an overcomplete basis built concatenating the two dictionaries can provide better performance with respect to each approach. Then, we propose a parameterized nonredundant transform whose eigenmodes incorporate a mode-specific mass parameter that captures the interplay between node and edge modes. Interestingly, we show that learning the mass parameters from data makes the proposed transform able to achieve the best distortion-sparsity tradeoff with respect to both complete and overcomplete bases.

</details>


### [76] [Synthetic Aperture Communication: Principles and Application to Massive IoT Satellite Uplink](https://arxiv.org/abs/2602.14629)
*Lucas Giroto,Marcus Henninger,Silvio Mandelli*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While synthetic aperture radar is widely adopted to provide high-resolution imaging at long distances using small arrays, the concept of coherent synthetic aperture communication (SAC) has not yet been explored. This article introduces the principles of SAC for direct satellite-to-device uplink, showcasing precise direction-of-arrival estimation for user equipment (UE) devices, facilitating spatial signal separation, localization, and easing link budget constraints. Simulations for a low Earth orbit satellite at 600 km orbit and two UE devices performing orthogonal frequency-division multiplexing-based transmission with polar coding at 3.5 GHz demonstrate block error rates below 0.1 with transmission powers as low as -10 dBm, even under strong interference when UE devices are resolved but fall on each other's strongest angular sidelobe. These results validate the ability of the proposed scheme to address mutual interference and stringent power limitations, paving the way for massive Internet of Things connectivity in non-terrestrial networks.

</details>


### [77] [RF-GPT: Teaching AI to See the Wireless World](https://arxiv.org/abs/2602.14833)
*Hang Zou,Yu Tian,Bohao Wang,Lina Bariah,Samson Lasaulce,Chongwen Huang,Mrouane Debbah*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) and multimodal models have become powerful general-purpose reasoning systems. However, radio-frequency (RF) signals, which underpin wireless systems, are still not natively supported by these models. Existing LLM-based approaches for telecom focus mainly on text and structured data, while conventional RF deep-learning models are built separately for specific signal-processing tasks, highlighting a clear gap between RF perception and high-level reasoning. To bridge this gap, we introduce RF-GPT, a radio-frequency language model (RFLM) that utilizes the visual encoders of multimodal LLMs to process and understand RF spectrograms. In this framework, complex in-phase/quadrature (IQ) waveforms are mapped to time-frequency spectrograms and then passed to pretrained visual encoders. The resulting representations are injected as RF tokens into a decoder-only LLM, which generates RF-grounded answers, explanations, and structured outputs. To train RF-GPT, we perform supervised instruction fine-tuning of a pretrained multimodal LLM using a fully synthetic RF corpus. Standards-compliant waveform generators produce wideband scenes for six wireless technologies, from which we derive time-frequency spectrograms, exact configuration metadata, and dense captions. A text-only LLM then converts these captions into RF-grounded instruction-answer pairs, yielding roughly 12,000 RF scenes and 0.625 million instruction examples without any manual labeling. Across benchmarks for wideband modulation classification, overlap analysis, wireless-technology recognition, WLAN user counting, and 5G NR information extraction, RF-GPT achieves strong multi-task performance, whereas general-purpose VLMs with no RF grounding largely fail.

</details>


### [78] [Lattice XBAR Filters in Thin-Film Lithium Niobate](https://arxiv.org/abs/2602.14937)
*Taran Anusorn,Byeongjin Kim,Ian Anderson,Ziqian Yao,Ruochen Lu*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work presents the demonstration of lattice filters based on laterally excited bulk acoustic resonators (XBARs). Two filter implementations, namely direct lattice and layout-balanced lattice topologies, are designed and fabricated in periodically poled piezoelectric film (P3F) thin-film lithium niobate (TFLN). By leveraging the strong electromechanical coupling of XBARs in P3F TFLN together with the inherently wideband nature of the lattice topology, 3-dB fractional bandwidths (FBWs) of 27.42\% and 39.11\% and low insertion losses (ILs) of 0.88 dB and 0.96 dB are achieved at approximately 20 GHz for the direct and layout-balanced lattice filters, respectively, under conjugate matching. Notably, all prototypes feature compact footprints smaller than 1.3 mm\textsuperscript{2}. These results highlight the potential of XBAR-based lattice architectures to enable low-loss, wideband acoustic filters for compact, high-performance RF front ends in next-generation wireless communication and sensing systems, while also identifying key challenges and directions for further optimization.

</details>


### [79] [Real-time Range-Angle Estimation and Tag Localization for Multi-static Backscatter Systems](https://arxiv.org/abs/2602.14985)
*Tara Esmaeilbeig,Kartik Patel,Traian E. Abrudan,John Kimionis,Eleftherios Kampianakis,Michael S. Eggleston*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multi-static backscatter networks (BNs) are strong candidates for joint communication and localization in the ambient IoT paradigm for 6G. Enabling real-time localization in large-scale multi-static deployments with thousands of devices require highly efficient algorithms for estimating key parameters such as range and angle of arrival (AoA), and for fusing these parameters into location estimates. We propose two low-complexity algorithms, Joint Range-Angle Clustering (JRAC) and Stage-wise Range-Angle Estimation (SRAE). Both deliver range and angle estimation accuracy comparable to FFT- and subspace-based baselines while significantly reducing the computation. We then introduce two real-time localization algorithms that fuse the estimated ranges and AoAs: a maximum-likelihood (ML) method solved via gradient search and an iterative re-weighted least squares (IRLS) method. Both achieve localization accuracy comparable to ML-based brute force search albeit with far lower complexity. Experiments on a real-world large-scale multi-static testbed with 4 illuminators, 1 multi-antenna receiver, and 100 tags show that JRAC and SRAE reduce runtime by up to 40X and IRLS achieves up to 500X reduction over ML-based brute force search without degrading localization accuracy. The proposed methods achieve 3 m median localization error across all 100 tags in a sub-6GHz band with 40 MHz bandwidth. These results demonstrate that multi-static range-angle estimation and localization algorithms can make real-time, scalable backscatter localization practical for next-generation ambient IoT networks.

</details>
