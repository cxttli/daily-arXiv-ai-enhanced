<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 21]
- [cs.IT](#cs.IT) [Total: 13]
- [cs.NI](#cs.NI) [Total: 3]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Data-Driven Deep MIMO Detection:Network Architectures and Generalization Analysis](https://arxiv.org/abs/2602.20178)
*Yongwei Yi,Xinping Yi,Wenjin Wang,Xiao Li,Shi Jin*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In practical Multiuser Multiple-Input Multiple-Output (MU-MIMO) systems, symbol detection remains challenging due to severe inter-user interference and sensitivity to Channel State Information (CSI) uncertainty. In contrast to the mostly studied belief propagation-type model-driven methods, which incur high computational complexity, Soft Interference Cancellation (SIC) strikes a good balance between performance and complexity. To further address CSI mismatch and nonlinear effects, the recently proposed data-driven deep neural receivers, such as DeepSIC, leverage the advantages of deep neural networks for interference cancellation and symbol detection, demonstrating strong empirical performance. However, there is still a lack of theoretical underpinning for why and to what extent DeepSIC could generalize with the number of training samples. This paper proposes inspecting the fully data-driven DeepSIC detection within a Network-of-MLPs architecture, which is composed of multiple interconnected MLPs via outer and inner Directed Acyclic Graphs (DAGs). Within such an architecture, DeepSIC can be upgraded as a graph-based message-passing process using Graph Neural Networks (GNNs), termed GNNSIC, with shared model parameters across users and iterations. Notably, GNNSIC achieves excellent expressivity comparable to DeepSIC with substantially fewer trainable parameters, resulting in improved sample efficiency and enhanced user generalization. By conducting a norm-based generalization analysis using Rademacher complexity, we reveal that an exponential dependence on the number of iterations for DeepSIC can be eliminated in GNNSIC due to parameter sharing. Simulation results demonstrate that GNNSIC attains comparable or improved Symbol Error Rate (SER) performance to DeepSIC with significantly fewer parameters and training samples.

</details>


### [2] [The Sim-to-Real Gap in MRS Quantification: A Systematic Deep Learning Validation for GABA](https://arxiv.org/abs/2602.20289)
*Zien Ma,S. M. Shermer,Oktay Karakuş,Frank C. Langbein*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Magnetic resonance spectroscopy (MRS) is used to quantify metabolites in vivo and estimate biomarkers for conditions ranging from neurological disorders to cancers. Quantifying low-concentration metabolites such as GABA ($γ$-aminobutyric acid) is challenging due to low signal-to-noise ratio (SNR) and spectral overlap. We investigate and validate deep learning for quantifying complex, low-SNR, overlapping signals from MEGA-PRESS spectra, devise a convolutional neural network (CNN) and a Y-shaped autoencoder (YAE), and select the best models via Bayesian optimisation on 10,000 simulated spectra from slice-profile-aware MEGA-PRESS simulations. The selected models are trained on 100,000 simulated spectra. We validate their performance on 144 spectra from 112 experimental phantoms containing five metabolites of interest (GABA, Glu, Gln, NAA, Cr) with known ground truth concentrations across solution and gel series acquired at 3 T under varied bandwidths and implementations. These models are further assessed against the widely used LCModel quantification tool. On simulations, both models achieve near-perfect agreement (small MAEs; regression slopes $\approx 1.00$, $R^2 \approx 1.00$). On experimental phantom data, errors initially increased substantially. However, modelling variable linewidths in the training data significantly reduced this gap. The best augmented deep learning models achieved a mean MAE for GABA over all phantom spectra of 0.151 (YAE) and 0.160 (FCNN) in max-normalised relative concentrations, outperforming the conventional baseline LCModel (0.220). A sim-to-real gap remains, but physics-informed data augmentation substantially reduced it. Phantom ground truth is needed to judge whether a method will perform reliably on real data.

</details>


### [3] [Fast Spectrogram Event Extraction via Offline Self-Supervised Learning: From Fusion Diagnostics to Bioacoustics](https://arxiv.org/abs/2602.20317)
*Nathaniel Chen,Kouroche Bouchiat,Peter Steiner,Andrew Rothstein,David Smith,Max Austin,Mike van Zeeland,Azarakhsh Jalalvand,Egemen Kolemen*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Next-generation fusion facilities like ITER face a "data deluge," generating petabytes of multi-diagnostic signals daily that challenge manual analysis. We present a "signals-first" self-supervised framework for the automated extraction of coherent and transient modes from high-noise time-frequency data. We also develop a general-purpose method and tool for extracting coherent, quasi-coherent, and transient modes for fluctuation measurements in tokamaks by employing non-linear optimal techniques in multichannel signal processing with a fast neural network surrogate on fast magnetics, electron cyclotron emission, CO2 interferometers, and beam emission spectroscopy measurements from DIII-D. Results are tested on data from DIII-D, TJ-II, and non-fusion spectrograms. With an inference latency of 0.5 seconds, this framework enables real-time mode identification and large-scale automated database generation for advanced plasma control. Repository is in https://github.com/PlasmaControl/TokEye.

</details>


### [4] [Cooperative ISAC for Joint Localization and Velocity Estimation in Cell-Free MIMO Systems](https://arxiv.org/abs/2602.20319)
*Zihuan Wang,Vincent W. S. Wong,Robert Schober*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we explore a cooperative integrated sensing and communication (ISAC) framework that utilizes orthogonal frequency division multiplexing (OFDM) waveforms. Under the control of a central processing unit (CPU), multiple access points (APs) collaboratively perform multistatic sensing while providing communication service in a cell-free multiple-input multiple-output (MIMO) system. Achieving high sensing accuracy requires the collection of global sensing information at the CPU, which can lead to significant fronthaul signaling overhead due to the feedback of the sensing signals from each AP. To tackle this issue, we propose a collaborative processing scheme in which the APs locally compress and quantize the received sensing signals before forwarding them to the CPU. The CPU then aggregates the information from all APs to estimate the location and velocity of the targets. We develop a distributed vector-quantized variational autoencoder (D-VQVAE) to enable an end-to-end implementation of this scheme. D-VQVAE consists of distributed encoders at the APs to locally encode the received sensing signals, codebooks for quantizing the encoded results, and a decoder at the CPU for location and velocity estimation. It effectively reduces the amount of data transmitted from each AP to the CPU while maintaining a high sensing accuracy. We employ a collaborative learning-assisted scheme to train D-VQVAE in an end-to-end manner. Simulation results show that the proposed D-VQVAE network outperforms the baseline schemes in sensing accuracy and reduces fronthaul signaling overhead by 99% when compared with the centralized sensing approach.

</details>


### [5] [Waveform Design for Partial-Time Superimposed ISAC Systems](https://arxiv.org/abs/2602.20353)
*Xi Nan,Rugui Yao,Ye Fan,Ruikang Zhong,Xiaoya Zuo,Theodoros A. Tsiftsis,Alexandros-Apostolos A. Boulogeorgos*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Nowadays, waveforms of integrated sensing and communication (ISAC) are almost based on conventional communication and sensing signal, which bounds both the communication and sensing performance. To deal with this issue, in this paper, a novel waveform design is presented for the partial-time superimposed (PTS) ISAC system. At the base station (BS), a parameter-adjustable linear frequency modulation (LFM) pulse signal and a continuous communication orthogonal frequency division multiplexing (OFDM) signal are employed to broadcast public information and perform sensing tasks, respectively, using a PTS scheme. Pulse compression gain enhances the system's long-range sensing capability, while OFDM ensures the system's high-speed data transmission capability. Meanwhile, the LFM signal is utilized as superimposed pilot for channel estimation, which has higher time-frequency resource utilization and stronger real-time performance compared to orthogonal pilots. We present an accurate parameter estimation method of multi-path sensing signal for reconstructing and interference cancellation in communication users. Additionally, a cyclic maximum likelihood method is introduced for channel estimation and the Cramer-Rao lower bound (CRLB) of channel estimation is derived. Simulations demonstrate the accuracy and robustness of the proposed parameter estimation algorithm as well as the improved channel estimation performance over traditional methods. The proposed waveform design method can achieve reliable data transmission and accurate target sensing.

</details>


### [6] [Height-Dependent Spectrum Activity Measurements and Modeling: A Case Study with FM Radio Bands](https://arxiv.org/abs/2602.20487)
*Sung Joon Maeng,Amir Hossein Fahim Raouf,Ozgur Ozdemir,İsmail Güvenç,Mihail L. Sichitiu*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The increasing demand for wireless connectivity necessitates advanced spectrum modeling to enable efficient spectrum sharing for next-generation aerial communications. While traditional models often overlook vertical variations in signal behavior, this paper proposes a height-dependent propagation model using a helikite-mounted software-defined radio (SDR). We collected extensive measurement data across the 88 MHz to 6 GHz range in both urban and rural environments. As a case study to validate our methodology, we focus on the FM radio band, which allows us to use publicly available transmitter locations and transmit power levels to facilitate comparisons between analytical with measurement results. We identify a clear transition from non-line-of-sight (NLoS) to line-of-sight (LoS) regimes at a specific altitude threshold and propose an altitude-dependent path loss model that incorporates this transition. Our results demonstrate that the proposed model significantly outperforms the standard free space path loss (FSPL) model in complex urban topologies, providing a more accurate framework for altitude-aware spectrum prediction and management across emerging aerial wireless technologies and bands.

</details>


### [7] [Comparing Implicit Neural Representations and B-Splines for Continuous Function Fitting from Sparse Samples](https://arxiv.org/abs/2602.20535)
*Hongze Yu,Yun Jiang,Jeffrey A. Fessler*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Continuous signal representations are naturally suited for inverse problems, such as magnetic resonance imaging (MRI) and computed tomography, because the measurements depend on an underlying physically continuous signal. While classical methods rely on predefined analytical bases like B-splines, implicit neural representations (INRs) have emerged as a powerful alternative that use coordinate-based networks to parameterize continuous functions with implicitly defined bases. Despite their empirical success, direct comparisons of their intrinsic representation capabilities with conventional models remain limited. This preliminary empirical study compares a positional-encoded INR with a cubic B-spline model for continuous function fitting from sparse random samples, isolating the representation capacity difference by only using coefficient-domain Tikhonov regularization. Results demonstrate that, under oracle hyperparameter selection, the INR achieves a lower normalized root-mean-squared error, yielding sharper edge transitions and fewer oscillatory artifacts than the oracle-tuned B-spline model. Additionally, we show that a practical bilevel optimization framework for INR hyperparameter selection based on measurement data split effectively approximates oracle performance. These findings empirically support the superior representation capacity of INRs for sparse data fitting.

</details>


### [8] [On Channel Estimation for Group-Connected Beyond Diagonal RIS Assisted Multi-User MIMO Communication](https://arxiv.org/abs/2602.20559)
*Rui Wang,Junyuan Gao,Shuowen Zhang,Bruno Clerckx,Liang Liu*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS) architectures offer superior beamforming gain over conventional diagonal RISs. However, the channel estimation overhead is the main hurdle for reaping the above gain in practice. This letter addresses this issue for group-connected BDRIS aided uplink communication from multiple multi-antenna users to one multi-antenna base station (BS). We first reveal that within each BD-RIS group, the cascaded channel associated with one user antenna and one BD-RIS element is a scaled version of that associated with any other user antenna and BD-RIS element due to the common RIS-BS channel. This insight drastically reduces the dimensionality of the channel estimation problem. Building on this property, we propose an efficient two-phase channel estimation protocol. In the first phase, the reference cascaded channels for all groups are estimated in parallel based on common received signals while determining the scaling coefficients for a single reference antenna. In the second phase, the scaling coefficients for all remaining user antennas are estimated. Numerical results demonstrate that our proposed framework achieves substantially lower estimation error with fewer pilot signals compared to state-of-the-art benchmark schemes.

</details>


### [9] [Provable orbit recovery over SO(3) from the non-uniform second moment](https://arxiv.org/abs/2602.20590)
*Tamir Bendory,Dan Edidin,Josh Katz,Shay Kreymer,Nir Sharon*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the recovery of an unknown three-dimensional band-limited signal from multiple noisy observations that are randomly rotated by latent elements of SO(3), where the rotations are drawn from an unknown, non-uniform distribution. Because the rotations are unobserved, only the signal orbit under the rotation group can be recovered. We show that the signal orbit and the rotation distribution are jointly identifiable from the first and second moments. This yields an improved high-noise sample complexity that scales quadratically with the noise variance, rather than cubically as in the uniform-rotation case. We further develop a provable, computationally efficient reconstruction algorithm that recovers the 3-D signal by successively solving a sequence of well-conditioned linear systems. The algorithm is validated through extensive numerical experiments. Our results provide a principled and tractable framework for high-noise 3-D orbit recovery, with potential relevance to cryo-electron microscopy and cryo-electron tomography modeling, where molecules are observed in unknown orientations.

</details>


### [10] [Functional Continuous Decomposition](https://arxiv.org/abs/2602.20857)
*Teymur Aghayev*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The analysis of non-stationary time-series data requires insight into its local and global patterns with physical interpretability. However, traditional smoothing algorithms, such as B-splines, Savitzky-Golay filtering, and Empirical Mode Decomposition (EMD), lack the ability to perform parametric optimization with guaranteed continuity. In this paper, we propose Functional Continuous Decomposition (FCD), a JAX-accelerated framework that performs parametric, continuous optimization on a wide range of mathematical functions. By using Levenberg-Marquardt optimization to achieve up to $C^1$ continuous fitting, FCD transforms raw time-series data into $M$ modes that capture different temporal patterns from short-term to long-term trends. Applications of FCD include physics, medicine, financial analysis, and machine learning, where it is commonly used for the analysis of signal temporal patterns, optimized parameters, derivatives, and integrals of decomposition. Furthermore, FCD can be applied for physical analysis and feature extraction with an average SRMSE of 0.735 per segment and a speed of 0.47s on full decomposition of 1,000 points. Finally, we demonstrate that a Convolutional Neural Network (CNN) enhanced with FCD features, such as optimized function values, parameters, and derivatives, achieved 16.8% faster convergence and 2.5% higher accuracy over a standard CNN.

</details>


### [11] [FGFRFT: Fast Graph Fractional FourierTransform via Fourier Series Approximation](https://arxiv.org/abs/2602.20870)
*Ziqi Yan,Sen Shi,Feiyue Zhao,Manjun Cui,Yangfan He,Zhichao Zhang*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The graph fractional Fourier transform (GFRFT) generalizes the graph Fourier transform (GFT) but suffers from a significant computational bottleneck: determining the optimal transform order requires expensive eigendecomposition and matrix multiplication, leading to $O(N^3)$ complexity. To address this issue, we propose a fast GFRFT (FGFRFT) algorithm for unitary GFT matrices based on Fourier series approximation and an efficient caching strategy. FGFRFT reduces the complexity of generating transform matrices to $O(2LN^2)$ while preserving differentiability, thereby enabling adaptive order learning. We validate the algorithm through theoretical analysis, approximation accuracy tests, and order learning experiments. Furthermore, we demonstrate its practical efficacy for image and point cloud denoising and present the fractional specformer, which integrates the FGFRFT into the specformer architecture. This integration enables the model to overcome the limitations of a fixed GFT basis and learn optimal fractional orders for complex data. Experimental results confirm that the proposed algorithm significantly accelerates computation and achieves superior performance compared with the GFRFT.

</details>


### [12] [Symbol-Aware Precoder Design for Physical-Layer Anonymous Communications](https://arxiv.org/abs/2602.20874)
*Yu Li,Milad Tatar Mamaghani,Xiangyun Zhou,Nan Yang*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Physical-layer characteristics, such as channel state information (CSI) and transmitter noise induced by hardware impairments, are often uniquely associated with a transmitter. This paper investigates transmitter anonymity at the physical layer from a signal design perspective. We consider an anonymous communication problem where the receiver should reliably decode the signal from the transmitter but should not make use of the signal to infer the transmitter's identity.Transmitter anonymity is quantified using a Kullback-Leibler divergence (KLD)-based metric, which enables the formulation of explicit anonymity constraints in the precoder design.We then propose an anonymous symbol-level precoding strategy that preserves reliable communication under spatial multiplexing while preventing transmitter identification. The proposed framework employs a partitioned equal-gain combining (P-EGC) scheme that leverages receiver diversity without requiring transmitter-specific CSI. Simulation results demonstrate anonymity-reliability tradeoffs across different signal-to-noise ratios (SNRs) and numbers of data streams. Moreover, the results reveal opposite trends of anonymity with respect to transmitter-dependent noise variations in the low-SNR and high-SNR regimes.

</details>


### [13] [Continuous-Time Analysis of AFDM: Fundamental Bounds, and Effects of Pulse-Shaping and Hardware Impairments](https://arxiv.org/abs/2602.20909)
*Michele Mirabella,Hyeon Seok Rou,Pasquale Di Viesti,Giuseppe Thadeu Freitas de Abreu,Giorgio Matteo Vitetta*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Affine frequency division multiplexing (AFDM) has recently emerged as a resilient waveform candidate for high-mobility next-generation wireless systems. However, current literature mostly focuses on discrete time (DT) models, often overlooking effects and hardware non-idealities of actual continuous time (CT) signal generation. In this paper, we bridge this gap by developing a CT-analytical framework based on the affine Fourier series (AFS) representation, which allows us to demonstrate that strictly bandlimited pulses and subcarrier suppression strategies are essential to maintain the multicarrier structure of the signal. In addition, we derive the analytical power spectral density of AFDM and evaluate its spectral characteristics in comparison with other multicarrier schemes, considering the impact of realistic truncated pulse-shaping. Furthermore, we analyze the sensitivity of the CT model to phase noise, carrier frequency offset, and sampling jitter, providing a theoretical analysis of communication performance. Finally, we derive closed-form Cramér-Rao bounds for channel parameter estimation, showing that the chirped modulation peculiar of AFDM increases the estimation variance but enables the resolution of Doppler ambiguities. Our findings provide the necessary theoretical and practical foundations for the implementation of AFDM in realistic wireless transceivers.

</details>


### [14] [Synapse-Inspired Energy Networks: A Neuromorphic Approach to Microgrid Protection without Communication Links](https://arxiv.org/abs/2602.20944)
*Saurabh Prabhakar,Bijaya Ketan Panigrahi,Frede Blaabjerg,Subham Sahoo*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Traditional protection systems for microgrids, which rely on high fault currents and continuous communication, struggle to keep up with the changing dynamics and cybersecurity concerns of decentralized networks. In this study, we introduce a novel biologically inspired protection system based on neuromorphic principles, where each distributed energy resource (DER) functions as a simple neuron. These neurons process local changes in voltage, current signals, and converting them into spike patterns that represent the severity of disturbances. Just as neurons communicate via synapses in biological systems, we exploit transmission cables to coordinate between DERs, enabling them to share information and respond to faults collectively. Fault detection and circuit breaker activation are driven by a First-To-Spike (FTTS) mechanism, similar to the concept of traveling wave protection, but without needing GPS synchronization or communication links. A key innovation is the ability to use the timing of spikes to locally determine the nature of a fault, offering an intelligent, adaptive response to disturbances. Performance shows tripping latency of 10-58 ms, surpassing conventional relays and even traveling-wave methods (60 ms), while maintaining detection accuracy above 98% and spatial selectivity over 97%, enabling real-time, communication-free, scalable protection for plug-and-play microgrids.

</details>


### [15] [Cell-Free Massive MIMO-Assisted SWIPT Using Stacked Intelligent Metasurfaces](https://arxiv.org/abs/2602.20983)
*Thien Duc Hua,Mohammadali Mohammadi,Hien Quoc Ngo,Michail Matthaiou*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This study explores a next-generation multiple access (NGMA) framework for cell-free massive MIMO (CF-mMIMO) systems enhanced by stacked intelligent metasurfaces (SIMs), aiming to improve simultaneous wireless information and power transfer (SWIPT) performance. A fundamental challenge lies in optimally selecting the operating modes of access points (APs) to jointly maximize the received energy and satisfy spectral efficiency (SE) quality-of-service constraints. Practical system impairments, including a non-linear harvested energy model, pilot contamination (PC), channel estimation errors, and reliance on long-term statistical channel state information (CSI), are considered. We derive closed-form expressions for both the achievable SE and the average sum harvested energy (sum-HE). A mixed-integer non-convex optimization problem is formulated to jointly optimize the SIM phase shifts, APs mode selection, and power allocation to maximize average sum-HE under SE and average harvested energy constraints. To solve this problem, we propose a centralized training, decentralized execution (CTDE) framework based on deep reinforcement learning (DRL), which efficiently handles high-dimensional decision spaces. A Markovian environment and a normalized joint reward function are introduced to enhance the training stability across on-policy and off-policy DRL algorithms. Additionally, we provide a two-phase convex-based solution as a theoretical robust performance. Numerical results demonstrate that the proposed DRL-based CTDE framework achieves SWIPT performance comparable to convexification-based solution, while significantly outperforming baselines.

</details>


### [16] [Timing Recovery and Sequence Detection for Integrate-and-Fire Time Encoding Receivers](https://arxiv.org/abs/2602.20953)
*Neil Irwin Bernardo*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent advances in neuromorphic signal processing have introduced time encoding machines as a promising alternative to conventional uniform sampling for low-power communication receivers. In this paradigm, analog signals are converted into event timings by an integrate-and-fire circuit, allowing information to be represented through spike times rather than amplitude samples. While event-driven sampling eliminates the need for a fixed-rate clock, receivers equipped with integrate-and-fire time encoding machines, called time encoding receivers, often assume perfect symbol synchronization, leaving the problem of symbol timing recovery unresolved. This paper presents a joint timing recovery and data detection framework for integrate-and-fire time encoding receivers. The log-likelihood function is derived to capture the dependence between firing times, symbol timing offset, and transmitted sequence, leading to a maximum likelihood formulation for joint timing estimation and sequence detection. A practical two-stage receiver is developed, consisting of a timing recovery algorithm followed by a zero-forcing detector. Simulation results demonstrate accurate symbol timing offset estimation and improved symbol error rate performance compared to existing time encoding receivers.

</details>


### [17] [Optimal QAM Constellation for Over-the-Air Computation in the Presence of Heavy-Tailed Channel Noise](https://arxiv.org/abs/2602.21027)
*Saeed Razavikia,Deniz Gündüz,Carlo Fischione*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Over-the-air computation (OAC) enables low-latency aggregation over multiple-access channels (MACs) by exploiting the superposition property of the wireless medium to compute functions efficiently in distributed networks. A critical but often overlooked challenge is that electromagnetic interference in practical radio channels frequently exhibits heavy-tailed behavior, causing strong impulsive noise that severely degrades computation performance. This work studies digital OAC with QAM-based signaling under heavy-tailed interference modeled by a Cauchy distribution (lacking a finite second moment). We seek QAM-like constellations that minimize the mean-squared error (MSE) of sum aggregation subject to an average-power constraint. The problem is formulated as a constrained optimization, whose solution yields unique optimality conditions. Numerical results confirm the effectiveness of the proposed design. Notably, the framework extends naturally to nomographic functions, broader constellation families, and alternative noise models.

</details>


### [18] [Distributed Continuous Aperture Arrays for Multiuser SWIPT](https://arxiv.org/abs/2602.21096)
*Muhammad Zeeshan Mumtaz,Mohammadali Mohammadi,Hien Quoc Ngo,Michail Matthaiou*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a distributed continuous aperture array (D CAPA) to support simultaneous wireless information and power transfer (SWIPT) to multiple information users (IUs) and energy users (EUs). Each metasurface supports continuous surface currents that radiate electromagnetic (EM) waves for information and energy transmission to the users. These waves propagate through continuous EM channels characterized by the dyadic Green function. We formulate a system power consumption (PC) minimization problem subject to spectral efficiency and energy harvesting quality of service (QoS) requirements, where the QoS requirements are derived under the equal power allocation (EPA) scheme. An efficient two layer optimization algorithm is developed to solve this problem by optimizing the power allocation subject to the QoS violation penalties using augmented Lagrangian transformation. Our numerical results show that well optimized current distributions over each metasurface in the proposed D CAPA achieve up to 65% and 61% reductions in overall system PC compared to the EPA and colocated CAPA (C CAPA) cases, while maintaining the same total aperture size and transmission power.

</details>


### [19] [BRISC: A Dataset of Channel Measurements at 5 GHz With a Reflective Intelligent Surface](https://arxiv.org/abs/2602.21102)
*Mattia Piana,Giovanni Angelo Alghisi,Anna Valeria Guglielmi,Giovanni Perin,Francesco Gringoli,Stefano Tomasin*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce the broadband reconfigurable intelligent surface (RIS) channel (BRISC) dataset. The dataset comprises measurements of channel state information (CSI) collected at 5.53 GHz using a 256-element RIS with binary states. In the measurement campaign, the transmitter and receiver are two software defined radios (SDRs), phase-synchronized via an OctoClock, where the transmitter (receiver) is equipped with one (two) antenna(s). To manage complexity, the RIS elements are grouped into blocks of different sizes, where all elements within a block share the same state. CSIs have been captured for multiple a) transmitter positions (and fixed receiver location), b) pilot block sizes, and c) state configurations. Furthermore, we calibrated the parameters of state-of-the-art RIS channel models to fit the measured CSI. With approximately 10000 configurations explored per transmitting position, BRISC serves as a robust benchmark in communication applications. We also show here an example of its use for physical-layer authentication.

</details>


### [20] [Resilient Cell-Free Massive MIMO Networks](https://arxiv.org/abs/2602.21107)
*Junbin Yu,Tianyu Lu,Mohammadali Mohammadi,Michail Matthaiou*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a novel optimization framework for enhancing the security resilience of cell-free massive multiple-input multiple-output (CF-mMIMO) networks with multi-antenna access points (APs) and protective partial zero-forcing (PPZF) under active eavesdropping. Based on the main principles of absorption, adaptation, and recovery, we formulate a security-aware resilience metric to quantify the system performance during and after a security outage. A multi-user service priority-aware power allocation problem is formulated to minimize the mean squared error (MSE) between real-time and desired security efficiency, thereby enabling a trade-off between the target user's secrecy performance and multi-user quality of service (QoS). To solve this non-convex problem, a security-aware iterative algorithm based on the successive convex approximation (SCA) is employed. The proposed algorithm determines the optimal power allocation strategy by balancing solution quality against recovery time. At each iteration, it evaluates the overall resilience score and selects the strategy that achieves the highest value. Simulation results confirm that the proposed framework significantly improves the resilience of CF-mMIMO networks, allowing flexible adaptation between rapid recovery and high-quality recovery, depending on system requirements.

</details>


### [21] [Attention-Based SINR Estimation in User-Centric Non-Terrestrial Networks](https://arxiv.org/abs/2602.21116)
*Bruno De Filippo,Alessandro Guidotti,Alessandro Vanelli-Coralli*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The signal-to-interference-plus-noise ratio (SINR) is central to performance optimization in user-centric beamforming for satellite-based non-terrestrial networks (NTNs). Its assessment either requires the transmission of dedicated pilots or relies on computing the beamforming matrix through minimum mean squared error (MMSE)-based formulations beforehand, a process that introduces significant computational overhead. In this paper, we propose a low-complexity SINR estimation framework that leverages multi-head self-attention (MHSA) to extract inter-user interference features directly from either channel state information or user location reports. The proposed dual MHSA (DMHSA) models evaluate the SINR of a scheduled user group without requiring explicit MMSE calculations. The architecture achieves a computational complexity reduction by a factor of three in the CSI-based setting and by two orders of magnitude in the location-based configuration, the latter benefiting from the lower dimensionality of user reports. We show that both DMHSA models maintain high estimation accuracy, with the root mean squared error typically below 1 dB with priority-queuing-based scheduled users. These results enable the integration of DMHSA-based estimators into scheduling procedures, allowing the evaluation of multiple candidate user groups and the selection of those offering the highest average SINR and capacity.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [22] [Exponential Lower Bounds for 2-query Relaxed Locally Decodable Codes](https://arxiv.org/abs/2602.20278)
*Alexander R. Block,Jeremiah Blocki,Kuan Cheng,Elena Grigorescu,Xin Li,Yu Zheng,Minshen Zhu*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Locally Decodable Codes (LDCs) are error-correcting codes $C\colonΣ^n\rightarrow Σ^m,$ encoding \emph{messages} in $Σ^n$ to \emph{codewords} in $Σ^m$, with super-fast decoding algorithms. They are important mathematical objects in many areas of theoretical computer science, yet the best constructions so far have codeword length $m$ that is super-polynomial in $n$, for codes with constant query complexity and constant alphabet size.
  In a very surprising result, Ben-Sasson, Goldreich, Harsha, Sudan, and Vadhan (SICOMP 2006) show how to construct a relaxed version of LDCs (RLDCs) with constant query complexity and almost linear codeword length over the binary alphabet, and used them to obtain significantly-improved constructions of Probabilistically Checkable Proofs.
  In this work, we study RLDCs in the standard Hamming-error setting. We prove an exponential lower bound on the length of Hamming RLDCs making $2$ queries (even adaptively) over the binary alphabet. This answers a question explicitly raised by Gur and Lachish (SICOMP 2021) and is the first exponential lower bound for RLDCs. Combined with the results of Ben-Sasson et al., our result exhibits a ``phase-transition''-type behavior on the codeword length for some constant-query complexity. We achieve these lower bounds via a transformation of RLDCs to standard Hamming LDCs, using a careful analysis of restrictions of message bits that fix codeword bits.

</details>


### [23] [Learning During Detection: Continual Learning for Neural OFDM Receivers via DMRS](https://arxiv.org/abs/2602.20361)
*Mohanad Obeed,Ming Jian*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Deep neural networks (DNNs) have been increasingly explored for receiver design because they can handle complex environments without relying on explicit channel models. Nevertheless, because communication channels change rapidly, their distributions can shift over time, often making periodic retraining necessary. This paper proposes a zero-overhead online and continual learning framework for orthogonal frequency-division multiplexing (OFDM) neural receivers that directly detect the soft bits of received signals. Unlike conventional fine-tuning methods that rely on dedicated training intervals or full resource grids, our approach leverages existing demodulation reference signals (DMRS) to simultaneously enable signal demodulation and model adaptation. We introduce three pilot designs: fully randomized, hybrid, and additional pilots that flexibly support joint demodulation and learning. To accommodate these pilot designs, we develop two receiver architectures: (i) a parallel design that separates inference and fine-tuning for uninterrupted operation, and (ii) a forward-pass reusing design that reduces computational complexity. Simulation results show that the proposed method effectively tracks both slow and fast channel distribution variations without additional overhead, service interruption, or catastrophic performance degradation under distribution shift.

</details>


### [24] [On the Height Profile of Analog Error-Correcting Codes](https://arxiv.org/abs/2602.20366)
*Ron M. Roth,Ziyuan Zhu,Changcheng Yuan,Paul H. Siegel,Anxiao Jiang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In recent work, it has been shown that maintaining reliability in analog vector--matrix multipliers can be modeled as the following coding problem. Vectors in $\mathbb{R}^k$ are encoded into codewords of a linear $[n,k,d]$ code $C$ over $\mathbb{R}$. For prescribed positive reals $δ< Δ$, additive errors of magnitude at most $δ$ are tolerable and need no handling, yet outlying errors of magnitude greater than $Δ$ are to be located or detected. The trade-off between the ratio $Δ/δ$ and the number of outlying errors that can be handled is determined by the height profile of $C$; as such, the height profile provides a finer description of the error handling capability of $C$, compared to the minimum distance $d$, which only determines the number of correctable errors. This work contains a further study of the notion of the height profile. Several characterizations of the height profile are presented, thereby yielding methods for computing it. The starting point is formulating this computation as an optimization problem that is solved by a set of linear programs. This, in turn, leads to a combinatorial characterization of the height profile as a maximum (or max--min) over a certain finite set of codewords of $C$. Moreover, this characterization is shown to have a simple geometric interpretation when the columns of the generator matrix of $C$ all have the same $L_2$ norm. Through examples of several code families, it is demonstrated how the results herein can be used to compute the height profile explicitly.

</details>


### [25] [Permutation decoding of algebraic geometry codes from Hermitian and norm-trace curves](https://arxiv.org/abs/2602.20455)
*Monica Lichtenwalner,Hiram H. López,Gretchen L. Matthews,Padmapani Seneviratne*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Permutation decoding is a process that utilizes the permutation automorphism group of a linear code to correct errors in received words. Given a received word, a set of automorphisms, called a PD set, moves errors out of the information positions so that the original message can be determined. In this paper, we investigate permutation decoding for certain families of algebraic geometry codes. Automorphisms of the underlying curve are used to specify permutation automorphisms of the code. Specifically, we describe permutation decoding sets that correct specific burst errors for one-point codes on Hermitian and norm-trace curves.

</details>


### [26] [On the Optimal Integer-Forcing Precoding: A Geometric Perspective and a Polynomial-Time Algorithm](https://arxiv.org/abs/2602.20529)
*Junren Qin,Fan Jiang,Tao Yang,Shanxiang Lyu,Rongke Liu,Shi Jin*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The joint optimization of the integer matrix $\mathbf{A}$ and the power scaling matrix $\mathbf{D}$ is central to achieving the capacity-approaching performance of Integer-Forcing (IF) precoding. This problem, however, is known to be NP-hard, presenting a fundamental computational bottleneck. In this paper, we reveal that the solution space of this problem admits a intrinsic geometric structure: it can be partitioned into a finite number of conical regions, each associated with a distinct full-rank integer matrix $\mathbf{A}$. Leveraging this decomposition, we transform the NP-hard problem into a search over these regions and propose the Multi-Cone Nested Stochastic Pattern Search (MCN-SPS) algorithm. Our main theoretical result is that MCN-SPS finds a near-optimal solution with a computational complexity of $\mathcal{O}\left(K^4\log K\log_2(r_0)\right)$, which is polynomial in the number of users $K$. Numerical simulations corroborate the theoretical analysis and demonstrate the algorithm's efficacy.

</details>


### [27] [Efficient Solvers for Coupling-Aware Beamforming in Continuous Aperture Arrays](https://arxiv.org/abs/2602.20599)
*Geonhee Lee,Kwonyeol Park,Hyeongjun Park,Jinwoo An,Junil Choi*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In continuous aperture arrays (CAPAs), careful consideration of the underlying physics is essential, among which electromagnetic (EM) mutual coupling plays a critical role in beamforming performance. Building on a physically consistent mutual coupling model, the beamforming design is formulated as a functional optimization whose optimality condition leads to a Fredholm integral equation. The incorporation of the coupling model, however, substantially increases computational complexity, necessitating efficient and accurate integral equation solvers. In this letter, we propose two efficient solvers: 1) a coordinate-transformation-based kernel approximation that preserves the operator structure while alleviating discretization demands, and 2) a direct lower-upper (LU)-based solver that stably handles the Nyström-discretized system. Numerical results demonstrate improved accuracy and reduced computational overhead compared to conventional methods, with the LU-based solver emerging as an efficient and scalable solution for large-scale CAPA optimization via offline factorization.

</details>


### [28] [Insertion Correcting Capability for Quantum Deletion-Correcting Codes](https://arxiv.org/abs/2602.20635)
*Ken Nakamura,Takayuki Nozaki*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proves that any quantum t-deletion-correcting codes also correct a total of t insertion and deletion errors under a certain condition. Here, this condition is that a set of quantum states is defined as a quantum error-correcting code if the error spheres of its states are disjoint, as classical coding theory. In addition, this paper proposes the quantum indel distance and describes insertion and deletion errors correcting capability of quantum codes by this distance.

</details>


### [29] [Topology-Aware Integrated Communication, Sensing, and Power Transfer for SAGIN](https://arxiv.org/abs/2602.20908)
*Han Yu,Jiajun He,Xinping Yi,Feng Yin,Hing Cheung So,Giuseppe Caire*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The space-air-ground integrated network (SAGIN) has garnered significant attention in recent years due to its capability to extend communication networks from terrestrial environments to near-ground and space contexts. The application of SAGIN enables to achieve a high-quality, multi-functional, and complex communication requirements, which are essential for sixth-generation communication systems. This paper presents a topology aware (TA) framework to leverage the topological structure in SAGIN to address the multi-functional communication challenge, particularly the integrated sensing, communication, and power transfer (ISCPT) problem. To take advantage of the topological structure, we initially establish the topology according to the criteria of visibility and channel strength. The ISCPT problem can be reformulated into a topological structure as a mixed integer linear program, providing valuable insights from the objectives and constraints. Results demonstrate the superior performance of our solution compared to the benchmarks.

</details>


### [30] [Topology-Aware Coordination for Multi-Functional Low-Altitude Wireless Networks](https://arxiv.org/abs/2602.20993)
*Jiajun He,Han Yu,Yiran Guo,Xinping Yi,Fan Liu,Hing Cheung So,Hien Quoc Ngo,Michail Matthaiou,Giuseppe Caire*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Low-altitude wireless networks (LAWNs) are expected to consist of multi-tier, heterogeneous terrestrial and non-terrestrial devices, where effective coordination is essential to fully unlock the complementary capabilities of diverse systems from different vendors. To address this issue, we propose a novel multi-functional coordination framework that enables seamless cooperation within the LAWN while supporting efficient execution of diverse network functions. In the proposed architecture, each device or infrastructure element is assigned to a specific functional role, namely, edge mobile terminal (E-MT), distributed MT (D-MT), or computing center. E-MTs are equipped with lightweight, independent signal processing and computing capabilities, while D-MTs and the computing center handle regional and global coordination, respectively. To enhance the overall network efficiency, we model the LAWN as a sparse graph, where nodes represent network nodes and edges are defined according to a set of controllable connection rules. This topology-aware (TA) representation allows for efficiently solving various coordination tasks across the network. Numerical results show that the proposed TA coordination framework outperforms baseline approaches that lack topological insights, achieving higher efficiency in multi-task coordination. Finally, we discuss key technical challenges and outline potential solutions for future deployment.

</details>


### [31] [Delay Alignment Modulation for Secure ISAC Systems](https://arxiv.org/abs/2602.21114)
*Tianyu Lu,Jiajun He,Mohammadali Mohammadi,Michail Matthaiou*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces delay-alignment modulation (DAM) for secure integrated sensing and communication (ISAC). Due to the broadcast nature of multi-user downlinks, communications are vulnerable to eavesdropping. DAM applies controlled per-path symbol delays at the transmitter to coherently align the multipath components at the intended user, enhancing the received signal power, while simultaneously creating delay misalignment at the eavesdropper (Eve). To mitigate sensing degradation caused by multipath propagation, we propose a two-stage protocol that first estimates the angle and then the delay of the line-of-sight (LoS) path after suppressing multipath interference. We derive the secrecy spectral efficiency (SSE) and the Cramer-Rao (CRB) of the target delay. Finally, we develop a path-based zero-forcing (ZF) precoding framework and formulate a max-min SSE design under CRB and power constraints. Simulation results show DAM significantly outperforms the strongest-path (SP) benchmark in terms of SSE, while meeting sensing requirements, since intentional delay alignment at legitimate users degrades reception at Eve.

</details>


### [32] [TCDA: Robust 2D-DOA Estimation for Defective L-Shaped Arrays](https://arxiv.org/abs/2602.21146)
*Wenlong Wang,Tianyang Zhang,Tailun Dong,Lei Zhang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While tensor-based methods excel at Direction-of-Arrival (DOA) estimation, their performance degrades severely with faulty or sparse arrays that violate the required manifold structure. To address this challenge, we propose Tensor Completion for Defective Arrays (TCDA), a robust algorithm that reformulates the physical imperfection problem as a data recovery task within a virtual tensor space. We present a detailed derivation for constructing an incomplete third-order Parallel Factor Analysis (PARAFAC) tensor from the faulty array signals via subarray partitioning, cross-correlation, and dimensional reshaping. Leveraging the tensor's inherent low-rank structure, an Alternating Least Squares (ALS)-based algorithm directly recovers the factor matrices embedding the DOA parameters from the incomplete observations. This approach provides a software-defined 'self-healing' capability, demonstrating exceptional robustness against random element failures without requiring additional processing steps for DOA estimation.

</details>


### [33] [Phase-Aware Localization in Pinching Antenna Systems: CRLB Analysis and ML Estimation](https://arxiv.org/abs/2602.21162)
*Hao Feng,Ebrahim Bedeer,Ming Zeng,Xingwang Li,Shimin Gong,Quoc-Viet Pham*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Pinching antenna systems (PASS) have recently emerged as a promising architecture for high-frequency wireless communications. In this letter, we investigate localization in PASS by jointly exploiting the received signal amplitude and phase information, unlike recent works that consider only the amplitude information. A complex baseband signal model is formulated to capture free-space path loss, waveguide attenuation, and distance-dependent phase rotation between the user and each pinching antenna. Using this model, we derive the Fisher information matrix (FIM) with respect to the user location and obtain closed-form expressions for the Cramer-Rao lower bound (CRLB) and the position error bound (PEB). A maximum likelihood (ML) estimator that jointly considers the received signal amplitude and phase is developed to estimate the unknown user location. Given the non-convexity of the estimation problem, a two-stage solution combining coarse grid search and Levenberg-Marquardt refinement is proposed. Numerical results demonstrate that the proposed phase-aware estimator outperforms existing amplitude-only method in terms of positioning accuracy.

</details>


### [34] [Wireless-Fed Pinching-Antenna Systems with Horn Antennas](https://arxiv.org/abs/2602.21167)
*Hao Feng,Ming Zeng,Ebrahim Bedeer,Xingwang Li,Octavia A. Dobre,Zhiguo Ding*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Pinching-antenna systems have recently emerged as a promising solution for enhancing coverage in high-frequency wireless communications by guiding signals through dielectric waveguides and radiating them via position-adjustable antennas. However, their practical deployment is fundamentally constrained by waveguide attenuation and line-installation requirements, which limit the achievable coverage range. To address this challenge, this paper investigates a wireless-fed pinching-antenna architecture that employs highly directional horn antennas to enable efficient coverage extension. Specifically, a full-duplex amplify-and-forward relay equipped with horn antennas is introduced between the base station and the waveguide input, which significantly improves the link budget in high-frequency bands while effectively eliminating self-interference. On this basis, we formulate a total power minimization problem subject to a quality-of-service constraint at the user equipment, involving the joint optimization of the pinching-antenna position, the relay amplification gain, and the base station transmit power. By exploiting the structure of the end-to-end signal-to-noise ratio, the optimal pinching-antenna position is first obtained in closed form by balancing waveguide attenuation and free-space path loss. Subsequently, closed-form expressions for the optimal relay gain and transmit power are derived. Numerical results demonstrate that the proposed scheme substantially outperforms conventional systems without relaying and relay-assisted transmission with fixed antennas in terms of total power consumption.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [35] [AWCP: A Workspace Delegation Protocol for Deep-Engagement Collaboration across Remote Agents](https://arxiv.org/abs/2602.20493)
*Xiaohang Nie,Zihan Guo,Youliang Chen,Yuanjian Zhou,Weinan Zhang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The rapid evolution of Large Language Model (LLM)-based autonomous agents is reshaping the digital landscape toward an emerging Agentic Web, where increasingly specialized agents must collaborate to accomplish complex tasks. However, existing collaboration paradigms are constrained to message passing, leaving execution environments as isolated silos. This creates a context gap: agents cannot directly manipulate files or invoke tools in a peer's environment, and must instead resort to costly, error-prone environment reconstruction. We introduce the Agent Workspace Collaboration Protocol (AWCP), which bridges this gap through temporary workspace delegation inspired by the Unix philosophy that everything is a file. AWCP decouples a lightweight control plane from pluggable transport mechanisms, allowing a Delegator to project its workspace to a remote Executor, who then operates on the shared files directly with unmodified local toolchains. We provide a fully open-source reference implementation with MCP tool integration and validate the protocol through live demonstrations of asymmetric collaboration, where agents with complementary capabilities cooperate through delegated workspaces. By establishing the missing workspace layer in the agentic protocol stack, AWCP paves the way for a universally interoperable agent ecosystem in which collaboration transcends message boundaries. The protocol and reference implementation are publicly available at https://github.com/SII-Holos/awcp.

</details>


### [36] [Deep Reinforcement Learning Based Block Coordinate Descent for Downlink Weighted Sum-rate Maximization on AI-Native Wireless Networks](https://arxiv.org/abs/2602.20724)
*Siya Chen,Chee Wei Tan,H. Vincent Poor*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces a deep reinforcement learning-based block coordinate descent (DRL-based BCD) algorithm to address the nonconvex weighted sum-rate maximization (WSRM) problem with a total power constraint. Firstly, we present an efficient block coordinate descent (BCD) method to solve the problem. We then integrate deep reinforcement learning (DRL) techniques into the BCD method and propose the DRL-based BCD algorithm. This approach combines the data-driven learning capability of machine learning techniques with the navigational and decision-making characteristics of the optimization-theoretic-based BCD method. This combination significantly improves the algorithm's performance by reducing its sensitivity to initial points and mitigating the risk of entrapment in local optima. The primary advantages of the proposed DRL-based BCD algorithm lie in its ability to adhere to the constraints of the WSRM problem and significantly enhance accuracy, potentially achieving the exact optimal solution. Moreover, unlike many pure machine-learning approaches, the DRL-based BCD algorithm capitalizes on the underlying theoretical analysis of the WSRM problem's structure. This enables it to be easily trained and computationally efficient while maintaining a level of interpretability. Through numerical experiments, the DRL-based BCD algorithm demonstrates substantial advantages in effectiveness, efficiency, robustness, and interpretability for maximizing sum rates, which also provides valuable potential for designing resource-constrained AI-native wireless optimization strategies in next-generation wireless networks.

</details>


### [37] [Airavat: An Agentic Framework for Internet Measurement](https://arxiv.org/abs/2602.20924)
*Alagappan Ramanathan,Eunju Kang,Dongsu Han,Sangeetha Abdu Jyothi*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Internet measurement faces twin challenges: complex analyses require expert-level orchestration of tools, yet even syntactically correct implementations can have methodological flaws and can be difficult to verify. Democratizing measurement capabilities thus demands automating both workflow generation and verification against methodological standards established through decades of research.
  We present Airavat, the first agentic framework for Internet measurement workflow generation with systematic verification and validation. Airavat coordinates a set of agents mirroring expert reasoning: three agents handle problem decomposition, solution design, and code implementation, with assistance from a registry of existing tools. Two specialized engines ensure methodological correctness: a Verification Engine evaluates workflows against a knowledge graph encoding five decades of measurement research, while a Validation Engine identifies appropriate validation techniques grounded in established methodologies. Through four Internet measurement case studies, we demonstrate that Airavat (i) generates workflows matching expert-level solutions, (ii) makes sound architectural decisions, (iii) addresses novel problems without ground truth, and (iv) identifies methodological flaws missed by standard execution-based testing.

</details>
