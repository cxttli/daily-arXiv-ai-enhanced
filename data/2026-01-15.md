<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 15]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.IT](#cs.IT) [Total: 27]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Joint Beamforming and Position Optimization for Movable-Antenna and Movable-Element RIS-Aided Full-Duplex 6G MISO Systems](https://arxiv.org/abs/2601.08922)
*Ayda Nodel Hokmabadi,Chadi Assi*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Full-duplex communication substantially enhances spectral efficiency by enabling simultaneous transmission and reception on the same time-frequency resources. However, its practical deployment remains hindered by strong residual self-interference and inter-user interference, which severely degrade system performance. This work investigates a full-duplex MISO network that leverages movable-antenna base stations (MA-BS) and movable-element reconfigurable intelligent surfaces (ME-RIS) to overcome these limitations in next-generation 6G systems. Unlike conventional fixed-geometry architectures, the proposed framework jointly optimizes antenna and RIS element positions, together with RIS phase shifts, to strengthen desired links while suppressing interference. Our design objective is to maximize the system sum rate through the joint optimization of transmit and receive beamforming vectors, uplink transmit powers, RIS phase shifts, and the spatial locations of both the BS antennas and RIS elements. To solve this challenging nonconvex problem, an alternating optimization algorithm is developed, employing semidefinite relaxation for beamforming design and successive convex approximation for position optimization. Simulation results demonstrate that the proposed ME-RIS-assisted architecture with movable BS antennas offers substantial gains over conventional fixed-position full-duplex networks. These findings highlight the potential of integrating movable antennas with movable RIS elements as a key enabler for high-performance full-duplex operation in future 6G wireless systems.

</details>


### [2] [Robust Consensus-Based Distributed Beamforming for Wideband Cell-free Multi-RIS MISO Systems](https://arxiv.org/abs/2601.08946)
*Konstantinos D. Katsanos,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The cell-free networking paradigm constitutes a revolutionary architecture for future generations of wireless networks, which has been recently considered in synergy with Reconfigurable Intelligent Surfaces (RISs), a promising physical-layer technology for signal propagation programmability. In this paper, we focus on wideband cell-free multi-RIS-empowered Multiple-Input Single-Output (MISO) systems and present a decentralized cooperative active and passive beamforming scheme, aiming to provide an efficient alternative towards the cooperation overhead of available centralized schemes depending on central processing unit. Considering imperfect channel information availability and realistic frequency selectivity behavior of each RIS's element response, we devise a distributed optimization approach based on consensus updates for the RISs' phase configurations. Our simulation results showcase that the proposed distributed design is superior to centralized schemes that are based on various Lorentzian-type wideband modeling approaches for the RISs.

</details>


### [3] [Joint DOA and Non-circular Phase Estimation of Non-circular Signals for Antenna Arrays: Block Sparse Bayesian Learning Method](https://arxiv.org/abs/2601.09148)
*Zihan Shen,Jiaqi Li,Xudong Dong,Xiaofei Zhang*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This letter proposes a block sparse Bayesian learning (BSBL) algorithm of non-circular (NC) signals for direction-of-arrival (DOA) estimation, which is suitable for arbitrary unknown NC phases. The block sparse NC signal representation model is constructed through a permutation strategy, capturing the available intra-block structure information to enhance recovery performance. After that, we create the sparse probability model and derive the cost function under BSBL framework. Finally, the fast marginal likelihood maximum (FMLM) algorithm is introduced, enabling the rapid implementation of signal recovery by the addition and removal of basis functions. Simulation results demonstrate the effectiveness and the superior performance of our proposed method.

</details>


### [4] [User-Centric Stream Sensing for Grant-Free Access: Deep Learning with Covariance Differencing](https://arxiv.org/abs/2601.09168)
*Sojeong Park,Yeongjun Kim,Hyun Jong Yang*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Grant-free (GF) access is essential for massive connectivity but faces collision risks due to uncoordinated transmissions. While user-side sensing can mitigate these collisions by enabling autonomous transmission decisions, conventional methods become ineffective in overloaded scenarios where active streams exceed receive antennas. To address this problem, we propose a differential stream sensing framework that reframes the problem from estimating the total stream count to isolating newly activated streams via covariance differencing. We analyze the covariance deviation induced by channel variations to establish a theoretical bound based on channel correlation for determining the sensing window size. To mitigate residual interference from finite sampling, a deep learning (DL) classifier is integrated. Simulations across both independent and identically distributed flat Rayleigh fading and standardized channel environments demonstrate that the proposed method consistently outperforms non-DL baselines and remains robust in overloaded scenarios.

</details>


### [5] [WiFo-M$^2$: Plug-and-Play Multi-Modal Sensing via Foundation Model to Empower Wireless Communications](https://arxiv.org/abs/2601.09179)
*Haotian Zhang,Shijian Gao,Xiang Cheng*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The growing adoption of sensor-rich intelligent systems has boosted the use of multi-modal sensing to improve wireless communications. However, traditional methods require extensive manual design of data preprocessing, network architecture, and task-specific fine-tuning, which limits both development scalability and real-world deployment. To address this, we propose WiFo-M$^2$, a foundation model that can be easily plugged into existing deep learning-based transceivers for universal performance gains. To extract generalizable out-of-band (OOB) channel features from multi-modal sensing, we introduce ContraSoM, a contrastive pre-training strategy. Once pre-trained, WiFo-M$^2$ infers future OOB channel features from historical sensor data and strengthens feature robustness via modality-specific data augmentation. Experiments show that WiFo-M$^2$ improves performance across multiple transceiver designs and demonstrates strong generalization to unseen scenarios.

</details>


### [6] [WiFo-E: A Scalable Wireless Foundation Model for End-to-End FDD Precoding in Communication Networks](https://arxiv.org/abs/2601.09186)
*Weibo Wen,Shijian Gao,Haotian Zhang,Xiang Cheng,Liuqing Yang*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate precoding in massive multiple-input multiple-output (MIMO) frequency-division duplexing (FDD) systems relies on efficient channel state information (CSI) acquisition. End-to-end learning frameworks improve performance by jointly optimizing this process, but they lack scalability and fail to generalize across different system configurations, such as varying numbers of antennas and users. To overcome this limitation, we introduce WiFo-E, a wireless foundation model designed for scalable end-to-end precoding. WiFo-E employs multi-task pretraining on a diverse set of configurations to learn transferable representations of underlying wireless principles. Central to the model is a sparse Mixture-of-Experts (MoE) Transformer architecture, which mitigates task interference and enhances training efficiency by activating specialized parameter subsets adaptively. Extensive simulations demonstrate that WiFo-E outperforms conventional per-configuration training and shows strong generalization to unseen system configurations, providing a flexible and efficient foundation for adaptive massive MIMO precoding.

</details>


### [7] [Artificial Intelligence Empowered Channel Prediction: A New Paradigm for Propagation Channel Modeling](https://arxiv.org/abs/2601.09205)
*Ruisi He,Mi Yang,Zhengyu Zhang,Bo Ai,Zhangdui Zhong*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a novel paradigm centered on Artificial Intelligence (AI)-empowered propagation channel prediction to address the limitations of traditional channel modeling. We present a comprehensive framework that deeply integrates heterogeneous environmental data and physical propagation knowledge into AI models for site-specific channel prediction, which referred to as channel inference. By leveraging AI to infer site-specific wireless channel states, the proposed paradigm enables accurate prediction of channel characteristics at both link and area levels, capturing spatio-temporal evolution of radio propagation. Some novel strategies to realize the paradigm are introduced and discussed, including AI-native and AI-hybrid inference approaches. This paper also investigates how to enhance model generalization through transfer learning and improve interpretability via explainable AI techniques. Our approach demonstrates significant practical efficacy, achieving an average path loss prediction root mean square error (RMSE) of $\sim$ 4 dB and reducing training time by 60\%-75\%. This new modeling paradigm provides a foundational pathway toward high-fidelity, generalizable, and physically consistent propagation channel prediction for future communication networks.

</details>


### [8] [Range-Doppler-Acceleration Estimation for Fast-Moving and Accelerating Targets](https://arxiv.org/abs/2601.09317)
*Nadav Neuberger,Simon Kollecker,Martin Kaeske*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A central aspect of every pulsed radar signal processor is the targets Range-Doppler estimation within a Coherent Processing Interval. Conventional methods typically rely on simplifying assumptions, such as linear target motion, narrowband operation, or constant velocity, to enable fast computation. However, these assumptions break down in scenarios involving quadratic range-time behavior, high radial velocities or accelerations, or wideband signals, leading to undesired effects such as intra-pulse Doppler shift/stretch and target migration across Range-Doppler cells. This paper presents a generalized waveform-independent Range-Doppler compression approach that compensates for these effects while maintaining minimal Signal-to-Noise-Ratio loss and practical computational efficiency. The performance limits of the proposed method are analyzed and expressed through a unified metric that depends on both scene and system parameters. Comparison with other approaches is presented, showing their estimation bias and performance degradation.

</details>


### [9] [A Hybrid Machine Learning Framework for Improved Short-Term Peak-Flow Forecasting](https://arxiv.org/abs/2601.09336)
*Gabriele Bertoli,Kai Schroeter,Rossella Arcucci,Enrica Caporali*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reliable river flow forecasting is an essential component of flood risk management and early warning systems. It enables improved emergency response coordination and is critical for protecting infrastructure, communities, and ecosystems from extreme hydrological events. Process-based hydrological models and purely data-driven approaches often underperform during extreme events, particularly in forecasting peak flows. To address this limitation, this study introduces a hybrid forecasting framework that couples Extreme Gradient Boosting (XGBoost) and Random Forest (RF). XGBoost is employed for continuous streamflow forecasting, while RF is specifically trained for peak-flow prediction, and the two outputs are combined into an enhanced forecast. The approach is implemented across 857 catchments of the LamaH-CE dataset, using rainfall and discharge observations at 6-hour resolution. Results demonstrate consistently high skill, with 71% of catchments achieving a Kling-Gupta Efficiency (KGE) greater than 0.90. Peak-flow detection reaches 87%, with a false-alarm rate of 13%. Compared to the European Flood Awareness System (EFAS), the framework achieves lower peak-magnitude errors, fewer false alarms, and improved streamflow and peak-flow forecasting accuracy. The proposed framework is computationally lightweight, scalable, and easily transferable across watersheds, with training times of only seconds on standard CPUs. These findings highlight the potential of integrating hydrological understanding with efficient machine learning to improve the accuracy and reliability of operational flood forecasting, and outline future directions for hybrid hydrological-machine learning model development.

</details>


### [10] [Unique Word Channel Estimation for Oversampled OTFS](https://arxiv.org/abs/2601.09364)
*Radim Zedka,Roman Marsalek,Marek Bobula,Arman Farhang*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Practical aspects of orthogonal time frequency space (OTFS), such as channel estimation and its performance in fractional delay-Doppler (DD) channels, are a lively topic in the OTFS community. Oversampling and pulse shaping are also discussed in the existing literature, but not in the context of channel estimation. To the best of our knowledge, this paper is the first to address the problem of data-to-pilot and vice versa energy leakage caused by oversampling and pulse shaping in OTFS. Theoretical analysis is performed on an oversampled, pulse-shaped OTFS implementing the embedded pilot channel estimation technique, revealing a trade-off between the amount of energy leakage and excess bandwidth introduced by the pulse shape. Next, a novel variant of OTFS is introduced, called UW-OTFS, which is designed to overcome the leakage problem by placing the pilot in the oversampled time domain instead of the DD domain. The unique structure of UW-OTFS offers 36 percent higher spectral efficiency than the OTFS with embedded pilot. UW-OTFS also outperforms traditional OTFS in terms of bit error ratio and out-of-band emissions.

</details>


### [11] [Uplink Multi-User MIMO Implementation in OpenAirInterface for a Cell-Free O-RAN Testbed](https://arxiv.org/abs/2601.09384)
*Utku Uçak,Fariba Armandoust,Matthias Mehlhose,Daniel Schäufele,Jochen Fink,Renato L. G. Cavalcante,Sławomir Stańczak*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cell-Free Multiple-Input Multiple-Output (MIMO) and Open Radio Access Network (O-RAN) have been active research topics in the wireless communication community in recent years. As an open-source software implementation of the 3rd Generation Partnership Project (3GPP) 5th Generation (5G) protocol stack, OpenAirInterface (OAI) has become a valuable tool for deploying and testing new ideas in wireless communication systems. In this paper, we present our OAI based real-time uplink Multi-User MIMO (MU-MIMO) testbed developed at Fraunhofer HHI. As a part of our Cell-Free MIMO testbed development, we built a 2x2 MU-MIMO system using general purpose computers and commercially available software defined radios (SDRs). Using a modified OAI next-Generation Node-B (gNB) and two unmodified OAI user equipment (UE), we show that it is feasible to use Sounding Reference Signal (SRS) channel estimates to compute uplink combiners. Our results verify that this method can be used to separate and decode signals from two users transmitting in nonorthogonal time-frequency resources. This work serves as an important verification step to build a complete Cell-Free MU-MIMO system that leverages time domain duplexing (TDD) reciprocity to do downlink beamforming over multiple cells.

</details>


### [12] [Beamforming Gain with Nonideal Phase Shifters](https://arxiv.org/abs/2601.09426)
*Heedong Do,Angel Lozano*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This research sets forth a universal framework to characterize the beamforming gain achievable with arbitrarily nonideal phase shifters. Precisely, the maximum possible shortfall relative to the gain attainable with ideal phase shifters is established. Such shortfall is shown to be fundamentally determined by the perimeter of the convex hull of the set of feasible beamforming coefficients on the complex plane. This result holds regardless of whether the beamforming is at the transmitter, at the receiver, or at a reconfigurable intelligent surface. In i.i.d. fading channels, the shortfall hardens to the maximum possible shortfall as the number of antennas grows.

</details>


### [13] [Two-Scale Spatial Deployment for Cost-Effective Wireless Networks via Cooperative IRSs and Movable Antennas](https://arxiv.org/abs/2601.09463)
*Ying Gao,Qingqing Wu,Ziyuan Zheng,Yanze Zhu,Wen Chen,Xin Lin,Shanpu Shen*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a two-scale spatial deployment strategy to ensure reliable coverage for multiple target areas, integrating macroscopic intelligent reflecting surfaces (IRSs) and fine-grained movable antennas (MAs). Specifically, IRSs are selectively deployed from candidate sites to shape the propagation geometry, while MAs are locally repositioned among discretized locations to exploit small-scale channel variations. The objective is to minimize the total deployment cost of MAs and IRSs by jointly optimizing the IRS site selection, MA positions, transmit precoding, and IRS phase shifts, subject to the signal-to-noise ratio (SNR) requirements for all target areas. This leads to a challenging mixed-integer non-convex optimization problem that is intractable to solve directly. To address this, we first formulate an auxiliary problem to verify the feasibility. A penalty-based double-loop algorithm integrating alternating optimization and successive convex approximation (SCA) is developed to solve this feasibility issue, which is subsequently adapted to obtain a suboptimal solution for the original cost minimization problem. Finally, based on the obtained solution, we formulate an element refinement problem to further reduce the deployment cost, which is solved by a penalty-based SCA algorithm. Simulation results demonstrate that the proposed designs consistently outperform benchmarks relying on independent area planning or full IRS deployment in terms of cost-efficiency. Moreover, for cost minimization, MA architectures are preferable in large placement apertures, whereas fully populated FPA architectures excel in compact ones; for worst-case SNR maximization, MA architectures exhibit a lower cost threshold for feasibility, while FPA architectures can attain peak SNR at a lower total cost.

</details>


### [14] [Echo-Side Integrated Sensing and Communication via Space-Time Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2601.09484)
*Marouan Mizmizi,Stefano Tebaldini,Umberto Spagnolini*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents an echo-side modulation framework for integrated sensing and communication (ISAC) systems. A space-time reconfigurable intelligent surface (ST-RIS) impresses a continuous-phase modulation onto the radar echo, enabling uplink data transmission with a phase modulation of the transmitted radar-like waveform. The received signal is a multiplicative composition of the sensing waveform and the phase for communication. Both functionalities share the same physical signal and perceive each other as impairments.
  The achievable communication rate is expressed as a function of a coupling parameter that links sensing accuracy to phase error accumulation. Under a fixed bandwidth constraint, the sensing and communication figures of merit define a convex Pareto frontier. The optimal bandwidth allocation satisfying a minimum sensing requirement is derived in closed form. The modified Cramer-Rao bound (MCRB) for range estimation is derived in closed form; this parameter must be estimated to compensate for the frequency offset before data demodulation. Frame synchronization is formulated as a generalized likelihood ratio test (GLRT), and the detection probability is obtained through characteristic function inversion, accounting for residual frequency errors from imperfect range estimation. Numerical results validate the theoretical bounds and characterize the trade-off across the operating range.

</details>


### [15] [Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems](https://arxiv.org/abs/2601.09701)
*Fahimeh Orvati Nia,Shima Salehi,Joshua Peeples*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Advanced metering infrastructure (AMI) provides high-resolution electricity consumption data that can enhance monitoring, diagnosis, and decision making in modern power distribution systems. Detecting anomalies in these time-series measurements is challenging due to nonlinear, nonstationary, and multi-scale temporal behavior across diverse building types and operating conditions. This work presents a systematic, power-system-oriented evaluation of a GAN-LSTM framework for smart meter anomaly detection using the Large-scale Energy Anomaly Detection (LEAD) dataset, which contains one year of hourly measurements from 406 buildings. The proposed pipeline applies consistent preprocessing, temporal windowing, and threshold selection across all methods, and compares the GAN-LSTM approach against six widely used baselines, including statistical, kernel-based, reconstruction-based, and GAN-based models. Experimental results demonstrate that the GAN-LSTM significantly improves detection performance, achieving an F1-score of 0.89. These findings highlight the potential of adversarial temporal modeling as a practical tool for supporting asset monitoring, non-technical loss detection, and situational awareness in real-world power distribution networks. The code for this work is publicly available

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [16] [Streamlined Pathway (SP) Approach: An Efficient Load Balancer to Enhance Quality of Service](https://arxiv.org/abs/2601.08887)
*Aymen Hasan Alawadi*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Efficient load-balancing mechanisms are critical for maximizing performance and increasing the quality of service (QoS) of data center networks (DCNs). Obtaining the optimal QoS while minimizing resource consumption remains a significant challenge. This paper proposes the streamlined pathway (SP) model, which is a flow scheduling solution that requires minimal statistical knowledge of the DCN data plane. The SP model utilizes the software-defined networks (SDN) paradigm with less information gathered from the DCN data plane, besides the traditional hash-based flow scheduling mechanism, the Equal Cost Multi-Path (ECMP). In SDN, the proposed methodology harnesses a minimal yet powerful set of statistical data extracted from the DCN data plane, including port throughput and elephant flow information on the aggregate switches of the DCN fat-tree topology. Several experiments, in addition to theoretical analysis, have been conducted to demonstrate the efficiency of the proposed SP model in terms of QoS enhancement. These results confirm that SP outperforms leading techniques such as Sieve, Hedera, and ECMP, concerning bisection bandwidth, DCN link utilization, packet loss, and packet delivery latency.

</details>


### [17] [UAV-enabled Computing Power Networks: Design and Performance Analysis under Energy Constraints](https://arxiv.org/abs/2601.09493)
*Yiqin Deng,Zhengru Fang,Senkang Hu,Yanan Ma,Xiaoyu Guo,Haixia Zhang,Yuguang Fang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents an innovative framework that boosts computing power by utilizing ubiquitous computing power distribution and enabling higher computing node accessibility via adaptive UAV positioning, establishing a UAV-enabled Computing Power Network (UAV-CPN). In a UAV-CPN, a UAV functions as a dynamic relay, outsourcing computing tasks from the request zone to an expanded service zone with diverse computing nodes, including vehicle onboard units, edge servers, and dedicated powerful nodes. This approach has the potential to alleviate communication bottlenecks and overcome the "island effect" observed in multi-access edge computing. A significant challenge is to quantify computing power performance under complex dynamics of communication and computing. To address this challenge, we introduce task completion probability to capture the capability of UAV-CPNs for task computing. We further enhance UAV-CPN performance under a hybrid energy architecture by jointly optimizing UAV altitude and transmit power, where fuel cells and batteries collectively power both UAV propulsion and communication systems. Extensive evaluations show significant performance gains, highlighting the importance of balancing communication and computing capabilities, especially under dual-energy constraints. These findings underscore the potential of UAV-CPNs to significantly boost computing power.

</details>


### [18] [FairShare: Auditable Geographic Fairness for Multi-Operator LEO Spectrum Sharing](https://arxiv.org/abs/2601.09641)
*Seyed Bagher Hashemi Natanzi,Hossein Mohammadi,Vuk Marojevic,Bo Tang*

Main category: cs.NI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Dynamic spectrum sharing (DSS) among multi-operator low Earth orbit (LEO) mega-constellations is essential for coexistence, yet prevailing policies focus almost exclusively on interference mitigation, leaving geographic equity largely unaddressed. This work investigates whether conventional DSS approaches inadvertently exacerbate the rural digital divide. Through large-scale, 3GPP-compliant non-terrestrial network (NTN) simulations with geographically distributed users, we systematically evaluate standard allocation policies. The results uncover a stark and persistent structural bias: SNR-priority scheduling induces a 1.65x urban-rural access disparity, privileging users with favorable satellite geometry. Counter-intuitively, increasing system bandwidth amplifies rather than alleviates this gap, with disparity rising from 1.0x to 1.65x as resources expand. To remedy this, we propose FairShare, a lightweight, quota-based framework that enforces geographic fairness. FairShare not only reverses the bias, achieving an affirmative disparity ratio of Delta_geo = 0.72x, but also reduces scheduler runtime by 3.3%. This demonstrates that algorithmic fairness can be achieved without trading off efficiency or complexity. Our work provides regulators with both a diagnostic metric for auditing fairness and a practical, enforceable mechanism for equitable spectrum governance in next-generation satellite networks.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [19] [Two-dimensional Entanglement-assisted Quantum Quasi-cyclic Low-density Parity-check Codes](https://arxiv.org/abs/2601.08927)
*Pavan Kumar,Shayan Srinivasa Garani*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For any positive integer $g \ge 2$, we derive general conditions for the existence of a $2g$-cycle in the Tanner graph of two-dimensional ($2$-D) classical quasi-cyclic (QC) low-density parity-check (LDPC) codes. Based on these conditions, we construct a family of $2$-D classical QC-LDPC codes with girth greater than $4$ by stacking $p \times p \times p$ tensors, where $p$ is an odd prime. Furthermore, for composite values of $p$, we propose two additional families of $2$-D classical LDPC codes obtained via similar tensor stacking. In this case, one family achieves girth greater than $4$, while the other attains girth greater than $6$. All the proposed $2$-D classical QC-LDPC codes exhibit an erasure correction capability of at least $p \times p$. Based on the constructed classical $2$-D QC-LDPC codes, we derive two families of $2$-D entanglement-assisted (EA) quantum low-density parity-check (QLDPC) codes. The first family of $2$-D EA-QLDPC codes is obtained from a pair of binary $2$-D classical LDPC codes and is designed such that the unassisted part of the Tanner graph of the resulting EA-QLDPC code is free of cycles of length four, while requiring only a single ebit to be shared across the quantum transceiver. The second family is constructed from a single $2$-D classical LDPC code whose Tanner graph is free from $4$-cycles. Moreover, the constructed EA-QLDPC codes inherit an erasure correction capability of $p \times p$, as the underlying classical codes possess the same erasure correction property.

</details>


### [20] [On the Information Leakage Envelope of the Gaussian Mechanism](https://arxiv.org/abs/2601.08986)
*Sara Saeidian*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the pointwise maximal leakage (PML) envelope of the Gaussian mechanism, which characterizes the smallest information leakage bound that holds with high probability under arbitrary post-processing. For the Gaussian mechanism with a Gaussian secret, we derive a closed-form expression for the deterministic PML envelope for sufficiently small failure probabilities. We then extend this result to general unbounded secrets by identifying a sufficient condition under which the envelope coincides with the Gaussian case. In particular, we show that strongly log-concave priors satisfy this condition via an application of the Brascamp-Lieb inequality.

</details>


### [21] [An Information-Theoretic Perspective on LLM Tokenizers](https://arxiv.org/abs/2601.09039)
*Mete Erdogan,Abhiram Gorle,Shubham Chandak,Mert Pilanci,Tsachy Weissman*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language model (LLM) tokenizers act as structured compressors: by mapping text to discrete token sequences, they determine token count (and thus compute and context usage) and the statistical structure seen by downstream models. Despite their central role in LLM pipelines, the link between tokenization, compression efficiency and induced structure is not well understood. We empirically demonstrate that tokenizer training scale redistributes entropy: as training data grows, the token stream becomes more diverse in aggregate (higher unigram entropy) yet markedly more predictable in-context (lower higher-order conditional entropies), indicating that tokenization absorbs substantial short-range regularity although these gains degrade under train-test domain mismatch. To ground these observations, we first benchmark i) pretrained GPT-family tokenizers as black-box compressors across various domains, and ii) learned tokenizers across configurations spanning vocabulary size, training scale, and domain. Next, we study tokenization as a transform for universal compression and introduce a compression-aware BPE variant. Finally, we adopt a channel lens and introduce capacity-utilization metrics to analyze tokenizer behaviour and outline implications for downstream modeling. Put together, our results expose various trade-offs between compression, induced structure, and robustness under domain shift, and motivate principled, compression-aware tokenizer design.

</details>


### [22] [Hybrid Mono- and Bi-static OFDM-ISAC via BS-UE Cooperation: Closed-Form CRLB and Coverage Analysis](https://arxiv.org/abs/2601.09057)
*Xiaoli Xu,Yong Zeng*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a hybrid mono- and bi-static sensing framework, by leveraging the base station (BS) and user equipment (UE) cooperation in integrated sensing and communication (ISAC) systems. This scheme is built on 3GPP-supported sensing modes, and it does not incur any extra spectrum cost or inter-cell coordination. To reveal the fundamental performance limit of the proposed hybrid sensing mode, we derive closed-form Cramér-Rao lower bound (CRLB) for sensing target localization and velocity estimation, as functions of target and UE positions. The results reveal that significant performance gains can be achieved over the purely mono- or bi-static sensing, especially when the BS-target-UE form a favorable geometry, which is close to a right triangle. The analytical results are validated by simulations using effective parameter estimation algorithm and weighted mean square error (MSE) fusion method. Based on the derived sensing bound, we further analyze the sensing coverage by varying the UE positions, which shows that sensing coverage first improves then degrades as the BS-UE separation increases. Furthermore, the sensing accuracy for a potential target with best UE selection is derived as a function of the UE density in the network.

</details>


### [23] [Overcoming the Shadow: Bending Airy Beams for Radiative Near-Field Multi-User Access in Half-Space Blockage Scenarios](https://arxiv.org/abs/2601.09098)
*Yifeng Qin,Jing Chen,Zhi Hao Jiang,Zhi Ning Chen,Yongming Huang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The move to next-generation wireless communications with extremely large-scale antenna arrays (ELAAs) brings the communications into the radiative near-field (RNF) region, where distance-aware focusing is feasible. However, high-frequency RNF links are highly vulnerable to blockage in indoor environments dominated by half-space obstacles (walls, corners) that create knife-edge shadows. Conventional near-field focused beams offer high gain in line-of-sight (LoS) scenarios but suffer from severe energy truncation and effective-rank collapse in shadowed regions, making hardware remedies such as reconfigurable intelligent surfaces (RIS) impractical. We propose a beamforming strategy that exploits the auto-bending property of Airy beams to mitigate half-space blockage without additional hardware. The Airy beam is designed to ``ride'' the diffraction edge, accelerating its main lobe into the shadow to restore connectivity. Our contributions are threefold: (i) a Green's function-based RNF multi-user channel model that analytically reveals singular-value collapse behind knife-edge obstacles; (ii) an Airy analog beamforming scheme that optimizes the bending trajectory to recover the effective channel rank; and (iii) an Airy null-steering method that aligns oscillatory nulls with bright-region users to suppress interference in mixed shadow/bright scenarios. Simulations show that the proposed edge-riding Airy strategy achieves an SNR improvement of over 20 dB and restores full-rank connectivity in shadowed links compared to conventional RNF focusing, virtually eliminating outage in geometric shadows and increasing multi-user spectral efficiency by approximately 35\% under typical indoor ELAA configurations. These results demonstrate robust RNF multi-user access in half-space blockage scenarios without relying on RIS.

</details>


### [24] [The .serva Standard: One Primitive for All AI Cost Reduced, Barriers Removed](https://arxiv.org/abs/2601.09124)
*Rachel St. Clair,John Austin Cook,Peter Sutor,Victor Cavero,Garrett Mindt*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Artificial Intelligence (AI) infrastructure faces two compounding crises. Compute payload - the unsustainable energy and capital costs of training and inference - threatens to outpace grid capacity and concentrate capability among a handful of organizations. Data chaos - the 80% of project effort consumed by preparation, conversion, and preprocessing - strangles development velocity and locks datasets to single model architectures. Current approaches treat these as separate problems, managing each with incremental optimization while increasing ecosystem complexity. This paper presents ServaStack: a universal data format (.serva) paired with a universal AI compute engine (Chimera). The .serva format achieves lossless compression by encoding information using laser holography principles, while Chimera converts compute operations into a representational space where computation occurs directly on .serva files without decompression. The result is automatic data preprocessing. The Chimera engine enables any existing model to operate on .serva data without retraining, preserving infrastructure investments while revamping efficiency. Internal benchmarks demonstrate 30-374x energy efficiency improvements (96-99% reduction), 4x-34x lossless storage compression, and 68x compute payload reduction without accuracy loss when compared to RNN, CNN, and MLP models on FashionMNIST and MNIST datasets. At hyperscale with one billion daily iterations, these gains translate to $4.85M savings per petabyte per training cycle. When any data flows to any model on any hardware, the AI development paradigm shifts. The bottleneck moves from infrastructure to imagination.

</details>


### [25] [Movable Antenna Assisted Dual-Polarized Multi-Cell Cooperative AirComp: An Alternating Optimization Approach](https://arxiv.org/abs/2601.09137)
*Mingyu Hu,Nan Liu,Wei Kang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Over-the-air computation (AirComp) is a key enabler for distributed optimization, since it leverages analog waveform superposition to perform aggregation and thereby mitigates the communication bottleneck caused by iterative information exchange. However, AirComp is sensitive to wireless environment and conventional systems with fixed single-polarized base-station arrays cannot fully exploit spatial degrees of freedom while also suffering from polarization mismatch. To overcome these limitations, this paper proposes a multi-cell cooperative air-computation framework assisted by dual-polarized movable antennas (D-PMA), and formulates a mean squared error (MSE) minimization problem by jointly optimizing the combining matrix, polarization vectors, antenna positions, and user transmit coefficients. The resulting problem is highly nonconvex, so an alternating algorithm is developed in which closed-form updates are obtained for the combining matrix and transmit coefficients. Then a method based on successive convex approximation (SCA) and semidefinite relaxation (SDR) is proposed to refine polarization vectors, and the antenna positions are updated using a gradient-based method. In addition, we develop a statistical-channel-based scheme for optimizing the antenna locations, and we further present the corresponding algorithm to efficiently obtain the solution. Numerical results show that the proposed movable dual-polarized scheme consistently outperforms movable single-polarized and fixed-antenna baselines under both instantaneous and statistical channels.

</details>


### [26] [Reducing The Sub-packetization Level of Optimal-Access Cooperative MSR Codes](https://arxiv.org/abs/2601.09188)
*Yaqian Zhang,Jingke Xu*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cooperative MSR codes are a kind of storage codes which enable optimal-bandwidth repair of any $h\geq2$ node erasures in a cooperative way, while retaining the minimum storage as an $[n,k]$ MDS code. Each code coordinate (node) is assumed to store an array of $\ell$ symbols, where $\ell$ is termed as sub-packetization. Large sub-packetization tends to induce high complexity, large input/output in practice. To address the disk IO capability, a cooperative MSR code is said to have optimal-access property, if during node repair, the amount of data accessed at each helper node meets a theoretical lower bound.
  In this paper, we focus on reducing the sub-packetization of optimal-access cooperative MSR codes with two erasures. At first, we design two crucial MDS array codes for repairing a specific repair pattern of two erasures with optimal access. Then, using the two codes as building blocks and by stacking up of the two codes for several times, we obtain an optimal-access cooperative MSR code with two erasures. The derived code has sub-packetization $\ell=r^{\binom{n}{2}-\lfloor\frac{n}{r}\rfloor(\binom{r}{2}-1)}$ where $r=n-k$, and it reduces $\ell$ by a fraction of $1/r^{\lfloor\frac{n}{r}\rfloor(\binom{r}{2}-1)}$ compared with the state of the art ($\ell=r^{\binom{n}{2}}$).

</details>


### [27] [On Polar Coding with Feedback](https://arxiv.org/abs/2601.09222)
*Ling Liu,Qi Cao,Liping Li,Baoming Bai*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we investigate the performance of polar codes with the assistance of feedback in communication systems. Although it is well known that feedback does not improve the capacity of memoryless channels, we show that the finite length performance of polar codes can be significantly improved as feedback enables genie-aided decoding and allows more flexible thresholds for the polar coding construction. To analyze the performance under the new construction, we then propose an accurate characterization of the distribution of the error event under the genie-aided successive cancellation (SC) decoding. This characterization can be also used to predict the performance of the standard SC decoding of polar codes with rates close to capacity.

</details>


### [28] [A Theoretical Framework for Rate-Distortion Limits in Learned Image Compression](https://arxiv.org/abs/2601.09254)
*Changshuo Wang,Zijian Liang,Kai Niu,Ping Zhang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a novel systematic theoretical framework to analyze the rate-distortion (R-D) limits of learned image compression. While recent neural codecs have achieved remarkable empirical results, their distance from the information-theoretic limit remains unclear. Our work addresses this gap by decomposing the R-D performance loss into three key components: variance estimation, quantization strategy, and context modeling. First, we derive the optimal latent variance as the second moment under a Gaussian assumption, providing a principled alternative to hyperprior-based estimation. Second, we quantify the gap between uniform quantization and the Gaussian test channel derived from the reverse water-filling theorem. Third, we extend our framework to include context modeling, and demonstrate that accurate mean prediction yields substantial entropy reduction. Unlike prior R-D estimators, our method provides a structurally interpretable perspective that aligns with real compression modules and enables fine-grained analysis. Through joint simulation and end-to-end training, we derive a tight and actionable approximation of the theoretical R-D limits, offering new insights into the design of more efficient learned compression systems.

</details>


### [29] [Regenerating codes with minimal disk I/O cost achieving optimal tradeoff between storage and repair bandwidth](https://arxiv.org/abs/2601.09300)
*Minhan Gao,Kenneth Shum*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: There are multiple performance metrics in the design of coding schemes for distributed storage systems. The first metric is called repair bandwidth, which measures the network resources required during the repair process. Another critical metric for repair efficiency is disk I/O cost, defined as the amount of data packets accessed at helper nodes to repair the failed node. In an encoding scheme with optimal I/O cost, the number of packets sent to the newcomer is exactly the same as the number of packets read from memory. This mode of repair is referred to as uncoded repair, as no coding operations are performed at the helper node. In addition to minimizing disk I/O cost, an uncoded repair mechanism has the advantage of incurring minimal computational overhead at the helper node. In this paper, we demonstrate that for single node failures, if all surviving nodes participate in the repair of the failed node, we can achieve all points on the fundamental tradeoff curve between storage and repair bandwidth. The design of the proposed encoding scheme is based on the theory of gammoids, a specialized class of graph-based matroids. We prove that this scheme can tolerate an unlimited number of node repair iterations over a field of fixed size.

</details>


### [30] [An Information Theoretic Proof of the Radon-Nikodym Theorem](https://arxiv.org/abs/2601.09308)
*Peter Harremoës*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Radon-Nikodym theorem plays a significant role in the definition of Shannon entropy, f-divergences, and other basic quantities in information theory. The existence of Radon Nikodym derivates appear in many text books in measure theory but in text books on probability or information theory it is often omitted because the proof is often considered to be too difficult.

</details>


### [31] [Contraction of Rényi Divergences for Discrete Channels: Properties and Applications](https://arxiv.org/abs/2601.09328)
*Adrien Vandenbroucque,Amedeo Roberto Esposito,Michael Gastpar*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work explores properties of Strong Data-Processing constants for Rényi Divergences. Parallels are made with the well-studied $\varphi$-Divergences, and it is shown that the order $α$ of Rényi Divergences dictates whether certain properties of the contraction of $\varphi$-Divergences are mirrored or not. In particular, we demonstrate that when $α>1$, the contraction properties can deviate quite strikingly from those of $\varphi$-Divergences. We also uncover specific characteristics of contraction for the $\infty$-Rényi Divergence and relate it to $\varepsilon$-Local Differential Privacy. The results are then applied to bound the speed of convergence of Markov chains, where we argue that the contraction of Rényi Divergences offers a new perspective on the contraction of $L^α$-norms commonly studied in the literature.

</details>


### [32] [Generalized Schalkwijk-Kailath Coding for Autoregressive Gaussian Channels](https://arxiv.org/abs/2601.09329)
*Jun Su,Guangyue Han,Shlomo Shamai*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a Gaussian random coding scheme for AR($p$) Gaussian channels that generalizes the celebrated Schalkwijk-Kailath (SK) coding scheme. This constructive coding scheme, termed the SK(2) coding scheme, yields a closed-form characterization for the corresponding achievable rate. Among many others, this result shows that the celebrated SK coding scheme is not universally optimal, and therefore, disprove the conjecture proposed by Butman in \cite{butman1976linear}.

</details>


### [33] [A Constructive Method to Minimize the Index of Coincidence under Marginal Constraints](https://arxiv.org/abs/2601.09347)
*Pierre Jean-Claude Robert Bertrand*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider the problem of minimizing the index of coincidence of a joint distribution under fixed marginal constraints. This objective is motivated by several applications in information theory, where the index of coincidence naturally arises. A closed-form solution is known when the marginals satisfy a strong feasibility condition, but this condition is rarely met in practice. We first show that the measure of the set of marginals for which condition applies vanishes as the dimension grows. We then characterize the structure of the optimal coupling in the general case, proving that it exhibits a monotone staircase of zero entries. Based on this structure, we propose an explicit iterative construction and prove that it converges in finitely many steps to a minimizer. Main result of the paper is a complete constructive solution of index-of-coincidence minimization.

</details>


### [34] [Asymptotic Rate Bounds and Constructions for the Inclusive Variant of Disjunct Matrices](https://arxiv.org/abs/2601.09362)
*Yuto Mizunuma,Yuichiro Fujiwara*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Disjunct matrices, also known as cover-free families and superimposed codes, are combinatorial arrays widely used in group testing. Among their variants, those that satisfy an additional combinatorial property called inclusiveness form a special class suitable for computationally efficient and highly error-tolerant group testing under the general inhibitor complex model, a broad framework that subsumes practical settings such as DNA screening. Despite this relevance, the asymptotic behavior of the inclusive variant of disjunct matrices has remained largely unexplored. In particular, it was not previously known whether this variant can achieve an asymptotically positive rate, a requirement for scalable group testing designs. In this work, we establish the first nontrivial asymptotic lower bound on the maximum achievable rate of the inclusive variant, which matches the strongest known upper bound up to a logarithmic factor. Our proof is based on the probabilistic method and yields a simple and efficient randomized construction. Furthermore, we derandomize this construction to obtain a deterministic polynomial-time construction. These results clarify the asymptotic potential of robust and scalable group testing under the general inhibitor complex model.

</details>


### [35] [On Decoding First- and Second-Order BiD Codes](https://arxiv.org/abs/2601.09390)
*Devansh Jain,Lakshmi Prasad Natarajan*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: BiD codes, which are a new family of algebraic codes of length $3^m$, achieve the erasure channel capacity under bit-MAP decoding and offer asymptotically larger minimum distance than Reed-Muller (RM) codes. In this paper we propose fast maximum-likelihood (ML) and max-log-MAP decoders for first-order BiD codes. For second-order codes, we identify their minimum-weight parity checks and ascertain a code property known as 'projection' in the RM coding literature. We use these results to design a belief propagation decoder that performs within 1 dB of ML decoder for block lengths 81 and 243.

</details>


### [36] [A Generalized Leakage Interpretation of Alpha-Mutual Information](https://arxiv.org/abs/2601.09406)
*Akira Kamatsuka,Takahiro Yoshida*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper presents a unified interpretation of $α$-mutual information ($α$-MI) in terms of generalized $g$-leakage. Specifically, we present a novel interpretation of $α$-MI within an extended framework for quantitative information flow based on adversarial generalized decision problems. This framework employs the Kolmogorov-Nagumo mean and the $q$-logarithm to characterize adversarial gain. Furthermore, we demonstrate that, within this framework, the parameter $α$ can be interpreted as a measure of the adversary's risk aversion.

</details>


### [37] [Dobrushin Coefficients of Private Mechanisms Beyond Local Differential Privacy](https://arxiv.org/abs/2601.09498)
*Leonhard Grosse,Sara Saeidian,Tobias J. Oechtering,Mikael Skoglund*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate Dobrushin coefficients of discrete Markov kernels that have bounded pointwise maximal leakage (PML) with respect to all distributions with a minimum probability mass bounded away from zero by a constant $c>0$. This definition recovers local differential privacy (LDP) for $c\to 0$. We derive achievable bounds on contraction in terms of a kernels PML guarantees, and provide mechanism constructions that achieve the presented bounds. Further, we extend the results to general $f$-divergences by an application of Binette's inequality. Our analysis yields tighter bounds for mechanisms satisfying LDP and extends beyond the LDP regime to any discrete kernel.

</details>


### [38] [Error Exponents for Randomised List Decoding](https://arxiv.org/abs/2601.09519)
*Henrique K. Miyamoto,Sheng Yang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper studies random-coding error exponents of randomised list decoding, in which the decoder randomly selects $L$ messages with probabilities proportional to the decoding metric of the codewords. The exponents (or bounds) are given for mismatched, and then particularised to matched and universal decoding metrics. Two regimes are studied: for fixed list size, we derive an ensemble-tight random-coding error exponent, and show that, for the matched metric, it does not improve the error exponent of ordinary decoding. For list sizes growing exponentially with the block-length, we provide a non-trivial lower bound to the error exponent that is tight at high rates under the matched metric.

</details>


### [39] [A Finite-Sample Strong Converse for Binary Hypothesis Testing via (Reverse) Rényi Divergence](https://arxiv.org/abs/2601.09550)
*Roberto Bruno,Adrien Vandenbroucque,Amedeo Roberto Esposito*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work investigates binary hypothesis testing between $H_0\sim P_0$ and $H_1\sim P_1$ in the finite-sample regime under asymmetric error constraints. By employing the ``reverse" Rényi divergence, we derive novel non-asymptotic bounds on the Type II error probability which naturally establish a strong converse result. Furthermore, when the Type I error is constrained to decay exponentially with a rate $c$, we show that the Type II error converges to 1 exponentially fast if $c$ exceeds the Kullback-Leibler divergence $D(P_1\|P_0)$, and vanishes exponentially fast if $c$ is smaller. Finally, we present numerical examples demonstrating that the proposed converse bounds strictly improve upon existing finite-sample results in the literature.

</details>


### [40] [On Linear Estimators for some Stable Vectors](https://arxiv.org/abs/2601.09554)
*Rayan Chouity,Charbel Hannoun,Jihad Fahs,Ibrahim Abou-Faycal*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider the estimation problem for jointly stable random variables. Under two specific dependency models: a linear transformation of two independent stable variables and a sub-Gaussian symmetric $α$-stable (S$α$S) vector, we show that the conditional mean estimator is linear in both cases. Moreover, we find dispersion optimal linear estimators. Interestingly, for the sub-Gaussian (S$α$S) vector, both estimators are identical generalizing the well-known Gaussian result of the conditional mean being the best linear minimum-mean square estimator.

</details>


### [41] [The Spectral Representations Of The Simple Hypothesis Testing Problem](https://arxiv.org/abs/2601.09564)
*Barış Nakiboğlu*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The convex conjugate (i.e., the Legendre transform) of Type II error probability (volume) as a function of Type I error probability (volume) is determined for the hypothesis testing problem with randomized detectors. The derivation relies on properties of likelihood ratio quantiles and is general enough to extend to the case of $σ$-finite measures in all non-trivial cases. The convex conjugate of the Type II error volume, called the primitive entropy spectrum, is expressed as an integral of the complementary distribution function of the likelihood ratio using a standard spectral identity. The resulting dual characterization of the Type II error volume leads to state of the art bounds for the case of product measures via Berry--Esseen theorem through a brief analysis relying on properties of the Gaussian Mills ratio, both with and without tilting.

</details>


### [42] [On the Error Probability of RPA Decoding of Reed-Muller Codes over BMS Channels](https://arxiv.org/abs/2601.09581)
*Dorsa Fathollahi,V. Arvind Rameshwar,V. Lalitha*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze the performance of the Recursive Projection-Aggregation (RPA) decoder of Ye and Abbe (2020), for Reed-Muller (RM) codes, over general binary memoryless symmetric (BMS) channels. Our work is a significant generalization of a recent result of Rameshwar and Lalitha (2025) that showed that the RPA decoder provably achieves vanishing error probabilities for "low-rate" RM codes, over the binary symmetric channel (BSC). While a straightforward generalization of the proof strategy in that paper will require additional, restrictive assumptions on the BMS channel, our technique, which employs an equivalence between the RPA projection operation and a part of the "channel combining" phase in polar codes, requires no such assumptions. Interestingly, such an equivalence allows for the use of a generic union bound on the error probability of the first-order RM code (the "base case" of the RPA decoder), under maximum-likelihood decoding, which holds for any BMS channel. We then exploit these observations in the proof strategy outlined in the work of Rameshwar and Lalitha (2025), and argue that, much like in the case of the BSC, one can obtain vanishing error probabilities, in the large $n$ limit (where $n$ is the blocklength), for RM orders that scale roughly as $\log \log n$, for all BMS channels.

</details>


### [43] [Secret sharing with additive access structures from correlated random variables](https://arxiv.org/abs/2601.09640)
*David Miller,Rémi A. Chou*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We generalize secret-sharing models that rely on correlated randomness and public communication, originally designed for a fixed access structure, to support a sequence of dynamic access structures, which we term an Additive Access Structure. Specifically, the access structure is allowed to monotonically grow by having any subset of participants added to it at a given time step, and the dealer only learns of these changes to the access structure on the time step that they occur. For this model, we prove the existence of a secret sharing strategy that achieves the same secret rate at each time step as the best known strategy for the fixed access structure version of this model. We also prove that there exists a strategy that is capacity-achieving at any time step where the access structure is a threshold access structure.

</details>


### [44] [Counting and Entropy Bounds for Structure-Avoiding Spatially-Coupled LDPC Constructions](https://arxiv.org/abs/2601.09674)
*Lei Huang*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Designing large coupling memory quasi-cyclic spatially-coupled LDPC (QC-SC-LDPC) codes with low error floors requires eliminating specific harmful substructures (e.g., short cycles) induced by edge spreading and lifting. Building on our work~\cite{r15} that introduced a Clique Lovász Local Lemma (CLLL)-based design principle and a Moser--Tardos (MT)-type constructive approach, this work quantifies the size and structure of the feasible design space. Using the quantitative CLLL, we derive explicit lower bounds on the number of partition matrices satisfying a given family of structure-avoidance constraints, and further obtain bounds on the number of non-equivalent solutions under row/column permutations. Moreover, via Rényi-entropy bounds for the MT distribution, we provide a computable lower bound on the number of distinct solutions that the MT algorithm can output, giving a concrete diversity guarantee for randomized constructions. Specializations for eliminating 4-cycle candidates yield closed-form bounds as functions of system parameters, offering a principled way to size memory/lifting and to estimate the remaining search space.

</details>


### [45] [Progress on the Courtade-Kumar Conjecture: Optimal High-Noise Entropy Bounds and Generalized Coordinate-wise Mutual Information](https://arxiv.org/abs/2601.09679)
*Adel Javanmard,David P. Woodruff*

Main category: cs.IT

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Courtade-Kumar conjecture posits that dictatorship functions maximize the mutual information between the function's output and a noisy version of its input over the Boolean hypercube. We present two significant advancements related to this conjecture. First, we resolve an open question posed by Courtade and Kumar, proving that for any Boolean function (regardless of bias), the sum of mutual information between the function's output and the individual noisy input coordinates is bounded by $1-H(α)$, where $α$ is the noise parameter of the Binary Symmetric Channel. This generalizes their previous result which was restricted to balanced Boolean functions. Second, we advance the study of the main conjecture in the high noise regime. We establish an optimal error bound of $O(λ^2)$ for the asymptotic entropy expansion, where $λ= (1-2α)^2$, improving upon the previous best-known bounds. This refined analysis leads to a sharp, linear Fourier concentration bound for highly informative functions and significantly extends the range of the noise parameter $λ$ for which the conjecture is proven to hold.

</details>
