<div id=toc></div>

# Table of Contents

- [cs.NI](#cs.NI) [Total: 1]
- [eess.SP](#eess.SP) [Total: 14]
- [cs.IT](#cs.IT) [Total: 5]


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [1] [Joint Optimization of DNN Model Caching and Request Routing in Mobile Edge Computing](https://arxiv.org/abs/2511.03159)
*Shuting Qiu,Fang Dong,Siyu Tan,Ruiting Zhou,Dian Shen,Patrick P. C. Lee,Qilin Fan*

Main category: cs.NI

TL;DR: 本文提出基于动态DNN的联合缓存和路由优化方案CoCaR及其在线变体CoCaR-OL，在移动边缘计算环境下显著提升用户请求推理精度和服务质量。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算(MEC)虽然能够在用户附近缓存DNN模型，提供低延迟服务并改善用户体验，但边缘服务器容量有限，难以缓存所有DNN模型，且模型加载时间对服务质量的影响尚未得到充分研究。传统的缓存方案缺乏灵活性，无法有效平衡模型推理精度和加载延迟。

Method: 本文提出了CoCaR算法，这是一种基于线性规划和随机舍入的离线算法，利用动态DNN优化缓存和路由方案，实现接近最优的性能。此外，还开发了在线变体CoCaR-OL，能够有效适应动态和不可预测的在线请求模式。动态DNN技术将完整的DNN模型拆分为相互关联的子模型，实现更细粒度和灵活的模型缓存与请求路由。

Result: 仿真结果表明，提出的CoCaR算法相比现有基线方法将用户请求的平均推理精度提高了46%。在在线场景中，CoCaR-OL相比竞争性基线在用户服务质量方面实现了不低于32.3%的提升。

Conclusion: 本文通过引入动态DNN的概念，提出了联合模型缓存和请求路由的解决方案。CoCaR和CoCaR-OL算法分别解决了离线和在线场景下的优化问题，显著提升了用户请求的推理精度和服务质量，为MEC环境下的智能服务部署提供了新的技术路径。

Abstract: Mobile edge computing (MEC) can pre-cache deep neural networks (DNNs) near
end-users, providing low-latency services and improving users' quality of
experience (QoE). However, caching all DNN models at edge servers with limited
capacity is difficult, and the impact of model loading time on QoE remains
underexplored. Hence, we introduce dynamic DNNs in edge scenarios,
disassembling a complete DNN model into interrelated submodels for more
fine-grained and flexible model caching and request routing solutions. This
raises the pressing issue of jointly deciding request routing and submodel
caching for dynamic DNNs to balance model inference precision and loading
latency for QoE optimization. In this paper, we study the joint dynamic model
caching and request routing problem in MEC networks, aiming to maximize user
request inference precision under constraints of server resources, latency, and
model loading time. To tackle this problem, we propose CoCaR, an offline
algorithm based on linear programming and random rounding that leverages
dynamic DNNs to optimize caching and routing schemes, achieving near-optimal
performance. Furthermore, we develop an online variant of CoCaR, named
CoCaR-OL, enabling effective adaptation to dynamic and unpredictable online
request patterns. The simulation results demonstrate that the proposed CoCaR
improves the average inference precision of user requests by 46\% compared to
state-of-the-art baselines. In addition, in online scenarios, CoCaR-OL achieves
an improvement of no less than 32.3\% in user QoE over competitive baselines.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [2] [AI-Enhanced Wi-Fi Sensing Through Single Transceiver Pair](https://arxiv.org/abs/2511.02845)
*Yuxuan Liu,Chiya Zhang,Yifeng Yuan,Chunlong He,Weizheng Zhang,Gaojie Chen*

Main category: eess.SP

TL;DR: 本研究揭示了AI在硬件受限的Wi-Fi感知系统中超越传统分辨率限制的理论基础，发现性能提升主要来自先验信息和时间相关性，并通过单收发器系统的实验验证了这一发现。


<details>
  <summary>Details</summary>
Motivation: 下一代Wi-Fi技术的发展严重依赖感知能力以实现复杂应用，但当前Wi-Fi感知系统在大规模部署中面临挑战：需要在保持最小带宽消耗和最少天线数量要求的同时实现高精度感知。尽管AI驱动的感知技术已展现出超越传统雷达理论分辨率限制的能力，但这种现象的理论基础尚未在现有研究中得到深入探讨。

Method: 研究人员开发了一个基于AI的Wi-Fi感知系统，仅使用单个收发器对。通过设计聚焦于人体姿态估计和室内定位的实验来验证理论主张。实验系统在硬件受限条件下运行，专门测试AI在感知任务中的表现，并分析先验信息和时间相关性对性能提升的贡献。

Result: 实验结果证实了时间相关性和先验信息对AI在Wi-Fi感知系统中性能提升的贡献。研究发现，在硬件受限条件下，AI带来的性能增益主要来源于两个方面：先验信息使AI能够基于模糊输入生成合理细节，时间相关性帮助降低感知误差的上限。人体姿态估计和室内定位实验均验证了这一理论发现。

Conclusion: 本研究为AI在硬件受限的Wi-Fi感知系统中超越传统雷达分辨率限制的现象提供了理论解释。通过实验验证了AI性能提升主要来源于先验信息和时间相关性两个关键因素：先验信息使AI能够基于模糊输入生成合理的细节，而时间相关性则有助于降低感知误差的上限。这一理论发现为下一代Wi-Fi感知技术的优化设计提供了重要指导。

Abstract: The advancement of next-generation Wi-Fi technology heavily relies on sensing
capabilities, which play a pivotal role in enabling sophisticated applications.
In response to the growing demand for large-scale deployments, contemporary
Wi-Fi sensing systems strive to achieve high-precision perception while
maintaining minimal bandwidth consumption and antenna count requirements.
Remarkably, various AI-driven perception technologies have demonstrated the
ability to surpass the traditional resolution limitations imposed by radar
theory. However, the theoretical underpinnings of this phenomenon have not been
thoroughly investigated in existing research. In this study, we found that
under hardware-constrained conditions, the performance gains brought by AI to
Wi-Fi sensing systems primarily originate from two aspects: prior information
and temporal correlation. Prior information enables the AI to generate
plausible details based on vague input, while temporal correlation helps reduce
the upper bound of sensing error. We developed an AI-based Wi-Fi sensing system
using a single transceiver pair and designed experiments focusing on human pose
estimation and indoor localization to validate the theoretical claims. The
results confirm the performance gains contributed by temporal correlation and
prior information.

</details>


### [3] [EEGReXferNet: A Lightweight Gen-AI Framework for EEG Subspace Reconstruction via Cross-Subject Transfer Learning and Channel-Aware Embedding](https://arxiv.org/abs/2511.02848)
*Shantanu Sarkar,Piotr Nabrzyski,Saurabh Prasad,Jose Luis Contreras-Vidal*

Main category: eess.SP

TL;DR: EEGReXferNet是一个轻量级生成式AI框架，通过跨主体迁移学习进行EEG子空间重建，解决了传统方法计算复杂性和缺乏多域敏感性的问题，在保持实时性能的同时显著提高了EEG信号重建质量。


<details>
  <summary>Details</summary>
Motivation: 脑电图(EEG)作为广泛使用的非侵入性脑活动监测技术，由于各种伪影导致的低信噪比问题严重影响了其实用性。传统伪影去除方法需要手动干预或在滤波/重建过程中存在抑制关键神经特征的风险。现有的生成式模型(如VAEs和GANs)缺乏集成的时域-频域-空域敏感性，且计算强度大，限制了其在脑机接口等实时应用中的适用性。

Method: EEGReXferNet是一个基于Keras TensorFlow 2.15.1开发的轻量级生成式AI框架。该框架采用模块化架构，利用相邻通道的体积传导、带特定卷积编码和滑动窗口的动态潜在特征提取。通过集成基于参考的缩放，确保连续窗口间的连续性，并通过跨主体迁移学习实现有效的泛化能力。

Result: EEGReXferNet在性能上显著提升：平均功率谱密度相关系数≥0.95，平均频谱图RV系数≥0.85；模型总权重减少约45%以缓解过拟合；保持计算效率，适用于实时EEG预处理；在时域、频域和空域分辨率方面均有改善，并有效实现跨主体泛化。

Conclusion: EEGReXferNet为神经生理学和脑机接口应用提供了鲁棒的实时EEG预处理能力，通过轻量化设计和跨主体迁移学习，有效解决了传统方法的局限性，为实际应用中的EEG信号重建提供了实用解决方案。

Abstract: Electroencephalography (EEG) is a widely used non-invasive technique for
monitoring brain activity, but low signal-to-noise ratios (SNR) due to various
artifacts often compromise its utility. Conventional artifact removal methods
require manual intervention or risk suppressing critical neural features during
filtering/reconstruction. Recent advances in generative models, including
Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs),
have shown promise for EEG reconstruction; however, these approaches often lack
integrated temporal-spectral-spatial sensitivity and are computationally
intensive, limiting their suitability for real-time applications like
brain-computer interfaces (BCIs). To overcome these challenges, we introduce
EEGReXferNet, a lightweight Gen-AI framework for EEG subspace reconstruction
via cross-subject transfer learning - developed using Keras TensorFlow
(v2.15.1). EEGReXferNet employs a modular architecture that leverages volume
conduction across neighboring channels, band-specific convolution encoding, and
dynamic latent feature extraction through sliding windows. By integrating
reference-based scaling, the framework ensures continuity across successive
windows and generalizes effectively across subjects. This design improves
spatial-temporal-spectral resolution (mean PSD correlation >= 0.95; mean
spectrogram RV-Coefficient >= 0.85), reduces total weights by ~45% to mitigate
overfitting, and maintains computational efficiency for robust, real-time EEG
preprocessing in neurophysiological and BCI applications.

</details>


### [4] [Benchmarking ResNet for Short-Term Hypoglycemia Classification with DiaData](https://arxiv.org/abs/2511.02849)
*Beyza Cinar,Maria Maleshkova*

Main category: eess.SP

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Individualized therapy is driven forward by medical data analysis, which
provides insight into the patient's context. In particular, for Type 1 Diabetes
(T1D), which is an autoimmune disease, relationships between demographics,
sensor data, and context can be analyzed. However, outliers, noisy data, and
small data volumes cannot provide a reliable analysis. Hence, the research
domain requires large volumes of high-quality data. Moreover, missing values
can lead to information loss. To address this limitation, this study improves
the data quality of DiaData, an integration of 15 separate datasets containing
glucose values from 2510 subjects with T1D. Notably, we make the following
contributions: 1) Outliers are identified with the interquartile range (IQR)
approach and treated by replacing them with missing values. 2) Small gaps
($\le$ 25 min) are imputed with linear interpolation and larger gaps ($\ge$ 30
and $<$ 120 min) with Stineman interpolation. Based on a visual comparison,
Stineman interpolation provides more realistic glucose estimates than linear
interpolation for larger gaps. 3) After data cleaning, the correlation between
glucose and heart rate is analyzed, yielding a moderate relation between 15 and
60 minutes before hypoglycemia ($\le$ 70 mg/dL). 4) Finally, a benchmark for
hypoglycemia classification is provided with a state-of-the-art ResNet model.
The model is trained with the Maindatabase and Subdatabase II of DiaData to
classify hypoglycemia onset up to 2 hours in advance. Training with more data
improves performance by 7% while using quality-refined data yields a 2-3% gain
compared to raw data.

</details>


### [5] [Approaching Low-Cost Cardiac Intelligence with Semi-Supervised Knowledge Distillation](https://arxiv.org/abs/2511.02851)
*Rushuang Zhou,Yuan-Ting Zhang,M. Jamal Deen,Yining Dong*

Main category: eess.SP

TL;DR: LiteHeart通过半监督知识蒸馏框架显著缩小了低成本与高成本心脏智能系统的诊断性能差距，使日常心脏监测更加普及。


<details>
  <summary>Details</summary>
Motivation: 部署先进心脏人工智能进行日常心脏监测受到其对大量医疗数据和计算资源依赖的阻碍。低成本心脏智能使用可穿戴设备数据提供有前景的替代方案，但与高成本心脏智能相比存在显著的诊断性能差距。

Method: 提出了LiteHeart半监督知识蒸馏框架，包含区域感知蒸馏模块（模拟心脏病学家关注诊断相关ECG区域的方式）和跨层互信息模块（对齐LCCI和HCCI系统的决策过程），并采用半监督训练策略提高模型在有限监督下的鲁棒性。

Result: 在涵盖38种心血管疾病的五个数据集上评估，LiteHeart大幅减少了LCCI和HCCI之间的性能差距，在宏F1分数上比现有方法提高4.27%至7.10%。

Conclusion: LiteHeart显著增强了低成本心脏智能系统的诊断能力，为使用可穿戴技术实现可扩展、经济实惠且准确的日常心脏医疗保健铺平了道路。

Abstract: Deploying advanced cardiac artificial intelligence for daily cardiac
monitoring is hindered by its reliance on extensive medical data and high
computational resources. Low-cost cardiac intelligence (LCCI) offers a
promising alternative by using wearable device data, such as 1-lead
electrocardiogram (ECG), but it suffers from a significant diagnostic
performance gap compared to high-cost cardiac intelligence (HCCI). To bridge
this gap, we propose LiteHeart, a semi-supervised knowledge distillation
framework. LiteHeart introduces a region-aware distillation module to mimic how
cardiologists focus on diagnostically relevant ECG regions and a cross-layer
mutual information module to align the decision processes of LCCI and HCCI
systems. Using a semi-supervised training strategy, LiteHeart further improves
model robustness under limited supervision. Evaluated on five datasets covering
over 38 cardiovascular diseases, LiteHeart substantially reduces the
performance gap between LCCI and HCCI, outperforming existing methods by 4.27%
to 7.10% in macro F1 score. These results demonstrate that LiteHeart
significantly enhances the diagnostic capabilities of low-cost cardiac
intelligence systems, paving the way for scalable, affordable, and accurate
daily cardiac healthcare using wearable technologies.

</details>


### [6] [Real-Time Interactive Hybrid Ocean: Spectrum-Consistent Wave Particle-FFT Coupling](https://arxiv.org/abs/2511.02852)
*Shengze Xue,Yu Ren,Jiacheng Hong,Run Ni,Shuangjiu Xiao,Deli Dong*

Main category: eess.SP

TL;DR: 实时混合海洋仿真：结合FFT全局背景与局部波粒子补丁，实现高效逼真的交互式水面渲染


<details>
  <summary>Details</summary>
Motivation: 现有的FFT谱海洋虽然高效且能实现大尺度真实感，但假设全局平稳性和空间均匀性，难以表示非均匀海面和近场交互（如船舶和浮体）；而波粒子能捕捉局部尾迹和涟漪，但在大规模维护成本高且难以匹配全局谱统计。需要一种能兼顾两者的方法。

Method: 提出了一种实时交互式混合海洋系统：全局FFT背景与围绕交互物体的局部波粒子(WP)区域耦合，在统一的谱参数和色散关系驱动下工作。在补丁边界处，粒子根据与FFT相同的方向谱注入，确保局部频率方向分布与背景对齐并匹配能量密度。创新性地设计了基于频率桶的粒子采样和GPU并行合成方案。

Result: 成功实现了能够在实时交互性能下同时提供大尺度谱真实感和细粒度局部细节的海洋仿真系统，通过统一的谱参数和频率桶实现方案，保持了谱能量一致性，支持局部尾迹和涟漪效果而不干扰远场。

Conclusion: 该论文提出了一种统一的混合海洋框架，通过结合FFT谱背景和局部波粒子区域，在实时交互性能下同时实现了大尺度谱真实感和细粒度局部交互效果，为海洋仿真提供了一种高效且逼真的解决方案。

Abstract: Fast Fourier Transform-based (FFT) spectral oceans are widely adopted for
their efficiency and large-scale realism, but they assume global stationarity
and spatial homogeneity, making it difficult to represent non-uniform seas and
near-field interactions (e.g., ships and floaters). In contrast, wave particles
capture local wakes and ripples, yet are costly to maintain at scale and hard
to match global spectral statistics.We present a real-time interactive hybrid
ocean: a global FFT background coupled with local wave-particle (WP) patch
regions around interactive objects, jointly driven under a unified set of
spectral parameters and dispersion. At patch boundaries, particles are injected
according to the same directional spectrum as the FFT, aligning the local
frequency-direction distribution with the background and matching energy
density, without disturbing the far field.Our approach introduces two main
innovations: (1) Hybrid ocean representation. We couple a global FFT background
with local WP patches under a unified spectrum, achieving large-scale spectral
consistency while supporting localized wakes and ripples.(2) Frequency-bucketed
implementation. We design a particle sampling and GPU-parallel synthesis scheme
based on frequency buckets, which preserves spectral energy consistency and
sustains real-time interactive performance.Together, these innovations enable a
unified framework that delivers both large-scale spectral realism and
fine-grained interactivity in real time.

</details>


### [7] [Consciousness-ECG Transformer for Conscious State Estimation System with Real-Time Monitoring](https://arxiv.org/abs/2511.02853)
*Young-Seok Kweon,Gi-Hwan Shin,Ji-Yong Kim,Bokyeong Ryu,Seong-Whan Lee*

Main category: eess.SP

TL;DR: 本研究提出基于ECG的consciousness-ECG transformer系统，通过分析心率变异性特征实现意识状态监测，在睡眠分期和麻醉监测任务中分别达到87.7%和88.0%的准确率，为传统EEG方法提供了实用的替代方案。


<details>
  <summary>Details</summary>
Motivation: 意识状态估计在睡眠分期和麻醉管理等医疗环境中对确保患者安全和优化健康结果至关重要。传统脑电图(EEG)方法面临对噪声高度敏感和需要受控环境的挑战，迫切需要寻找更可靠、更实用的替代方案。

Method: 提出了consciousness-ECG transformer，利用心电图(ECG)信号进行非侵入式意识状态估计。采用带有解耦查询注意力的transformer架构来有效捕获区分意识和无意识状态的心率变异性特征，并实现了实时监测系统。

Result: 在睡眠分期数据集上达到0.877准确率和0.786 AUC值，在麻醉水平监测数据集上达到0.880准确率和0.895 AUC值。实验结果表明该模型显著优于基线模型，证明了ECG信号在意识状态估计中的有效性。

Conclusion: 本研究提出的基于ECG的意识状态监测系统为EEG方法提供了实用的、稳健的替代方案，特别适合动态临床环境。ECG基础意识监测具有增强患者安全和推进意识状态理解的巨大潜力。

Abstract: Conscious state estimation is important in various medical settings,
including sleep staging and anesthesia management, to ensure patient safety and
optimize health outcomes. Traditional methods predominantly utilize
electroencephalography (EEG), which faces challenges such as high sensitivity
to noise and the requirement for controlled environments. In this study, we
propose the consciousness-ECG transformer that leverages electrocardiography
(ECG) signals for non-invasive and reliable conscious state estimation. Our
approach employs a transformer with decoupled query attention to effectively
capture heart rate variability features that distinguish between conscious and
unconscious states. We implemented the conscious state estimation system with
real-time monitoring and validated our system on datasets involving sleep
staging and anesthesia level monitoring during surgeries. Experimental results
demonstrate that our model outperforms baseline models, achieving accuracies of
0.877 on sleep staging and 0.880 on anesthesia level monitoring. Moreover, our
model achieves the highest area under curve values of 0.786 and 0.895 on sleep
staging and anesthesia level monitoring, respectively. The proposed system
offers a practical and robust alternative to EEG-based methods, particularly
suited for dynamic clinical environments. Our results highlight the potential
of ECG-based consciousness monitoring to enhance patient safety and advance our
understanding of conscious states.

</details>


### [8] [NEF-NET+: Adapting Electrocardio panorama in the wild](https://arxiv.org/abs/2511.02880)
*Zehui Zhan,Yaojun Hu,Jiajing Zhan,Wanchen Lian,Wanqing Wu,Jintai Chen*

Main category: eess.SP

TL;DR: NEF-NET+是增强的全景ECG合成框架，解决了原Nef-Net的现实应用限制，支持任意长度信号、跨设备泛化和电极偏差补偿，PSNR提升6dB。


<details>
  <summary>Details</summary>
Motivation: 传统多导联ECG系统只能从固定视角捕捉心脏信号，某些心脏疾病需要非标准视角才能发现诊断关键模式。现有Nef-Net方法存在理想化假设，面临长时间ECG建模、设备特异性信号伪影和电极放置校准不优化等现实挑战。

Method: 提出NEF-NET+增强框架，采用新的直接视图变换模型架构，包含离线预训练、设备校准调优和患者特定即时校准三个步骤，实现任意长度信号合成、跨设备泛化和电极放置偏差补偿。

Result: 构建了包含5367个记录和48个视角的新基准测试Panobench，实验结果显示NEF-NET+相比Nef-Net在现实环境中PSNR提升约6 dB，在全景ECG合成任务上表现优异。

Conclusion: NEF-NET+相比原始Nef-Net在现实环境中取得了显著改进，PSNR提升约6 dB，能够有效支持任意长度信号合成、跨设备泛化和电极放置偏差补偿，为全景ECG合成提供了更实用的解决方案。

Abstract: Conventional multi-lead electrocardiogram (ECG) systems capture cardiac
signals from a fixed set of anatomical viewpoints defined by lead placement.
However, certain cardiac conditions (e.g., Brugada syndrome) require
additional, non-standard viewpoints to reveal diagnostically critical patterns
that may be absent in standard leads. To systematically overcome this
limitation, Nef-Net was recently introduced to reconstruct a continuous
electrocardiac field, enabling virtual observation of ECG signals from
arbitrary views (termed Electrocardio Panorama). Despite its promise, Nef-Net
operates under idealized assumptions and faces in-the-wild challenges, such as
long-duration ECG modeling, robustness to device-specific signal artifacts, and
suboptimal lead placement calibration. This paper presents NEF-NET+, an
enhanced framework for realistic panoramic ECG synthesis that supports
arbitrary-length signal synthesis from any desired view, generalizes across ECG
devices, and com- pensates for operator-induced deviations in electrode
placement. These capabilities are enabled by a newly designed model
architecture that performs direct view transformation, incorporating a workflow
comprising offline pretraining, device calibration tuning steps as well as an
on-the-fly calibration step for patient-specific adaptation. To rigorously
evaluate panoramic ECG synthesis, we construct a new Electrocardio Panorama
benchmark, called Panobench, comprising 5367 recordings with 48-view per
subject, capturing the full spatial variability of cardiac electrical activity.
Experimental results show that NEF-NET+ delivers substantial improvements over
Nef-Net, yielding an increase of around 6 dB in PSNR in real-world setting. The
code and Panobench will be released in a subsequent publication.

</details>


### [9] [Analysis and Algorithm for Multi IRS Collaborative Localization via Hybrid Time Angle Estimation](https://arxiv.org/abs/2511.03133)
*Ziheng Zhang,Wen Chen,Qingqing Wu,Haoran Qin,Zhendong Li,Qiong Wu*

Main category: eess.SP

TL;DR: 本文提出了一种多智能反射面协同混合定位系统，通过联合时延和角度估计实现高精度目标定位，设计了高效的估计算法，在低信噪比条件下仍保持优异性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统定位系统在复杂环境中的精度限制问题，利用智能反射面的协同部署来增强定位性能，特别是在低信噪比条件下实现精确的目标定位。

Method: 提出多IRS协同混合定位架构；推导级联时延、到达角和出发角估计的Fisher信息矩阵和CRB；设计基于原子范数最小化和ADMM的联合角度估计算法；开发结合加权最小二乘、总体最小二乘和二次校正的三阶段定位算法。

Result: 数值仿真结果表明，所提系统的协同机制、混合定位和分布式部署带来显著效益，估计算法准确性高，尤其在低信噪比条件下表现优异，能够接近CRB的理论界限。

Conclusion: 该多IRS协同混合定位系统通过理论分析和算法设计，在低信噪比条件下仍能保持高精度定位，为未来无线定位系统提供了有价值的解决方案。系统架构和算法设计具有实际应用潜力。

Abstract: This paper proposes a novel multiple intelligent reflecting surfaces (IRSs)
collaborative hybrid localization system, which involves deploying multiple
IRSs near the target area and achieving target localization through joint time
delay and angle estimation. Specifically, echo signals from all reflective
elements are received by each sensor and jointly processed to estimate the time
delay and angle parameters. Based on the above model, we derive the Fisher
Information Matrix (FIM) for cascaded delay, Angle of Arrival (AOA), and Angle
of Departure (AOD) estimation in semi passive passive models, along with the
corresponding Cramer Rao Bound (CRB). To achieve precise estimation close to
the CRB, we design efficient algorithms for angle and location estimation. For
angle estimation, reflective signals are categorized into three cases based on
their rank, with different signal preprocessing. By constructing an atomic norm
set and minimizing the atomic norm, the joint angle estimation problem is
transformed into a convex optimization problem, and low-complexity estimation
of multiple AOA and AOD pairs is achieved using the Alternating Direction
Method of Multipliers (ADMM). For location estimation, we propose a three-stage
localization algorithm that combines weighted least squares, total least
squares, and quadratic correction to handle errors in the coefficient matrix
and observation vector, thus improving accuracy. Numerical simulations validate
the superiority of the proposed system, demonstrating that the system's
collaboration, hybrid localization, and distributed deployment provide
substantial benefits, as well as the accuracy of the proposed estimation
algorithms, particularly in low signal to noise ratio (SNR) condition.

</details>


### [10] [Multimodal-Wireless: A Large-Scale Dataset for Sensing and Communication](https://arxiv.org/abs/2511.03220)
*Tianhao Mao,Le Liang,Jie Yang,Hao Ye,Shi Jin,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: 本文介绍了Multimodal-Wireless，一个基于CARLA和Sionna框架构建的开源多模态感知数据集，包含16万帧跨多种场景和天气条件的多传感器数据，支持无线通信与协同感知研究。


<details>
  <summary>Details</summary>
Motivation: 为解决无线通信研究中缺乏综合多模态感知数据集的问题，满足通信与协同感知融合研究对大规模、多样化数据的需求。随着多模态学习和人工智能在通信领域的快速发展，研究者需要包含多种传感器数据的开放数据集来支持算法开发和验证。

Method: 研究方法基于集成CARLA模拟器和Sionna框架构建了一个可定制的数据管道。通过该管道在四个虚拟城镇中收集数据，涵盖十六种通信场景和三种天气条件。数据集包含约160,000帧，融合了多种感知模态：通信信道、激光雷达、RGB和深度摄像头、惯性测量单元以及雷达数据。

Result: 成功构建了Multimodal-Wireless数据集，包含约160,000帧数据，覆盖四个虚拟城镇、十六种通信场景和三种天气条件。该数据集集成了通信信道、激光雷达、RGB/深度摄像头、IMU和雷达等多种感知模态，为研究人员提供了丰富的多模态数据资源，并展示了在波束预测等应用中的潜力。

Conclusion: 该研究成功创建了一个开放源代码的多模态感知数据集，为无线通信研究社区提供了宝贵的资源。通过集成CARLA模拟器和Sionna框架构建的数据管道，研究人员能够高效地生成大规模、多样化的多模态数据，促进通信与协同感知领域的发展。该数据集的开放性和可定制性将推动相关研究的创新。

Abstract: This paper presents Multimodal-Wireless, an open-source multimodal sensing
dataset designed for wireless communication research. The dataset is generated
through an integrated and customizable data pipeline built upon the CARLA
simulator and Sionna framework. It contains approximately 160,000 frames
collected across four virtual towns, sixteen communication scenarios, and three
weather conditions, encompassing multiple sensing modalities--communication
channel, light detection and ranging, RGB and depth cameras, inertial
measurement unit, and radar. This paper provides a comprehensive overview of
the dataset, outlining its key features, overall framework, and technical
implementation details. In addition, it explores potential research
applications concerning communication and collaborative perception, exemplified
by beam prediction using a multimodal large language model. The dataset is open
in https://le-liang.github.io/mmw/.

</details>


### [11] [Decentralized Federated Learning with Distributed Aggregation Weight Optimization](https://arxiv.org/abs/2511.03284)
*Zhiyuan Zhai,Xiaojun Yuan,Xin Wang,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: 本文提出了一种面向去中心化联邦学习的分布式聚合权重优化算法，实现了真正分布式的DFL系统，无需中央实体协调即可获得最优学习性能


<details>
  <summary>Details</summary>
Motivation: 传统DFL依赖中央实体设计聚合权重，违背了去中心化本质，需要开发真正符合DFL去中心化特性的分布式权重优化方法

Method: 开发了分布式聚合权重优化算法，通过定量分析聚合权重对收敛性的影响，将学习性能优化问题转化为特征值优化问题，并采用基于次梯度的分布式算法求解

Result: 边缘设备仅需本地信息和D2D通信即可获得最优聚合权重，实现了优化、通信和学习过程的完全分布式，显著提升了DFL系统的学习效率

Conclusion: 本文提出的分布式聚合权重优化算法成功实现了真正分布式的DFL系统，优化、通信和学习过程均可完全分布式进行，数值结果验证了其在实际部署中的优越性

Abstract: Decentralized federated learning (DFL) is an emerging paradigm to enable edge
devices collaboratively training a learning model using a device-to-device
(D2D) communication manner without the coordination of a parameter server (PS).
Aggregation weights, also known as mixing weights, are crucial in DFL process,
and impact the learning efficiency and accuracy. Conventional design relies on
a so-called central entity to collect all local information and conduct system
optimization to obtain appropriate weights. In this paper, we develop a
distributed aggregation weight optimization algorithm to align with the
decentralized nature of DFL. We analyze convergence by quantitatively capturing
the impact of the aggregation weights over decentralized communication
networks. Based on the analysis, we then formulate a learning performance
optimization problem by designing the aggregation weights to minimize the
derived convergence bound. The optimization problem is further transformed as
an eigenvalue optimization problem and solved by our proposed subgradient-based
algorithm in a distributed fashion. In our algorithm, edge devices only need
local information to obtain the optimal aggregation weights through local (D2D)
communications, just like the learning itself. Therefore, the optimization,
communication, and learning process can be all conducted in a distributed
fashion, which leads to a genuinely distributed DFL system. Numerical results
demonstrate the superiority of the proposed algorithm in practical DFL
deployment.

</details>


### [12] [UAV SAR Imaging with 5G NR OFDM Signals in NLOS Environments](https://arxiv.org/abs/2511.03292)
*Qiuyuan Yang,Cunhua Pan,Ruidong Li,Zhenkun Zhang,Hong Ren,Changhong Wang,Jiangzhou Wang*

Main category: eess.SP

TL;DR: 本文提出基于OFDM信号的合作式ISAC框架用于SAR成像，通过两阶段CS-SAGE方案解决NLOS环境下的成像退化问题，实现高精度散射体定位。


<details>
  <summary>Details</summary>
Motivation: 感知与通信一体化(ISAC)对未来无线系统具有重要潜力，能实现高效频谱利用和新颖应用场景，但在非视距(NLOS)环境下面临严重成像退化挑战，需要开发弱信号检测和虚假点消除的有效方法。

Method: 提出合作式ISAC框架，利用OFDM通信信号实现SAR成像；开发两阶段CS-SAGE方案：第一阶段采用正交匹配追踪(OMP)进行粗估计，识别主要散射体的大致位置；第二阶段采用SAGE算法进行精细估计，准确提取散射体参数；在QuaDRiGa信道模型下进行验证。

Result: 仿真结果验证了所提合作式ISAC框架的有效性，该框架能够成功检测弱信号并消除虚假点，在NLOS环境下实现高精度散射体定位，为实际系统设计提供了宝贵见解。

Conclusion: 本文提出的合作式ISAC框架成功解决了NLOS环境下的成像退化问题，通过两阶段CS-SAGE方案实现了高精度散射体定位，为实际系统设计提供了有价值的见解。

Abstract: The integration of sensing and communication (ISAC) has significant potential
for future wireless systems, enabling efficient spectrum utilization and novel
application scenarios. In this paper, we propose a cooperative ISAC framework
for synthetic aperture radar (SAR) imaging by leveraging orthogonal frequency
division multiplexing (OFDM) communication signals. We address the challenge of
severe imaging degradation in non-line-of-sight (NLOS) environments under the
QUAsi Deterministic RadIo channel GenerAtor (QuaDRiGa). To detect weak signals
and eliminate false points, we develop a two-stage compressed sensing-space
alternating generalized expectation maximization (CS-SAGE) scheme for
high-precision scatterer localization. In stage I, orthogonal matching pursuit
(OMP) is employed for coarse estimation to identify the approximate locations
of dominant scatterers. Then, the SAGE algorithm in stage II performs fine
estimation to accurately extract scatterer parameters. Simulation results
validate the effectiveness of the proposed cooperative ISAC framework, and
provide valuable insights for practical system design.

</details>


### [13] [Performance Analysis of Wireless-Powered Pinching Antenna Systems](https://arxiv.org/abs/2511.03401)
*Kunrui Cao,Jingyu Chen,Panagiotis D. Diamantoulakis,Lei Zhou,Xingwang Li,Yuanwei Liu,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 本文研究无线供电夹持天线系统的可靠性，推导了中断概率和遍历速率闭式表达式，发现系统存在最优部署参数，且分离式PS-AP部署优于集成方案。


<details>
  <summary>Details</summary>
Motivation: 夹持天线系统通过灵活调整天线位置建立强视距链路，可显著减少自由空间路径损失。本文旨在探索将无线供电技术与夹持天线系统结合的潜在优势，为无线供电通信系统性能提升提供新思路。

Method: 通过理论分析推导了实际有损波导和理想无损耗波导情况下中断概率和遍历速率的闭式表达式，并采用数学优化方法分析了波导和用户的最优部署策略。

Result: 吸收系数增加和用户区域维度扩大分别导致波导内和自由空间传播损失增加，从而提高中断概率并降低遍历速率。在高吸收系数和长波导条件下，中断概率劣于传统WPC系统，但遍历率优于传统系统。系统存在最优时间分配因子和PS-AP距离配置。

Conclusion: 无线供电夹持天线系统在特定条件下（高吸收系数和长波导）具有性能优势，系统存在最优的时间分配因子和PS-AP距离配置。将功率基站和接入点分离部署的方案优于混合接入点集成方案，为实际系统部署提供了重要指导。

Abstract: Pinching antenna system (PAS) serves as a groundbreaking paradigm that
enhances wireless communications by flexibly adjusting the position of pinching
antenna (PA) and establishing a strong line-of-sight (LoS) link, thereby
reducing the free-space path loss. This paper introduces the concept of
wireless-powered PAS, and investigates the reliability of wireless-powered PAS
to explore the advantages of PA in improving the performance of
wireless-powered communication (WPC) system. In addition, we derive the
closed-form expressions of outage probability and ergodic rate for the
practical lossy waveguide case and ideal lossless waveguide case, respectively,
and analyze the optimal deployment of waveguides and user to provide valuable
insights for guiding their deployments. The results show that an increase in
the absorption coefficient and in the dimensions of the user area leads to
higher in-waveguide and free-space propagation losses, respectively, which in
turn increase the outage probability and reduce the ergodic rate of the
wireless-powered PAS. However, the performance of wireless-powered PAS is
severely affected by the absorption coefficient and the waveguide length, e.g.,
under conditions of high absorption coefficient and long waveguide, the outage
probability of wireless-powered PAS is even worse than that of traditional WPC
system. While the ergodic rate of wireless-powered PAS is better than that of
traditional WPC system under conditions of high absorption coefficient and long
waveguide. Interestingly, the wireless-powered PAS has the optimal time
allocation factor and optimal distance between power station (PS) and access
point (AP) to minimize the outage probability or maximize the ergodic rate.
Moreover, the system performance of PS and AP separated at the optimal distance
between PS and AP is superior to that of PS and AP integrated into a hybrid
access point.

</details>


### [14] [A Modified Pulse and Design Framework to Halve the Complexity of OFDM Spectral Shaping Techniques](https://arxiv.org/abs/2511.03465)
*Javier Giménez,José A. Cortés,Francisco Javier Cañete,Eduardo Martos-Naya,Luis Díez*

Main category: eess.SP

TL;DR: 一种改进的OFDM波形设计，可将频谱整形技术的优化系数和计算量减少50%，大幅降低实现成本。


<details>
  <summary>Details</summary>
Motivation: OFDM调制技术虽然应用广泛但存在高带外发射问题，现有的频谱整形策略如预编码、主动干扰消除等方法虽然有效，但其优化程序和实时实现成本过高，需要寻找更高效的解决方案。

Method: 提出对传统OFDM波形的修改设计，建立新的技术框架来降低频谱整形的实现成本，具体通过减少优化系数数量和乘法运算次数来提升效率。

Result: 该方法能够将优化过程中涉及的系数数量和实现中的乘积运算数量减少最多50%，显著降低了实现成本和计算复杂度。

Conclusion: 本文提出了一种改进的OFDM波形设计，通过优化结构减少了频谱整形技术的实现复杂度和成本，为未来相关研究提供了低成本的技术框架。

Abstract: Orthogonal frequency division multiplexing (OFDM) is a widespread modulation
but suffers from high out-of-band emissions (OOBE). Spectral shaping strategies
such as precoding, active interference cancellation (AIC) and time-domain
methods are effective at reducing the OOBE but entail optimization procedures
and real-time implementation costs which might be considerable. This letter
proposes a modification of the conventional OFDM waveform aimed at reducing the
cost associated to many of the state-of-theart spectral shaping techniques and
sets a framework for future works that want to benefit from the same reduction.
This approach may reduce both the number of coefficients involved in the
optimization and the number of products of its implementation by up to 50%.

</details>


### [15] [A Novel Multi-Reference-Point Modeling Framework for Monostatic Background Channel: Toward 3GPP ISAC Standardization](https://arxiv.org/abs/2511.03487)
*Yameng Liu,Jianhua Zhang,Yuxiang Zhang,Zhiqiang Yuan,Chuangxin Jiang,Junchen Liu,Wei Hong,Yingyang Li,Yan Li,Guangyi Liu*

Main category: eess.SP

TL;DR: 本文通过28GHz室内测量和建模，提出了一种基于多参考点的随机模型来解决ISAC单站背景信道建模挑战，并通过遗传算法优化和实验验证证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: ISAC被ITU和3GPP确定为6G关键应用，需要现实的、标准兼容的信道模型进行系统设计。3GPP将ISAC信道定义为目标信道和背景信道的组合。虽然背景信道不携带直接目标信息，但其在复杂环境中对评估感知性能的准确建模至关重要。现有通信标准主要针对分离的收发信机，但ISAC单站模式(收发机同址)的背景信道建模仍是紧迫挑战。

Method: 在室内28GHz频段进行ISAC单站背景信道测量，提取真实信道参数；提出随机模型将单站背景信道建模为单站收发机与多个通信接收机类参考点(RPs)之间子信道的叠加；引入3GPP扩展实现框架；采用遗传算法方法提取最优多RPs数量和位置；通过比较测量和仿真信道参数验证优化方法和建模框架。

Result: 测量结果显示出显著的单跳传播和离散多径分布特征；提出的随机模型有效捕获了单站背景信道特性；遗传算法优化方法成功确定了最优多RPs配置；通过测量与仿真信道参数的对比验证了模型的有效性；该研究填补了ISAC信道建模的关键空白，支持6G标准化进程。

Conclusion: 本文通过在28GHz频段进行室内ISAC单站背景信道测量，提出了一种新颖的随机模型，将背景信道建模为单站收发机与多个类似通信接收机参考点之间子信道的叠加。该模型与3GPP标准兼容，并通过遗传算法优化多参考点的数量和位置。实验结果验证了模型的有效性，成功解决了ISAC信道建模中的关键空白，为6G标准化提供了重要支持。

Abstract: Integrated Sensing and Communication (ISAC) has been identified as a key 6G
application by ITU and 3GPP. A realistic, standard-compatible channel model is
essential for ISAC system design. To characterize the impact of Sensing Targets
(STs), 3GPP defines ISAC channel as a combination of target and background
channels, comprising multipath components related to STs and those originating
solely from the environment, respectively. Although the background channel does
not carry direct ST information, its accurate modeling is critical for
evaluating sensing performance, especially in complex environments. Existing
communication standards characterize propagation between separated transmitter
(Tx) and receiver (Rx). However, modeling background channels in the ISAC
monostatic mode, where the Tx and Rx are co-located, remains a pressing
challenge. In this paper, we firstly conduct ISAC monostatic background channel
measurements for an indoor scenario at 28 GHz. Realistic channel parameters are
extracted, revealing pronounced single-hop propagation and discrete multipath
distribution. Inspired by these properties, a novel stochastic model is
proposed to characterizing the ISAC monostatic background channel as the
superposition of sub-channels between the monostatic Tx&Rx and multiple
communication Rx-like Reference Points (RPs). This model is compatible with
standardizations, and a 3GPP-extended implementation framework is introduced.
Finally, a genetic algorithm-based method is proposed to extract the optimal
number and placement of multi-RPs. The optimization approach and modeling
framework are validated by comparing measured and simulated channel parameters.
Results demonstrate that the proposed model effectively captures monostatic
background channel characteristics, addresses a critical gap in ISAC channel
modeling, and supports 6G standardization.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [16] [List Decoding and New Bicycle Code Constructions for Quantum LDPC Codes](https://arxiv.org/abs/2511.02951)
*Sheida Rabeti,Hessam Mahdavifar*

Main category: cs.IT

TL;DR: 提出新的量子LDPC码解码器MBBP-LD，在保持线性时间复杂度的同时，相比现有最优解码器降低逻辑错误率高达40%，并探索性能更优的单变量自行车码。


<details>
  <summary>Details</summary>
Motivation: 现有的量子LDPC码解码器在性能和复杂度之间存在权衡。尽管BP-OSD等先进解码器表现良好，但需要进一步提升逻辑错误率表现，同时保持计算的线性时间复杂度，这对于实用的量子计算系统至关重要。特别是在短量子LDPC码的解码方面，存在显著的性能改进空间。

Method: 提出了多基置信传播列表解码器(MBBP-LD)，该解码器扩展了经典循环LDPC码的多基置信传播(MBBP)框架。引入了新的后处理列表解码器决策规则，优于传统最小度量选择器(LMS)准则。同时探索了单变量自行车(UB)码这一新的BB码子类，通过将多项式搜索空间从两个多项式分量减少到单个多项式分量来简化搜索。

Result: 对于参数为[[144,12,12]]的双变量自行车码，提出的MBBP-LD解码器相比现有的短量子LDPC码最优解码器(BP-OSD)实现了高达40%的逻辑错误率降低，同时保持了普通BP解码器的线性时间复杂度。仿真结果显示，较低权重奇偶校验的单变量自行车码在各种BP解码器下都表现出有前景的性能。

Conclusion: 本文提出的MBBP-LD解码器在保持线性时间复杂度的同时，显著降低了量子LDPC码的逻辑错误率。通过引入新的决策规则和探索单变量自行车码，为短量子LDPC码的解码提供了更高效的解决方案，在BB码上的性能比现有最优解码器提升高达40%，展现了在量子错误纠正领域的重要应用前景。

Abstract: In this paper, we propose a new decoder, called the Multiple-Bases
Belief-Propagation List Decoder (MBBP-LD), for Quantum Low-Density Parity-Check
(QLDPC) codes. It extends the Multiple-Bases Belief-Propagation (MBBP)
framework, originally developed for classical cyclic LDPC codes. The proposed
method preserves the linear-time complexity of standard BP decoder while
improving the logical error rate. To further reduce the logical error rate, a
new decision rule is introduced for the post-processing list decoder,
outperforming the conventional least-metric selector (LMS) criterion. For the
recently developed and implemented bivariate bicycle (BB) code with parameters
\([[144,12,12]]\), our proposed MBBP-LD decoder achieves up to 40\% lower
logical error rate compared to the state-of-the-art decoder for short QLDPC
codes, i.e., BP with ordered-statistics decoding (BP-OSD), while retaining the
linear-time complexity of the plain BP decoder. In addition, we explore a new
subclass of BB codes, that we refer to as the univariate bicycle (UB) codes,
specifically with lower-weight parity checks (\(w=6,8\)). This reduces the
polynomial search space for the code compared to general BB codes, i.e., by
reducing the search space over two polynomial components in BB codes to just a
single polynomial component in UB codes. Simulations demonstrate the promising
performance of these codes under various types of BP decoders.

</details>


### [17] [A Tsallis-Entropy Lens on Genetic Variation](https://arxiv.org/abs/2511.03063)
*Margarita Geleta,Daniel Mas Montserrat,Alexander G. Ioannidis*

Main category: cs.IT

TL;DR: 提出了信息论泛化的固定统计量 $F_q$，通过调节参数 q 实现对罕见和常见变异的差异化加权，提供比传统 $F_{ST}$ 更精细的群体分化分析视角。


<details>
  <summary>Details</summary>
Motivation: 传统的基于方差的固定指数 $F_{ST}$ 在等位基因频谱偏斜时存在局限性，需要更精细的分化分析方法来捕捉不同频率变异的贡献。

Method: 提出了基于信息论的 Tsallis-order q F-统计量 $F_q$，该统计量测量相对于合并种群，亚种群内 Tsallis q-熵损失的分数。通过在 One-vs-Rest (OVR) 和 Leave-One-Out (LOO) 模式下应用，可以识别驱动区域结构的亚种群。

Result: $F_q$ 通过调节 q 值，在低 q 时增强罕见变异的权重，在 q=1 时等价于等位基因与种群标签间的互信息，在 q=2 时嵌套传统 $F_{ST}$，在 q=1 以上逐渐强调常见变异。在 865 个大洋洲基因组数据和基于 HGDP 及千人基因组的模拟数据中验证了其有效性。

Conclusion: $F_q$ 作为模拟审计和种群结构摘要的高分辨率补充工具，能够提供比传统 $F_{ST}$ 更精细的群体分化分析。

Abstract: We introduce an information-theoretic generalization of the fixation
statistic, the Tsallis-order $q$ F-statistic, $F_q$, which measures the
fraction of Tsallis $q$-entropy lost within subpopulations relative to the
pooled population. The family nests the classical variance-based fixation index
$F_{\textbf{ST}}$ at $q{=}2$ and a Shannon-entropy analogue at $q{=}1$, whose
absolute form equals the mutual information between alleles and population
labels. By varying $q$, $F_q$ acts as a spectral differentiator that up-weights
rare variants at low $q$, while $q{>}1$ increasingly emphasizes common
variants, providing a more fine-grained view of differentiation than
$F_{\textbf{ST}}$ when allele-frequency spectra are skewed. On real data (865
Oceanian genomes with 1,823,000 sites) and controlled genealogical simulations
(seeded from 1,432 founders from HGDP and 1000 Genomes panels, with 322,216
sites), we show that $F_q$ in One-vs-Rest (OVR) and Leave-One-Out (LOO) modes
provides clear attribution of which subpopulations drive regional structure,
and sensitively timestamps isolation-migration events and founder effects.
$F_q$ serves as finer-resolution complement for simulation audits and
population-structure summaries.

</details>


### [18] [Constacyclic codes with best-known parameters](https://arxiv.org/abs/2511.03323)
*Zekai Chen,Min Sha*

Main category: cs.IT

TL;DR: 论文构造了多族具有优良参数的q元循环码，维数约为码长一半，最小距离与n/log_q n成正比，包含许多最优或接近最优的码。


<details>
  <summary>Details</summary>
Motivation: 寻找具有大最小距离的高维循环码，特别是在码长较长时保持良好的纠错性能，以满足现代通信系统对高效纠错码的需求。

Method: 通过构造性方法，利用有限域上的代数结构，系统地构建了多个q元循环码的无限族，针对不同形式的码长n进行参数优化设计。

Result: 成功构造了多族q元循环码，码长为n，维数约为n/2，最小距离至少为cn/log_q n（c为正常数），包含许多具有最优或接近最优参数的码字。

Conclusion: 该研究成功构造了多族具有良好参数的q元循环码，包含许多最优或接近最优的码字，为编码理论提供了有价值的构造方法。

Abstract: In this paper, we construct several infinite families of $q$-ary constacyclic
codes over a finite field $\mathbb{F}_q$ with length $n$, dimension around
$n/2$, and minimum distance at least $cn/\log_q n$ for some positive constant
$c$. They contain many constacyclic codes with optimal, or almost-optimal, or
best-known parameters. We also consider various forms of the length $n$.

</details>


### [19] [The (+)-(L, P)-TGRS code](https://arxiv.org/abs/2511.03398)
*Zhonghao Liang,Chenlu Jia,Qunying Liao*

Main category: cs.IT

TL;DR: 本文研究了(+)-(L, P)-TGRS码，给出了其奇偶校验矩阵、NMDS条件、非RS性质证明以及自正交码构造，部分解决了开放问题并改进了已有成果。


<details>
  <summary>Details</summary>
Motivation: 非Reed-Solomon类型线性码的构造是近年来的研究热点。2025年Hu等人通过定义(L, P)-扭曲广义Reed-Solomon码构造了一些非RS MDS码，本文在此基础上进一步研究(+)-(L, P)-TGRS码的性质和结构。

Method: 论文首先给出了(+)-(L, P)-TGRS码C的奇偶校验矩阵表示，然后通过理论分析推导出码为NMDS的充要条件，证明了在特定条件下码的非RS性质，进一步研究了对偶性质并构造了自正交码类。

Result: 论文获得了多项重要成果：1) 部分回答了Hu等人2025年提出的两个开放问题；2) 改进了Hu等人2025年的相应结果，证明了当2k大于n时C是非RS码；3) 构造了两类自正交码，推广了Ding等人2025年的相应结果。

Conclusion: 本论文研究了(+)-(L, P)-TGRS码C的性质，给出了其奇偶校验矩阵，证明了C成为NMDS码的充要条件，并证明了当2k大于n时C是非RS码。论文还给出了码不自对偶或自正交的充分条件，构造了两类自正交码，这些结果部分回答了Hu等人提出的开放问题，并改进了已有研究成果。

Abstract: The construction of the non-Reed-Solomon (in short, non-RS) type linear code
has been one of the research hotspots in recent years. In 2025, Hu et al.
constructed some non-RS MDS codes by defining the (L, P)-twisted generalized
Reed-Solomon code (in short, (L, P)-TGRS). In this paper, we focus on the
(+)-(L, P)-TGRS code C. We firstly present a parity-check matrix. Secondly, we
give a sufficient and necessary condition for C to be NMDS which partially
answers two open problems proposed by Hu et al. in 2025, and prove that C is
non-RS for 2k > n which partially improves the corresponding result given by Hu
et al. in 2025,. Thirdly, we give a sufficient condition for C not to be
self-dual or self-orthogonal, respectively, furthermore, we construct two
classes of self-orthogonal codes which is a promotion of the corresponding
result given by Ding et al. in 2025. Finally, some examples are given.

</details>


### [20] [On the Fundamental Scaling Laws of Fluid Antenna Systems](https://arxiv.org/abs/2511.03415)
*Xusheng Zhu,Farshad Rostami Ghadi,Tuo Wu,Kaitao Meng,Chao Wang,Gui Zhou*

Main category: cs.IT

TL;DR: 本文填补了流体天线系统错误概率分析的理论空白，建立了SER与空间相关性之间的基本标度定律，提出了通过扩展天线运动空间而非密集增加端口来优化系统性能的设计原则。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统(FAS)通过利用空间分集为增强无线通信提供了有前景的范式，但其错误概率的严格分析框架明显缺失。这一关键缺口阻碍了对FAS性能的深入理解和系统优化。

Method: 论文通过推导适用于通用调制方式的紧凑闭式渐近表达式来建立这些基本定律。该方法基于现实的空间相关信道模型，为SER与信道空间相关性结构之间的关系建立了基本标度定律框架，并完整刻画了分集增益和编码增益。

Result: 建立了控制FAS在空间相关信道中符号错误率(SER)的基本标度定律，得到了适用于通用调制方式的紧凑闭式渐近表达式，完整表征了分集增益和编码增益，揭示了SER与信道空间相关性结构之间的基本关系。

Conclusion: 该论文得出了一个明确的系统设计指导原则：通过扩展天线的运动空间来增加分集度可以从根本上改善SER，而在受限空间内仅仅增加端口密度会带来收益递减的效果。这为FAS系统的实际设计提供了重要的理论依据。

Abstract: Fluid antenna systems (FAS) offer a promising paradigm for enhancing wireless
communication by exploiting spatial diversity, yet a rigorous analytical
framework for their error probability has been notably absent. To this end,
this paper addresses this critical gap by unveiling the \textbf{fundamental
scaling laws} that govern the symbol error rate (SER) of FAS in realistic,
spatially correlated channels. To establish these laws, we derive a tight,
closed-form asymptotic expression for the SER applicable to a general class of
modulation schemes. This result is pivotal as it establishes the fundamental
scaling law governing the relationship between SER and the channel's spatial
correlation structure. Based on this framework, we provide a complete
characterization of the diversity and coding gains. The analysis culminates in
a definitive design directive: SER can be fundamentally improved by expanding
the antenna's movement space to increase diversity, while merely increasing
port density within a constrained space yields diminishing returns.

</details>
